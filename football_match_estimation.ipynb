{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilty Estimation of Home and Away Teams for English Football Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to football betting there can be a lot of money to be made, bookmakers each year make hundreds of thousands if not millions on the public betting on football games. With that being said bookmakers use probability to gain advantage over the football games being bet on and this then reflects on the odds that the public get. If we can estimate the probabilities for the home teams and away teams winning from the data gathered, we can stand a greater chance of gaining an advantage. It must be said that with any kind of betting there is always an implied risk of losing, oftentimes football teams can go against the run of data that they have, for example, top of the premier league losing or dropping points to bottom of the premier league, it doesn't always happen but it does happen.\n",
    "\n",
    "For this project the goal is to estimate the probabilities of winning for the home teams and away teams of football matches in the premier league, championship and league one of english football. The reasoning behind only obtaining probabilities of just winning is because the actual chance of two teams cancelling each other out for a draw is usually unlikely, it is more likely that one team underperforms, or one team overperforms, or both teams are just unlucky on the day. As we cant factor these outcomes in, predicting for a draw would be rather difficult.\n",
    "\n",
    "So the idea for this project is to create two classification models, one for modelling the estimation of home team win probabilities and one for modelling the estimation of away team win probabilities (where win = class 1 and lose/draw = class 0). The highest probability teams for each game will be ranked by probability and difference from the team with the lower probability of winning from each game along with their expected value and bet return. These teams then can be bet on and also used in accumulation calculations for accumulator bets.\n",
    "\n",
    "home team expected value formulation:\n",
    "\n",
    "p(W|ht) * wa + (1 - p(W|ht)) * - ba\n",
    "\n",
    "away team expected value formulation:\n",
    "\n",
    "p(W|at) * wa + (1 - p(W|at)) * - ba\n",
    "\n",
    "where W = win, ht = home team, at - away team, wa = win amount, ba = bet amount\n",
    "\n",
    "The metric of choice for both models is fbeta with slightly more weight towards maximising recall and minimising false negatives. This is because minimising false negatives allows the models to be more risk accepting as decreasing false negatives (predicting no win when it actualy is win) will imply increasing false positives (predicting win when it actually is no win), therefore allowing more risk, this is down to choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.389190Z",
     "start_time": "2021-04-08T08:13:24.696295Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from math import ceil\n",
    "from pyearth import Earth\n",
    "from tqdm import trange, tqdm_notebook\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import anderson\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import boxcox\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import differential_evolution\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRFClassifier\n",
    "from xgboost import plot_importance\n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from hpsklearn import HyperoptEstimator\n",
    "from hyperopt import atpe, tpe, fmin, hp, STATUS_OK, space_eval, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from catboost import CatBoostClassifier, Pool, EFstrType\n",
    "from lightgbm import LGBMClassifier\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import load_model\n",
    "\n",
    "# show entire sataset\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.420336Z",
     "start_time": "2021-04-08T08:13:31.389190Z"
    }
   },
   "outputs": [],
   "source": [
    "def similarity_imputation(data, impute_target, numeric_columns, missing_value='nan', n_neighbours=5, dec_places=0, regression=True):\n",
    "    \"\"\"\n",
    "    Computes euclidean distance for feature similarity imputation\n",
    "\n",
    "    if applying to multpile columns in the same dataframe the calculation will include previously imputed values\n",
    "\n",
    "    params:\n",
    "        data = dataframe that imputaion is being applied to\n",
    "        impute_target = feature column with missing data\n",
    "        numeric_columns  = feature columns in dataframe that have numeric values (nan values show numeric columns dtypes as 'object')\n",
    "        missing_value = value to impute\n",
    "        n_neighbours = number of closest neighbours to consider for imputation\n",
    "        dec_places = decimal places to match target feature column when imputing\n",
    "        regression = true for regression, false for classification\n",
    "\n",
    "    returns:\n",
    "        new dataframe with applied imputation\n",
    "        list of indices indicating rows with missing values that couldn't be used for distance calculation\n",
    "    \"\"\"\n",
    "    orig_data = data.copy()\n",
    "    features = data.copy()\n",
    "    features.drop(labels=impute_target, axis=1, inplace=True)\n",
    "    # ohe\n",
    "    idx = features.dtypes == 'object'\n",
    "    cat_cols = list(idx[idx].index.values)\n",
    "    num_cols = numeric_columns\n",
    "    for num_col in num_cols:\n",
    "        if num_col in cat_cols:\n",
    "            cat_cols.remove(num_col)\n",
    "    features_ohe = pd.get_dummies(features, columns=cat_cols)\n",
    "    # get index of missing target rows\n",
    "    if missing_value == 'nan':\n",
    "        mv = data[impute_target].isnull()\n",
    "        row_idx = mv[mv].index.values  # get index of true values\n",
    "    else:\n",
    "        mv = data[impute_target] == missing_value\n",
    "        row_idx = mv[mv].index.values  # get index of true values\n",
    "    # data that has no missing target value.. original data, dropped target data & ohe data\n",
    "    orig_data_with_target = orig_data.drop(row_idx, axis=0)\n",
    "    data_with_target = features.drop(row_idx, axis=0)\n",
    "    data_with_target_ohe = features_ohe.drop(row_idx, axis=0)\n",
    "    # data that has missing target value.. dropped target data & ohe data\n",
    "    data_missing_target = features.iloc[row_idx, :]\n",
    "    data_missing_target_ohe = features_ohe.iloc[row_idx, :]\n",
    "\n",
    "    # main loop\n",
    "    pred_data = data.copy()\n",
    "    # rows with more than 2 nan values\n",
    "    nan_index = []\n",
    "    for i in trange(len(data_missing_target),  desc='Target imputation row'):\n",
    "        y = data_missing_target.iloc[i, :].copy()\n",
    "        # y.drop(labels = 'shoe_size', inplace = True) # remove target variable\n",
    "        y_ohe = data_missing_target_ohe.iloc[i, :].copy()\n",
    "\n",
    "        # check for nan values in other columns\n",
    "        nan_y_count = 0\n",
    "        y_nan_cols = []\n",
    "        for k in range(len(y)):\n",
    "            if missing_value == 'nan':\n",
    "                if pd.isnull(y[k]):\n",
    "                    nan_y_count += 1  # count missing values\n",
    "                    y_nan_cols.append(y.index[k])\n",
    "            else:\n",
    "                if y[k] == missing_value:\n",
    "                    nan_y_count += 1  # count missing values\n",
    "                    # temp store column name of nan value\n",
    "                    y_nan_cols.append(y.index[k])\n",
    "        if nan_y_count >= 1:\n",
    "            # if i == 0:\n",
    "            #    print('First imputation row has 1 or more missing values!\\n')\n",
    "            if data_missing_target.iloc[i, :].name not in nan_index:\n",
    "                nan_index.append(data_missing_target.iloc[i, :].name)\n",
    "            continue\n",
    "        # elif nan_y_count <= 2:\n",
    "        #    y.drop(lables = y_nan_cols, inplace = True)\n",
    "        distances = []\n",
    "        for j in range(len(data_with_target)):\n",
    "            x = data_with_target.iloc[j, :].copy()\n",
    "            # remove target variable\n",
    "            #x.drop(labels = 'shoe_size', inplace = True)\n",
    "            x_ohe = data_with_target_ohe.iloc[j, :].copy()\n",
    "            # check for nan values in other columns\n",
    "            nan_x_count = 0\n",
    "            x_nan_cols = []\n",
    "            for l in range(len(x)):\n",
    "                if missing_value == 'nan':\n",
    "                    if pd.isnull(x[l]):  # if missing value is nan but not recognised\n",
    "                        nan_x_count += 1  # count missing values\n",
    "                        x_nan_cols.append(x.index[l])\n",
    "                else:\n",
    "                    if x[l] == missing_value:\n",
    "                        nan_x_count += 1  # count missing values\n",
    "                        # temp store column name of nan value\n",
    "                        x_nan_cols.append(x.index[l])\n",
    "            if nan_x_count >= 1:  # if more than 2 nan values index observation and move to next\n",
    "                if data_with_target.iloc[j, :].name not in nan_index:\n",
    "                    nan_index.append(data_with_target.iloc[j, :].name)\n",
    "                continue\n",
    "            # elif nan_x_count <= 2: # if x contains 2 or less nans, drop columns\n",
    "            #    x.drop(lables = x_nan_cols, inplace = True)\n",
    "            # ohe ########## needs to work when a value is categorical ##########\n",
    "            #x = pd.get_dummies(x)\n",
    "            #y = pd.get_dummies(y)\n",
    "            euc_dist = euclidean_dist(x_ohe, y_ohe)\n",
    "            distances.append(euc_dist)\n",
    "\n",
    "        data_feats = orig_data_with_target.copy()  # df of rows target values\n",
    "        for ind in nan_index:\n",
    "            if ind in data_feats.index:\n",
    "                data_feats.drop(labels=ind, axis=0, inplace=True)\n",
    "        data_feats['distance'] = distances\n",
    "        data_feats.sort_values(by='distance', ascending=True, inplace=True)\n",
    "        # check number of neighbours against available data\n",
    "        if n_neighbours > len(data_feats):\n",
    "            if len(data_feats) % 2 == 0:  # if len(data_feats) is even then make n_neighbours odd\n",
    "                k_nn = data_feats.iloc[0: len(data_feats)-1, :]\n",
    "            else:\n",
    "                k_nn = data_feats.iloc[0: len(data_feats), :]\n",
    "            print(\n",
    "                f'The n_neighbours parameter value of {n_neighbours} is greater than available data to perform a distance calculation\\ntherefore n_neighbours is automatically set to the nearest available value: {len(k_nn)}\\n')\n",
    "        else:\n",
    "            k_nn = data_feats.iloc[0: n_neighbours, :]\n",
    "        if regression == True:\n",
    "            # majority is the mean of nearest neighbours\n",
    "            majority = np.round(k_nn[impute_target].mean(), dec_places)\n",
    "            orig_data[impute_target][row_idx[i]] = majority\n",
    "        else:  # classification\n",
    "            # majority is the mode of the nearest neighbours\n",
    "            if len(k_nn[impute_target].mode()) > 1:\n",
    "                majority = k_nn[impute_target].mode().values[0]\n",
    "            else:\n",
    "                majority = k_nn[impute_target].mode().values[0]\n",
    "            orig_data[impute_target][row_idx[i]] = majority\n",
    "    return orig_data, sorted(nan_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.435328Z",
     "start_time": "2021-04-08T08:13:31.422387Z"
    }
   },
   "outputs": [],
   "source": [
    "def euclidean_dist(x_row, y_row):\n",
    "    sq_difs = []\n",
    "    for col in range(len(x_row)):\n",
    "        sq_dif = (x_row[col] - y_row[col])**2\n",
    "        sq_difs.append(sq_dif)\n",
    "\n",
    "    sum_difs = np.sum(sq_difs)\n",
    "    euc_dist = np.sqrt(sum_difs)\n",
    "    return euc_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.452867Z",
     "start_time": "2021-04-08T08:13:31.437293Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_ohe_team_df(data):\n",
    "    \"\"\"\n",
    "    creates a one hot encoded dataframe of teams\n",
    "    params:\n",
    "        data = main data (combined league data)\n",
    "\n",
    "    creates dataframe or returns error of mismatch of home/away teams\n",
    "    \"\"\"\n",
    "    if sorted(data['HomeTeam'].value_counts().index) == sorted(data['AwayTeam'].value_counts().index):\n",
    "        teams_enc = pd.get_dummies(\n",
    "            sorted(data['HomeTeam'].value_counts().index))\n",
    "        teams_enc.to_csv('ohe_teams.csv', encoding='utf-8', index=False)\n",
    "    else:\n",
    "        return 'Home teams and away teams do not match, check columns match.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.468235Z",
     "start_time": "2021-04-08T08:13:31.452867Z"
    }
   },
   "outputs": [],
   "source": [
    "def team_ohe(team):\n",
    "    \"\"\" \n",
    "    one hot encodes team\n",
    "\n",
    "    params:\n",
    "        team = string name of team\n",
    "\n",
    "    returns either array of ohe values for selected team or error for spelling\n",
    "    \"\"\"\n",
    "    ohe_df = pd.read_csv('ohe_teams.csv')\n",
    "    if team in ohe_df.columns:\n",
    "        return ohe_df[team].values\n",
    "    else:\n",
    "        return \"Cannot find team, please check spelling including capitals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.484171Z",
     "start_time": "2021-04-08T08:13:31.469191Z"
    }
   },
   "outputs": [],
   "source": [
    "def football_data_team_ohe(data):\n",
    "    \"\"\"\n",
    "    one hot encodes football teams in data\n",
    "\n",
    "    params:\n",
    "        data = main football data\n",
    "\n",
    "    returns new dataframe with encoded football teams\n",
    "    \"\"\"\n",
    "    footy_data = data.copy()\n",
    "    if sorted(data['HomeTeam'].value_counts().index) == sorted(data['AwayTeam'].value_counts().index):\n",
    "        all_teams = sorted(footy_data['HomeTeam'].value_counts().index)\n",
    "        # one hot encode home team\n",
    "        all_home_teams = [f'home_{t}' for t in all_teams]\n",
    "        home_teams = pd.DataFrame(0, index=range(\n",
    "            0, len(footy_data)), columns=all_home_teams)\n",
    "\n",
    "        for team in all_teams:\n",
    "            if team in footy_data['HomeTeam'].values:\n",
    "                mask = footy_data['HomeTeam'] == team\n",
    "                mask_idx = mask[mask].index.values\n",
    "                ohe_vals = team_ohe(team)\n",
    "                for i in range(0, len(mask_idx)):\n",
    "                    home_teams.loc[mask_idx[i]] = ohe_vals\n",
    "\n",
    "        for col in home_teams:\n",
    "            footy_data = footy_data.join(home_teams[col])\n",
    "        # remove original home team data\n",
    "        footy_data.drop(columns='HomeTeam', inplace=True)\n",
    "\n",
    "        # one hot encode away team\n",
    "        all_away_teams = [f'away_{t}' for t in all_teams]\n",
    "        away_teams = pd.DataFrame(0, index=range(\n",
    "            0, len(footy_data)), columns=all_away_teams)\n",
    "\n",
    "        for team in all_teams:\n",
    "            if team in footy_data['AwayTeam'].values:\n",
    "                mask = footy_data['AwayTeam'] == team\n",
    "                mask_idx = mask[mask].index.values\n",
    "                ohe_vals = team_ohe(team)\n",
    "                for i in range(0, len(mask_idx)):\n",
    "                    away_teams.loc[mask_idx[i]] = ohe_vals\n",
    "\n",
    "        for col in away_teams:\n",
    "            footy_data = footy_data.join(away_teams[col])\n",
    "        # remove original away team data\n",
    "        footy_data.drop(columns='AwayTeam', inplace=True)\n",
    "        return footy_data\n",
    "    else:\n",
    "        return 'Mismatch between home and away teams.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.499749Z",
     "start_time": "2021-04-08T08:13:31.487133Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_train_features():\n",
    "    features = pd.read_csv('combined_leagues_train features.csv')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.515703Z",
     "start_time": "2021-04-08T08:13:31.502738Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_transformed_train_data():\n",
    "    ''' load train features with transformed continuous data only '''\n",
    "    train_features = load_train_features()\n",
    "    # transformed features\n",
    "    box_cox = ['AHTSOT5PG', 'AATSOT5PG', 'AHTSOT5PHG',\n",
    "               'AATSOT5PAG', 'AHTP5PG', 'AHTGS_SOT5PHG_ratio']\n",
    "    quant = ['AHTGS5PG', 'AATGS5PG', 'AHTGC5PG', 'AATGC5PG', 'AHTGS5PHG', 'AATGS5PAG', 'AHTGC5PHG', 'AATGC5PAG', 'AHTGS_SOT5PG_ratio',\n",
    "             'AATGS_SOT5PG_ratio', 'AATGS_SOT5PAG_ratio', 'AHTGD5PG', 'AATGD5PG', 'AHTGD5PHG', 'AATGD5PAG', 'HA_AHTGS5PG_diff',\n",
    "             'HA_ATP5PG_diff', 'AHT_GS_P5PG_ratio', 'AAT_GS_P5PG_ratio', 'AwayTeamDist', 'AwayCapacityDiff_bin', 'AwayTeamDist_bin',\n",
    "             'bxcx_AATGS5PG', 'bxcx_AHTGS5PG', 'bxcx_AHTGC5PG', 'bxcx_AHTSOT5PG', 'bxcx_AATSOT5PG', 'bxcx_AHT_GS_P5PG_ratio',\n",
    "             'bxcx_AAT_GS_P5PG_ratio', 'bxcx_AATGC5PG']\n",
    "    train_features.drop(columns=box_cox, inplace=True)\n",
    "    train_features.drop(columns=quant, inplace=True)\n",
    "    return train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.533052Z",
     "start_time": "2021-04-08T08:13:31.518671Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_test_features():\n",
    "    features = pd.read_csv('Combined_leagues_test_features.csv')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.548447Z",
     "start_time": "2021-04-08T08:13:31.533052Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_home_targets():\n",
    "    \"\"\" returns home win targets... train_target, test_target \"\"\"\n",
    "    train_target = pd.read_csv('Combined_leagues_home_train_target.csv')\n",
    "    test_target = pd.read_csv('Combined_leagues_home_test_target.csv')\n",
    "    return train_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.564394Z",
     "start_time": "2021-04-08T08:13:31.549435Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_away_targets():\n",
    "    \"\"\" returns away win targets... train_target, test_target \"\"\"\n",
    "    train_target = pd.read_csv('Combined_leagues_away_train_target.csv')\n",
    "    test_target = pd.read_csv('Combined_leagues_away_test_target.csv')\n",
    "    return train_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.581751Z",
     "start_time": "2021-04-08T08:13:31.565428Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_home_win_train_df():\n",
    "    df = load_train_features()\n",
    "    target, _ = load_home_targets()\n",
    "    df['HomeFTR'] = target\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.597121Z",
     "start_time": "2021-04-08T08:13:31.581751Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_home_train_df_transformed():\n",
    "    df = load_transformed_train_data()\n",
    "    target, _ = load_home_targets()\n",
    "    df['HomeFTR'] = target\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.612824Z",
     "start_time": "2021-04-08T08:13:31.599119Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_away_win_train_df():\n",
    "    df = load_train_features()\n",
    "    target, _ = load_away_targets()\n",
    "    df['AwayFTR'] = target\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.627776Z",
     "start_time": "2021-04-08T08:13:31.612824Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_away_train_df_transformed():\n",
    "    df = load_transformed_train_data()\n",
    "    target, _ = load_away_targets()\n",
    "    df['AwayFTR'] = target\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.641270Z",
     "start_time": "2021-04-08T08:13:31.629731Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_train_features(train_features):\n",
    "    \"\"\" saves train_features as csv file \"\"\"\n",
    "    train_features.to_csv(\n",
    "        \"combined_leagues_train features.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.656583Z",
     "start_time": "2021-04-08T08:13:31.641270Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_test_features(test_features):\n",
    "    \"\"\" saves test_features as csv file \"\"\"\n",
    "    test_features.to_csv(\"Combined_leagues_test_features.csv\",\n",
    "                         encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.670384Z",
     "start_time": "2021-04-08T08:13:31.657579Z"
    }
   },
   "outputs": [],
   "source": [
    "def cdf(sample, x):\n",
    "    count = 0\n",
    "    for val in sample:\n",
    "        if val <= x:\n",
    "            count += 1\n",
    "\n",
    "    prob = count / len(sample)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.685886Z",
     "start_time": "2021-04-08T08:13:31.670384Z"
    }
   },
   "outputs": [],
   "source": [
    "def phi(contingency_table):\n",
    "    chi2 = chi2_contingency(contingency_table)[0]\n",
    "    n = contingency_table.sum()\n",
    "    return np.sqrt(chi2 / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.716818Z",
     "start_time": "2021-04-08T08:13:31.687877Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_football_ground(team):\n",
    "    \"\"\" \n",
    "    returns football ground and capacity for selected team\n",
    "    football ground used in conjunction with geopy for geo location\n",
    "\n",
    "    params:\n",
    "        team = string of team\n",
    "\n",
    "    returns tuple (ground name, capacity)\n",
    "    \"\"\"\n",
    "    football_ground_dict = {\n",
    "        'AFC Wimbledon': ('Wimbledon Plough Lane', 9300),\n",
    "        'Accrington': ('Accrington Crown Ground', 5450),\n",
    "        'Arsenal': ('London Emirates Stadium', 60260),\n",
    "        'Aston Villa': ('Aston Villa Villa Park', 42749),\n",
    "        'Barnsley': ('Barnsley Oakwell Stadium', 23287),\n",
    "        'Birmingham': ('Birmingham St Andrews Trillion Trophy Stadium', 29409),\n",
    "        'Blackburn': ('Blackburn Ewood Park', 31367),\n",
    "        'Blackpool': ('Blackpool Bloomfield Road', 16616),\n",
    "        'Bolton': ('Bolton University of Bolton Stadium', 28723),\n",
    "        'Bournemouth': ('Bournemouth Vitality Stadium', 11329),\n",
    "        'Bradford': ('Bradford Utilita Energy Stadium', 25136),\n",
    "        'Brentford': ('Brentford Community Stadium', 17250),\n",
    "        'Brighton': ('Brighton American Express Community Stadium', 30666),\n",
    "        'Bristol City': ('Bristol Ashton Gate Stadium', 27000),\n",
    "        'Bristol Rvs': ('Bristol Memorial Stadium', 12296),\n",
    "        'Burnley': ('Burnley Turf Moor', 21944),\n",
    "        'Burton': ('Burton Pirelli Stadium', 6912),\n",
    "        'Bury': ('Bury Gigg Lane', 11840),\n",
    "        'Cambridge': ('Cambridge Abbey Stadium', 8127),\n",
    "        'Cardiff': ('Cardiff City Stadium', 33280),\n",
    "        'Carlisle': ('Carlisle Brunton Park', 18202),\n",
    "        'Charlton': ('Charlton The Valley', 27111),\n",
    "        'Chelsea': ('Chelsea Stamford Bridge', 40834),\n",
    "        'Cheltenham': ('Cheltenham Jonny-Rocks Stadium', 7066),\n",
    "        'Chesterfield': ('chesterfield Proact Stadium', 10600),\n",
    "        'Colchester': ('Colchester JobServe Community Stadium', 10105),\n",
    "        'Coventry': ('Coventry The Ricoh Arena', 32609),\n",
    "        'Crawley Town': ('Crawley Broadfield Stadium', 6134),\n",
    "        'Crewe': ('Crewe Alexandra Stadium', 10153),\n",
    "        'Crystal Palace': ('London Selhurst Park', 25486),\n",
    "        'Dag and Red': ('Dagenham Victoria Road', 6078),\n",
    "        'Derby': ('Derby Pride Park Stadium', 33597),\n",
    "        'Doncaster': ('Doncaster Keepmoat Stadium', 15231),\n",
    "        'Everton': ('Liverpool Goodison Park', 39414),\n",
    "        'Exeter': ('Exeter St. James Park', 8541),\n",
    "        'Fleetwood Town': ('Fleetwood Highbury Stadium', 5327),\n",
    "        'Fulham': ('Fulham Craven Cottage', 19359),\n",
    "        'Gillingham': ('Gillingham Priestfield Stadium', 11582),\n",
    "        'Grimsby': ('Grimsby Blundell Park', 9031),\n",
    "        'Hartlepool': ('Hartlepool Victoria Park', 7865),\n",
    "        'Hereford': ('Hereford Edgar Street', 5213),\n",
    "        'Huddersfield': ('Huddersfield Kirklees Stadium', 24500),\n",
    "        'Hull': ('Hull KCom Stadium', 25586),\n",
    "        'Ipswich': ('Ipswich Portman Road Stadium', 30311),\n",
    "        'Leeds': ('Leeds Elland Road', 37792),\n",
    "        'Leicester': ('Leicester King Power Stadium', 32312),\n",
    "        'Leyton Orient': ('Leyton The Breyer Group Stadium', 9271),\n",
    "        'Lincoln': ('Lincoln LNER Stadium', 10120),\n",
    "        'Liverpool': ('Liverpool Anfield', 53394),\n",
    "        'Luton': ('Luton Kenilworth Road', 10356),  # possible new stadium\n",
    "        'Man City': ('Manchester Etihad Stadium', 55017),\n",
    "        'Man United': ('Manchester Old Trafford', 74140),\n",
    "        'Mansfield': ('Mansfield Field Mill', 9186),\n",
    "        'Middlesbrough': ('Middlesbrough The Riverside Stadium', 34742),\n",
    "        'Millwall': ('Millwall The Den', 20146),\n",
    "        'Milton Keynes Dons': ('Milton Keynes Stadium MK', 30500),\n",
    "        'Newcastle': ('Newcastle St. James Park', 52305),\n",
    "        'Northampton': ('Northampton Sixfields Stadium', 7798),\n",
    "        'Norwich': ('Norwich Carrow Road Stadium', 27244),\n",
    "        \"Nott'm Forest\": ('Nottingham The City Ground', 30446),\n",
    "        'Notts County': ('Nottingham Meadow Lane', 19841),\n",
    "        'Oldham': ('Oldham Boundary Park', 13513),\n",
    "        'Oxford': ('Oxford Kassam Stadium', 12400),\n",
    "        'Peterboro': ('Peterborough Weston Homes Stadium', 15314),\n",
    "        'Plymouth': ('Plymouth Home Park', 17904),\n",
    "        'Port Vale': ('Port Vale Vale Park', 19052),\n",
    "        'Portsmouth': ('Portsmouth Fratton Park', 20620),\n",
    "        'Preston': ('Preston Deepdale Stadium', 23404),\n",
    "        'QPR': ('Hammersmith Loftus Road', 18439),\n",
    "        'Reading': ('Reading Madejski Stadium', 24161),\n",
    "        'Rochdale': ('Rochdale Spotland Stadium', 15000),\n",
    "        'Rotherham': ('Rotherham AESSEAL New York Stadium', 12021),\n",
    "        'Rushden & D': ('Northampton Nene Park', 6441),\n",
    "        'Scunthorpe': ('Scunthorpe Glanford Park', 9088),\n",
    "        'Sheffield United': ('Sheffield Bramall Lane', 32050),\n",
    "        'Sheffield Weds': ('Sheffield Hillsborough Stadium', 34854),\n",
    "        'Shrewsbury': ('Shrewsbury New Meadow', 9875),\n",
    "        'Southampton': ('Southampton St. Marys Stadium', 32505),\n",
    "        'Southend': ('Southend-on-Sea Roots Hall Stadium', 12392),\n",
    "        'Stevenage': ('Stevenage Lamex Stadium', 7800),\n",
    "        'Stockport': ('Stockport Edgeley Park', 10841),\n",
    "        'Stoke': ('Stoke Bet365 Stadium', 30089),\n",
    "        'Sunderland': ('Sunderland Stadium of Light', 49000),\n",
    "        'Swansea': ('Swansea Liberty Stadium', 21088),\n",
    "        'Swindon': ('Swindon The County Ground', 15728),\n",
    "        'Torquay': ('Torquay Plainmoor', 6500),\n",
    "        'Tottenham': ('Tottenham White Hart Lane', 62303),\n",
    "        'Tranmere': ('Tranmere Prenton Park', 16567),\n",
    "        'Walsall': ('Walsall Bescot Stadium', 11300),\n",
    "        'Watford': ('Watford Vicarage Road', 21577),\n",
    "        'West Brom': ('West Bromwich The Hawthorns', 26688),\n",
    "        'West Ham': ('West Ham The London Stadium', 60000),\n",
    "        'Wigan': ('Wigan DW Stadium', 25133),\n",
    "        'Wimbledon': ('Wimbledon Plough Lane', 9300),\n",
    "        'Wolves': ('Wolverhampton Molineux Stadium', 31700),\n",
    "        'Wrexham': ('Wrexham Glyndŵr University Racecourse Stadium', 10771),\n",
    "        'Wycombe': ('Wycombe Adams Park', 9448),\n",
    "        'Yeovil': ('Yeovil Huish Park', 9565)\n",
    "    }\n",
    "    return football_ground_dict.get(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.732781Z",
     "start_time": "2021-04-08T08:13:31.717776Z"
    }
   },
   "outputs": [],
   "source": [
    "def fbeta(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta=1.2, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.748693Z",
     "start_time": "2021-04-08T08:13:31.733733Z"
    }
   },
   "outputs": [],
   "source": [
    "def r2(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.763829Z",
     "start_time": "2021-04-08T08:13:31.750723Z"
    }
   },
   "outputs": [],
   "source": [
    "def explained_var(y_true, y_pred):\n",
    "    return explained_variance_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.777274Z",
     "start_time": "2021-04-08T08:13:31.764794Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(features, target, model, k_splits=5):\n",
    "    cv = RepeatedStratifiedKFold(\n",
    "        n_splits=k_splits, n_repeats=2, random_state=1)\n",
    "    # evaluation scoring metric\n",
    "    metric = make_scorer(fbeta)\n",
    "    scores = cross_val_score(model, features, target,\n",
    "                             scoring=metric, cv=cv, n_jobs=-1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.791802Z",
     "start_time": "2021-04-08T08:13:31.777274Z"
    }
   },
   "outputs": [],
   "source": [
    "def cramers_corrected_stat(contingency_table):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher, \n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    chi2 = chi2_contingency(contingency_table)[0]\n",
    "    n = contingency_table.sum()\n",
    "    phi2 = chi2/n\n",
    "    r, k = contingency_table.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.807182Z",
     "start_time": "2021-04-08T08:13:31.791802Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_home_train_features_with_drop():\n",
    "    \"\"\" loads home training features with uncorrelated/unassociated features dropped and without continuous transformations \"\"\"\n",
    "    home_df = load_home_win_train_df()\n",
    "    non_sig = ['HF', 'AF', 'AY', 'HR', 'AR', 'year', 'AHTGS_SOT5PG_ratio', 'AHTGS_SOT5PHG_ratio', 'AATGS5PG_LOWoutlier',\n",
    "               'AHTSOT5PG_LOWoutlier', 'AATSOT5PG_LOWoutlier', 'AATSOT5PAG_LOWoutlier', 'AHTGS_SOT5PG_ratio_UPoutlier',\n",
    "               'AATGS_SOT5PG_ratio_UPoutlier', 'AHTGS_SOT5PHG_ratio_UPoutlier', 'AATGS_SOT5PAG_ratio_UPoutlier',\n",
    "               'AHTGD5PG_LOWoutlier', 'AATGD5PG_LOWoutlier', 'AwayTeamDist', 'AwayTeamDist_bin', 'Local_Derby',\n",
    "               'AATGS5PG_upqrt_AHTGC5PG_lowqrt']\n",
    "    #outlier_feats = [col for col in home_df.columns if 'outlier' in col]\n",
    "    # outlier_feat_keep = ['AHTGC5PG_LOWoutlier','AATGC5PG_UPoutlier','AHTGS5PHG_UPoutlier','AATGS5PAG_UPoutlier',\n",
    "    #                     'AATSOT5PG_LOWoutlier','AHTGD5PG_UPoutlier','AATGD5PG_UPoutlier','AATGD5PAG_LOWoutlier']\n",
    "    #drop_outlier_feats = [col for col in outlier_feats if col not in outlier_feat_keep  ]\n",
    "    others_to_drop = ['Div', 'FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HY',\n",
    "                      'AwayCapacityDiff', 'HomeFTR']  # ,'AwayCapacityDiff_bin','Dist>=100','cluster_0','cluster_1',\n",
    "    #                'cluster_2','bxcx_AHTGS5PG','bxcx_AHTGC5PG','bxcx_AATGC5PG','HA_AHTGS5PG_diff_lowqrt','AATGC5PG_upqrt',\n",
    "    #                  'AATGC5PG_lowqrt','HomeFTR']\n",
    "    #drop_others = [col for col in others_to_drop if col not in non_sig or col not in drop_outlier_feats]\n",
    "    # all features to drop\n",
    "    transformed = [col for col in home_df.columns if 'TRANSFORM' in col]\n",
    "    combined_feats = non_sig + others_to_drop + transformed\n",
    "    # drop features\n",
    "    drop_df = home_df.drop(columns=combined_feats)\n",
    "\n",
    "    return drop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.820761Z",
     "start_time": "2021-04-08T08:13:31.808178Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_home_train_features_with_drop_transformed():\n",
    "    \"\"\" loads home training features with uncorrelated/unassociated features dropped and with continuous transformations \"\"\"\n",
    "    home_df = load_home_train_df_transformed()\n",
    "    non_sig = ['HF', 'AF', 'AY', 'HR', 'AR', 'year', 'AHTGS_SOT5PG_ratio_quantileTRANSFORM', 'AHTGS_SOT5PHG_ratio_bxcx_pwrTRANSFORM',\n",
    "               'AATGS5PG_LOWoutlier', 'AHTSOT5PG_LOWoutlier', 'AATSOT5PG_LOWoutlier', 'AATSOT5PAG_LOWoutlier',\n",
    "               'AHTGS_SOT5PG_ratio_UPoutlier', 'AATGS_SOT5PG_ratio_UPoutlier', 'AHTGS_SOT5PHG_ratio_UPoutlier',\n",
    "               'AATGS_SOT5PAG_ratio_UPoutlier', 'AHTGD5PG_LOWoutlier', 'AATGD5PG_LOWoutlier', 'AwayTeamDist_quantileTRANSFORM',\n",
    "               'AwayTeamDist_bin_quantileTRANSFORM', 'Local_Derby', 'AATGS5PG_upqrt_AHTGC5PG_lowqrt']\n",
    "    #outlier_feats = [col for col in home_df.columns if 'outlier' in col]\n",
    "    # outlier_feat_keep = ['AHTGC5PG_LOWoutlier','AATGC5PG_UPoutlier','AHTGS5PHG_UPoutlier','AATGS5PAG_UPoutlier',\n",
    "    #                     'AATSOT5PG_LOWoutlier','AHTGD5PG_UPoutlier','AATGD5PG_UPoutlier','AATGD5PAG_LOWoutlier']\n",
    "    #drop_outlier_feats = [col for col in outlier_feats if col not in outlier_feat_keep  ]\n",
    "    others_to_drop = ['Div', 'FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HY',\n",
    "                      'AwayCapacityDiff', 'HomeFTR']  # ,'AwayCapacityDiff_bin','Dist>=100','cluster_0','cluster_1',\n",
    "    #                'cluster_2','bxcx_AHTGS5PG','bxcx_AHTGC5PG','bxcx_AATGC5PG','HA_AHTGS5PG_diff_lowqrt','AATGC5PG_upqrt',\n",
    "    #                  'AATGC5PG_lowqrt','HomeFTR']\n",
    "    #drop_others = [col for col in others_to_drop if col not in non_sig or col not in drop_outlier_feats]\n",
    "    # all features to drop\n",
    "    combined_feats = non_sig + others_to_drop\n",
    "    # drop features\n",
    "    drop_df = home_df.drop(columns=combined_feats)\n",
    "\n",
    "    return drop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.836401Z",
     "start_time": "2021-04-08T08:13:31.820761Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_away_train_features_with_drop():\n",
    "    \"\"\" loads away training features with uncorrelated/unassociated features dropped and without continuous transformations\"\"\"\n",
    "    away_df = load_away_win_train_df()\n",
    "    non_sig = ['HF', 'AF', 'HC', 'AY', 'HR', 'AR', 'AHTGS_SOT5PG_ratio', 'AHTGS_SOT5PHG_ratio', 'AATGS5PG_LOWoutlier',\n",
    "               'AHTGC5PG_LOWoutlier', 'AATGC5PG_UPoutlier', 'AATGC5PAG_UPoutlier', 'AHTSOT5PG_LOWoutlier',\n",
    "               'AATSOT5PG_LOWoutlier', 'AATSOT5PAG_LOWoutlier', 'AHTGS_SOT5PG_ratio_UPoutlier', 'AATGS_SOT5PG_ratio_UPoutlier',\n",
    "               'AHTGS_SOT5PHG_ratio_UPoutlier', 'AATGS_SOT5PAG_ratio_UPoutlier', 'AHTGD5PG_LOWoutlier', 'AATGD5PG_LOWoutlier',\n",
    "               'AATGD5PAG_LOWoutlier', 'AwayTeamDist', 'AwayTeamDist_bin', 'Local_Derby', 'Dist>=100',\n",
    "               'AHTGS5PG_upqrt_AATGC5PG_lowqrt', 'AATGS5PG_upqrt_AHTGC5PG_lowqrt']\n",
    "    #outlier_feats = [col for col in away_df.columns if 'outlier' in col]\n",
    "    # outlier_feat_keep = ['AATGS5PG_UPoutlier','AHTGC5PG_UPoutlier','AATGS5PAG_UPoutlier','AHTGC5PHG_UPoutlier','AATGC5PAG_UPoutlier',\n",
    "    #                    'AATSOT5PG_UPoutlier','AHTSOT5PHG_UPoutlier','AATCOT5PAG_UPoutlier','AHTGD5PHG_LOWoutlier']\n",
    "    #drop_outlier_feats = [col for col in outlier_feats if col not in outlier_feat_keep  ]\n",
    "    others_to_drop = ['Div', 'FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'AC', 'HY',\n",
    "                      'AwayCapacityDiff', 'AwayFTR']  # ,'AwayCapacityDiff_bin','Dist>=100','cluster_2',\n",
    "    #                 'bxcx_AHTGC5PG','bxcx_AATGC5PG','bxcx_AHTSOT5PG','AHTGC5PG_upqrt','AHTGC5PG_lowqrt','AATGC5PG_upqrt',\n",
    "    #                  'AATGC5PG_lowqrt','AwayFTR']\n",
    "    #drop_others = [col for col in others_to_drop if col not in non_sig or col not in drop_outlier_feats]\n",
    "    # all features to drop\n",
    "    transformed = [col for col in away_df.columns if 'TRANSFORM' in col]\n",
    "    combined_feats = non_sig + others_to_drop + transformed\n",
    "    # drop features\n",
    "    drop_df = away_df.drop(columns=combined_feats)\n",
    "\n",
    "    return drop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.852444Z",
     "start_time": "2021-04-08T08:13:31.837444Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_away_train_features_with_drop_transformed():\n",
    "    \"\"\" loads away training features with uncorrelated/unassociated features dropped and with continuous transformations\"\"\"\n",
    "    away_df = load_away_train_df_transformed()\n",
    "    non_sig = ['HF', 'AF', 'HC', 'AY', 'HR', 'AR', 'AHTGS_SOT5PG_ratio_quantileTRANSFORM', 'AHTGS_SOT5PHG_ratio_bxcx_pwrTRANSFORM',\n",
    "               'AATGS5PG_LOWoutlier', 'AHTGC5PG_LOWoutlier', 'AATGC5PG_UPoutlier', 'AATGC5PAG_UPoutlier', 'AHTSOT5PG_LOWoutlier',\n",
    "               'AATSOT5PG_LOWoutlier', 'AATSOT5PAG_LOWoutlier', 'AHTGS_SOT5PG_ratio_UPoutlier', 'AATGS_SOT5PG_ratio_UPoutlier',\n",
    "               'AHTGS_SOT5PHG_ratio_UPoutlier', 'AATGS_SOT5PAG_ratio_UPoutlier', 'AHTGD5PG_LOWoutlier', 'AATGD5PG_LOWoutlier',\n",
    "               'AATGD5PAG_LOWoutlier', 'AwayTeamDist_quantileTRANSFORM', 'AwayTeamDist_bin_quantileTRANSFORM', 'Local_Derby',\n",
    "               'Dist>=100', 'AHTGS5PG_upqrt_AATGC5PG_lowqrt', 'AATGS5PG_upqrt_AHTGC5PG_lowqrt']\n",
    "    #outlier_feats = [col for col in away_df.columns if 'outlier' in col]\n",
    "    # outlier_feat_keep = ['AATGS5PG_UPoutlier','AHTGC5PG_UPoutlier','AATGS5PAG_UPoutlier','AHTGC5PHG_UPoutlier','AATGC5PAG_UPoutlier',\n",
    "    #                    'AATSOT5PG_UPoutlier','AHTSOT5PHG_UPoutlier','AATCOT5PAG_UPoutlier','AHTGD5PHG_LOWoutlier']\n",
    "    #drop_outlier_feats = [col for col in outlier_feats if col not in outlier_feat_keep  ]\n",
    "    others_to_drop = ['Div', 'FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'AC', 'HY',\n",
    "                      'AwayCapacityDiff', 'AwayFTR']  # ,'AwayCapacityDiff_bin','Dist>=100','cluster_2',\n",
    "    #                 'bxcx_AHTGC5PG','bxcx_AATGC5PG','bxcx_AHTSOT5PG','AHTGC5PG_upqrt','AHTGC5PG_lowqrt','AATGC5PG_upqrt',\n",
    "    #                  'AATGC5PG_lowqrt','AwayFTR']\n",
    "    #drop_others = [col for col in others_to_drop if col not in non_sig or col not in drop_outlier_feats]\n",
    "    # all features to drop\n",
    "    #transformed = [col for col in away_df.columns if 'TRANSFORM' in col]\n",
    "    combined_feats = non_sig + others_to_drop\n",
    "    # drop features\n",
    "    drop_df = away_df.drop(columns=combined_feats)\n",
    "\n",
    "    return drop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:13:31.870297Z",
     "start_time": "2021-04-08T08:13:31.853458Z"
    }
   },
   "outputs": [],
   "source": [
    "def sequential_forward_feature_selection(model, dataframe, sampling=None, combined_sampling=None):\n",
    "    \"\"\" Classification \"\"\"\n",
    "\n",
    "    feats, targ = load_data(dataframe)\n",
    "    feats, targ = shuffle(feats, targ, random_state=42)\n",
    "    remaining_features = list(feats.columns)\n",
    "    feature_list = []\n",
    "    best_subfeat_scores = None\n",
    "    best_score = None\n",
    "    for i in trange(1, len(feats.columns) + 1, desc='Feature round...'):\n",
    "        #print(f'\\nremaining features: {remaining_features}\\n')\n",
    "        top_round_feat = None\n",
    "        top_round_scores = None\n",
    "        for rf in remaining_features:\n",
    "            # select features to score & one hot encode\n",
    "            if len(feature_list) == 0:\n",
    "                sub_feats = feats[rf]\n",
    "                if sub_feats.dtype == 'O':\n",
    "                    sub_feats = pd.get_dummies(sub_feats)\n",
    "                else:\n",
    "                    sub_feats = np.array(sub_feats).reshape(-1, 1)\n",
    "            else:\n",
    "                sub_feats = pd.concat([feats[feature_list], feats[rf]], axis=1)\n",
    "                if 'O' in sub_feats.dtypes.tolist():\n",
    "                    sub_feats = pd.get_dummies(sub_feats)\n",
    "\n",
    "            # initiate pipeline - scale, sampling - if needed, model\n",
    "            if sampling is not None and combined_sampling is None:\n",
    "                pipe = Pipeline(\n",
    "                    steps=[\n",
    "                        ('scaler', StandardScaler(with_mean=False)),\n",
    "                        ('sampling', sampling),\n",
    "                        ('model', model)\n",
    "                    ]\n",
    "                )\n",
    "            elif sampling is not None and combined_sampling is not None:\n",
    "                pipe = Pipeline(\n",
    "                    steps=[\n",
    "                        ('scaler', StandardScaler(with_mean=False)),\n",
    "                        ('sampling', sampling),\n",
    "                        ('combo sampling', combined_sampling),\n",
    "                        ('model', model)\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                pipe = Pipeline(\n",
    "                    steps=[\n",
    "                        ('scaler', StandardScaler(with_mean=False)),\n",
    "                        ('model', model)\n",
    "                    ]\n",
    "                )\n",
    "            # evaluate sub_feats with model\n",
    "            scores = evaluate_model(sub_feats, targ, pipe)\n",
    "            current_score = np.mean(scores)\n",
    "            # assert (current_score == np.nan), f'Model evaluation: {current_score}\\nFunction will not work correctly if a subset feature score is nan, check terminal or increase verbosity of cv to find where the problem is'  ######\n",
    "            # keep best score, feature & scores\n",
    "            if best_score is not None:\n",
    "                if current_score > best_score:\n",
    "                    best_score = current_score\n",
    "                    top_round_feat = rf\n",
    "                    top_round_scores = scores\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                best_score = current_score\n",
    "                top_round_feat = rf\n",
    "                top_round_scores = scores\n",
    "\n",
    "            #print(f'top round feat: {top_round_feat}')\n",
    "            #print(f'best score: {best_score}')\n",
    "\n",
    "        # update best scores\n",
    "        if top_round_scores is not None:\n",
    "            best_subfeat_scores = top_round_scores\n",
    "        # update best features\n",
    "        if top_round_feat is not None:\n",
    "            feature_list.append(top_round_feat)\n",
    "            # remove best round feature from next round\n",
    "            remaining_features.remove(top_round_feat)\n",
    "        else:\n",
    "            # if no feature improved the model we break and finish\n",
    "            print('Optimal features reached......\\n\\n')\n",
    "            break\n",
    "\n",
    "    # print model, best features, score and standard deviation\n",
    "    print(f'{model}\\n\\nBest Features:\\n{feature_list}\\n\\nScore: {np.mean(best_subfeat_scores)}        Std: {np.std(best_subfeat_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ml_models():\n",
    "    \"\"\" models for testing \"\"\"\n",
    "    models, names = list(), list()\n",
    "\n",
    "    models.append(LogisticRegression(solver='liblinear',\n",
    "                                     class_weight='balanced', random_state=42))\n",
    "    names.append('LR')\n",
    "\n",
    "    #models.append(NuSVC(random_state = 42))\n",
    "    # names.append('NuSVC')\n",
    "\n",
    "    models.append(KNeighborsClassifier(n_neighbors=5, n_jobs=-1))\n",
    "    names.append('KNN')\n",
    "\n",
    "    models.append(DecisionTreeClassifier(class_weight='balanced',\n",
    "                                         max_features='sqrt', random_state=42))\n",
    "    names.append('DT')\n",
    "\n",
    "    models.append(RandomForestClassifier(n_estimators=200,\n",
    "                                         class_weight='balanced', max_features='sqrt', n_jobs=-1, random_state=42))\n",
    "    names.append('RF')\n",
    "\n",
    "    models.append(GradientBoostingClassifier(\n",
    "        n_estimators=200, max_features='sqrt', random_state=42))\n",
    "    names.append('GB')\n",
    "\n",
    "    models.append(AdaBoostClassifier(n_estimators=100, random_state=42))\n",
    "    names.append('AB')\n",
    "\n",
    "    models.append(GaussianNB())\n",
    "    names.append('GNB')\n",
    "\n",
    "    models.append(ComplementNB())\n",
    "    names.append('CNB')\n",
    "\n",
    "    models.append(XGBClassifier(n_estimators=200, max_depth=3,\n",
    "                                use_label_encoder=False, random_state=42))\n",
    "    names.append('XGB')\n",
    "\n",
    "    models.append(XGBRFClassifier(\n",
    "        n_estimators=200, max_depth=3, random_state=42))\n",
    "    names.append('XGBRF')\n",
    "\n",
    "    return models, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T11:42:03.627150Z",
     "start_time": "2021-03-16T11:42:03.621209Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_us_models():\n",
    "    \"\"\" undersamplng models \"\"\"\n",
    "    models, names = list(), list()\n",
    "\n",
    "    models.append(TomekLinks())\n",
    "    names.append('TL')\n",
    "\n",
    "    models.append(EditedNearestNeighbours())\n",
    "    names.append('ENN')\n",
    "\n",
    "    models.append(RepeatedEditedNearestNeighbours())\n",
    "    names.append('RENN')\n",
    "\n",
    "    models.append(OneSidedSelection())\n",
    "    names.append('OSS')\n",
    "\n",
    "    models.append(NeighbourhoodCleaningRule())\n",
    "    names.append('NCR')\n",
    "\n",
    "    models.append(InstanceHardnessThreshold())\n",
    "    names.append('IHT')\n",
    "\n",
    "    models.append(SMOTEENN(enn=EditedNearestNeighbours(\n",
    "        sampling_strategy='majority')))\n",
    "    names.append('S(ENN)')\n",
    "\n",
    "    models.append(NearMiss(version=1, n_neighbors=3))\n",
    "    names.append('NM1')\n",
    "\n",
    "    models.append(NearMiss(version=2, n_neighbors=3))\n",
    "    names.append('NM2')\n",
    "\n",
    "    models.append(NearMiss(version=3, n_neighbors_ver3=3))\n",
    "    names.append('NM3')\n",
    "\n",
    "    return models, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_gb_setup():\n",
    "    gb_model = GradientBoostingClassifier(random_state=42)\n",
    "    home_train_features = load_home_train_features_with_drop()\n",
    "    gb_feats = home_train_features[['AHTGC5PHG', 'AHTSOT5PG', 'AATSOT5PG', 'AHTSOT5PHG', 'AATGS_SOT5PAG_ratio', 'AATGD5PAG',\n",
    "                                    'season_month', 'HA_ATP5PG_diff', 'AwayCapacityDiff_bin', 'HT_PrevSeasonPos_inv',\n",
    "                                    'AT_PrevSeasonPos_inv', 'bxcx_AHTSOT5PG', 'bxcx_AATGC5PG']]\n",
    "    gb_svms = SVMSMOTE(random_state=1)\n",
    "    gb_name = 'GB'\n",
    "    return gb_model, gb_feats, gb_svms, gb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_gnb_setup():\n",
    "    gnb_model = GaussianNB()\n",
    "    home_train_features = load_home_train_features_with_drop_transformed()\n",
    "    gnb_feats = home_train_features[['AwayCapacityDiff_bin_quantileTRANSFORM', 'HT_PrevSeasonPos_inv',\n",
    "                                     'HA_ATP5PG_diff_quantileTRANSFORM', 'AATSOT5PAG_bxcx_pwrTRANSFORM', 'season_month_sin',\n",
    "                                     'AHTGC5PG_UPoutlier', 'AT_PrevSeasonPos_inv', 'season_month']]\n",
    "    gnb_pca = PCA(n_components=7, whiten=True)\n",
    "    gnb_name = 'GNB'\n",
    "    return gnb_model, gnb_feats, gnb_pca, gnb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def away_ab_setup():\n",
    "    ab_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "    away_train_features = load_away_train_features_with_drop()\n",
    "    ab_feats = away_train_features[['AHTGC5PHG', 'AATGC5PAG', 'AATSOT5PG', 'AHTP5PHG', 'month', 'year', 'AATGS_SOT5PG_ratio',\n",
    "                                    'AATGS_SOT5PAG_ratio', 'AHTGD5PG', 'AATGD5PG', 'HA_AHTGS5PG_diff', 'AHT_GS_P5PG_ratio',\n",
    "                                    'AAT_GS_P5PG_ratio', 'AwayCapacityDiff_bin', 'HT_PrevSeasonPos_inv', 'AT_PrevSeasonPos_inv',\n",
    "                                    'bxcx_AHTGS5PG', 'bxcx_AHTGC5PG', 'bxcx_AHTSOT5PG', 'bxcx_AATSOT5PG']]\n",
    "    ab_svms = SVMSMOTE(random_state=1)\n",
    "    ab_name = 'AB'\n",
    "    return ab_model, ab_feats, ab_svms, ab_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def away_lgbm_setup():\n",
    "    lgbm_model = LGBMClassifier(n_estimators=200,\n",
    "                                learning_rate=0.1,\n",
    "                                objective='binary',\n",
    "                                max_depth=3,\n",
    "                                n_jobs=-1,\n",
    "                                random_state=42)\n",
    "    away_train_features = load_away_train_features_with_drop()\n",
    "    lgbm_feats = away_train_features[['AHTGS5PG', 'AHTGC5PG', 'AHTSOT5PHG', 'AATSOT5PAG', 'AHTP5PHG', 'AHTGD5PG',\n",
    "                                      'HA_AHTGS5PG_diff', 'HA_ATP5PG_diff', 'AHT_GS_P5PG_ratio', 'AwayCapacityDiff_bin',\n",
    "                                      'HT_PrevSeasonPos_inv', 'AT_PrevSeasonPos_inv']]\n",
    "    lgbm_name = 'LGBM'\n",
    "    return lgbm_model, lgbm_feats, lgbm_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T12:47:54.666484Z",
     "start_time": "2021-03-16T12:47:54.661483Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_os_models():\n",
    "    \"\"\" oversampling models \"\"\"\n",
    "    models, names = list(), list()\n",
    "\n",
    "    models.append(SMOTE())\n",
    "    names.append('S')\n",
    "\n",
    "    models.append(BorderlineSMOTE())\n",
    "    names.append('BS')\n",
    "\n",
    "    models.append(SVMSMOTE())\n",
    "    names.append('SVMS')\n",
    "\n",
    "    # models.append(ADASYN(sampling_strategy='minority'))\n",
    "    # names.append('AS')\n",
    "\n",
    "    # models.append(KMeansSMOTE())\n",
    "    # names.append('KMS')\n",
    "\n",
    "    return models, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T08:37:13.893367Z",
     "start_time": "2021-04-07T08:37:13.875446Z"
    }
   },
   "outputs": [],
   "source": [
    "# weighted average functions\n",
    "\n",
    "def ensemble_predictions(models, weights, test_features):\n",
    "    \"\"\"\n",
    "    make ensemble predictions, returns prediction\n",
    "    parameters:\n",
    "        models = list of models/pipes to include in ensemble\n",
    "        weights = array of weights to use for predictions\n",
    "        test_features = list of test features for each model included.. must be in same order\n",
    "\n",
    "    returns:\n",
    "        predicted classes, predicted probabilities for success, i.e label 1\n",
    "    \"\"\"\n",
    "    # model predictions.. probs\n",
    "    yhat_probs = [models[i].predict_proba(test_features)[:, 1] for i in range(\n",
    "        len(models))]  # probabilities for class 1\n",
    "    yhat_probs = np.array(yhat_probs)\n",
    "    # weighted sum across models.. probabilities of the weighted models\n",
    "    # summed products of probabilities & weights\n",
    "    weighted_probs = np.tensordot(yhat_probs, weights, axes=((0), (0)))\n",
    "    # get weighted predicted classes\n",
    "    # round probabilities to classes.. 0 or 1\n",
    "    yhat_classes = np.round(weighted_probs)\n",
    "    # turn floats values to intergers\n",
    "    yhat_classes = np.array([int(x) for x in yhat_classes])\n",
    "    return yhat_classes, weighted_probs\n",
    "\n",
    "\n",
    "def evaluate_ensemble(models, weights, test_features, test_target):\n",
    "    \"\"\"returns predicted classes, success probabilities and metric evaluation for models\"\"\"\n",
    "    # predictions\n",
    "    yhat, probs = ensemble_predictions(models, weights, test_features)\n",
    "    # calculate fbeta loss\n",
    "    return yhat, probs, fbeta(test_target, yhat)\n",
    "\n",
    "\n",
    "def normalise(weights):\n",
    "    \"\"\"normalises weight vector to have unit norm, returns normalised weight vector\"\"\"\n",
    "    # l1 vector norm\n",
    "    result = np.linalg.norm(weights, 1)\n",
    "    # check for vector of all 0's\n",
    "    if result == 0.0:\n",
    "        return weights\n",
    "    return weights / result\n",
    "\n",
    "\n",
    "def loss_function(weights, models, test_features, test_target):\n",
    "    \"\"\"loss function for optimisation, designed to be minimised\"\"\"\n",
    "    # normalise weights\n",
    "    norm_weights = normalise(weights)\n",
    "    # calculate error\n",
    "    _, _, score = evaluate_ensemble(\n",
    "        models, norm_weights, test_features, test_target)\n",
    "    return 1.0 - score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cluster_features():\n",
    "    return pd.read_csv('cluster_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cluster1_target():\n",
    "    return pd.read_csv('cluster_1_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cluster3_target():\n",
    "    return pd.read_csv('cluster_3_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T08:52:16.543489Z",
     "start_time": "2021-04-07T08:52:16.538501Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cluster_test_feats():\n",
    "    return pd.read_csv('cluster_test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cluster_models():\n",
    "    \"\"\" models for testing \"\"\"\n",
    "    models, names = list(), list()\n",
    "\n",
    "    models.append(KNeighborsClassifier(n_neighbors=5, n_jobs=-1))\n",
    "    names.append('KNN')\n",
    "\n",
    "    models.append(DecisionTreeClassifier(class_weight='balanced',\n",
    "                                         max_features='sqrt', random_state=42))\n",
    "    names.append('DT')\n",
    "\n",
    "    models.append(RandomForestClassifier(n_estimators=200,\n",
    "                                         class_weight='balanced', max_features='sqrt', n_jobs=-1, random_state=42))\n",
    "    names.append('RF')\n",
    "\n",
    "    models.append(GradientBoostingClassifier(n_estimators=200,\n",
    "                                             learning_rate=0.1, max_features='sqrt', random_state=42))\n",
    "    names.append('GB')\n",
    "\n",
    "    models.append(AdaBoostClassifier(n_estimators=100, random_state=42))\n",
    "    names.append('AB')\n",
    "\n",
    "    models.append(XGBClassifier(n_estimators=200, learning_rate=0.1,\n",
    "                                max_depth=3, use_label_encoder=False, random_state=42))\n",
    "    names.append('XGB')\n",
    "\n",
    "    models.append(CatBoostClassifier(n_estimators=500, learning_rate=0.1,\n",
    "                                     max_depth=6, auto_class_weights='Balanced', random_seed=42))\n",
    "    names.append('CBC')\n",
    "\n",
    "    models.append(LGBMClassifier(objective='binary', n_estimators=200,\n",
    "                                 learning_rate=0.1, max_depth=3, is_unbalance=True, random_state=42))\n",
    "    names.append('LGBM')\n",
    "\n",
    "    return models, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OHETeamTransformer():\n",
    "    \"\"\" \n",
    "    custom transformer that one hot encodes football teams\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def team_ohe(self, team):\n",
    "        \"\"\" \n",
    "        one hot encodes team\n",
    "\n",
    "        params:\n",
    "            team = string name of team\n",
    "\n",
    "        returns either array of ohe values for selected team or error for spelling\n",
    "        \"\"\"\n",
    "        ohe_df = pd.read_csv('ohe_teams.csv')\n",
    "        if team in ohe_df.columns:\n",
    "            return ohe_df[team].values\n",
    "        else:\n",
    "            return \"Cannot find team, please check spelling including capitals\"\n",
    "\n",
    "    def football_data_team_ohe(self, data):\n",
    "        \"\"\"\n",
    "        one hot encodes football teams in data\n",
    "\n",
    "        params:\n",
    "            data = main football data\n",
    "\n",
    "        returns new dataframe with encoded football teams\n",
    "        \"\"\"\n",
    "        footy_data = data.copy()\n",
    "        if sorted(data['HomeTeam'].value_counts().index) == sorted(data['AwayTeam'].value_counts().index):\n",
    "            all_teams = sorted(footy_data['HomeTeam'].value_counts().index)\n",
    "            # one hot encode home team\n",
    "            all_home_teams = [f'home_{t}' for t in all_teams]\n",
    "            home_teams = pd.DataFrame(0, index=range(\n",
    "                0, len(footy_data)), columns=all_home_teams)\n",
    "\n",
    "            for team in all_teams:\n",
    "                if team in footy_data['HomeTeam'].values:\n",
    "                    mask = footy_data['HomeTeam'] == team\n",
    "                    mask_idx = mask[mask].index.values\n",
    "                    ohe_vals = team_ohe(team)\n",
    "                    for i in range(0, len(mask_idx)):\n",
    "                        home_teams.loc[mask_idx[i]] = ohe_vals\n",
    "\n",
    "            for col in home_teams:\n",
    "                footy_data = footy_data.join(home_teams[col])\n",
    "            # remove original home team data\n",
    "            footy_data.drop(columns='HomeTeam', inplace=True)\n",
    "\n",
    "            # one hot encode away team\n",
    "            all_away_teams = [f'away_{t}' for t in all_teams]\n",
    "            away_teams = pd.DataFrame(0, index=range(\n",
    "                0, len(footy_data)), columns=all_away_teams)\n",
    "\n",
    "            for team in all_teams:\n",
    "                if team in footy_data['AwayTeam'].values:\n",
    "                    mask = footy_data['AwayTeam'] == team\n",
    "                    mask_idx = mask[mask].index.values\n",
    "                    ohe_vals = team_ohe(team)\n",
    "                    for i in range(0, len(mask_idx)):\n",
    "                        away_teams.loc[mask_idx[i]] = ohe_vals\n",
    "\n",
    "            for col in away_teams:\n",
    "                footy_data = footy_data.join(away_teams[col])\n",
    "            # remove original away team data\n",
    "            footy_data.drop(columns='AwayTeam', inplace=True)\n",
    "            return footy_data\n",
    "        else:\n",
    "            return 'Mismatch between home and away teams.'\n",
    "\n",
    "    def transform(self, data, **transform_params):\n",
    "        ohe_df = football_data_team_ohe(data)\n",
    "        return ohe_df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prfs(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bal_acc(y_true, y_pred):\n",
    "    return balanced_accuracy_score(y_true, y_pred, adjusted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cluster_model(features, target, model, k_splits=10):\n",
    "    cv = RepeatedStratifiedKFold(\n",
    "        n_splits=k_splits, n_repeats=2, random_state=1)\n",
    "    # evaluation scoring metric\n",
    "    metric = make_scorer(f1)\n",
    "    scores = cross_val_score(model, features, target,\n",
    "                             scoring=metric, cv=cv, n_jobs=-1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cluster1_features():\n",
    "    train_features = pd.read_csv('cluster1_train_features.csv')\n",
    "    test_features = pd.read_csv('cluster1_test_features.csv')\n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cluster1_targets():\n",
    "    train_target = pd.read_csv('cluster1_train_target.csv')\n",
    "    test_target = pd.read_csv('cluster1_test_target.csv')\n",
    "    return train_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cluster3_targets():\n",
    "    train_target = pd.read_csv('cluster3_train_target.csv')\n",
    "    test_target = pd.read_csv('cluster3_test_target.csv')\n",
    "    return train_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cluster3_features():\n",
    "    train_features = pd.read_csv('cluster3_train_features.csv')\n",
    "    test_features = pd.read_csv('cluster3_test_features.csv')\n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T10:07:51.590987Z",
     "start_time": "2021-04-07T10:07:51.570770Z"
    }
   },
   "outputs": [],
   "source": [
    "def expected_profit(cm_matrix, cb_matrix, pos_prior):\n",
    "    \"\"\" calculates expected profit \"\"\"\n",
    "    neg_prior = 1 - pos_prior\n",
    "    #total = cm_matrix[0][0] + cm_matrix[0][1] + cm_matrix[1][0] + cm_matrix[1][1]\n",
    "    total_pos = cm_matrix[1][0] + cm_matrix[1][1]\n",
    "    total_neg = cm_matrix[0][0] + cm_matrix[0][1]\n",
    "    # confucion matrix error rates\n",
    "    tn_rate = cm_matrix[0][0] / total_neg\n",
    "    fp_rate = cm_matrix[0][1] / total_neg\n",
    "    fn_rate = cm_matrix[1][0] / total_pos\n",
    "    tp_rate = cm_matrix[1][1] / total_pos\n",
    "\n",
    "    exp_profit = (pos_prior * (tp_rate * cb_matrix[1][1] + fn_rate * cb_matrix[1][0])) + (\n",
    "        neg_prior * (tn_rate * cb_matrix[0][0] + fp_rate * cb_matrix[0][1]))\n",
    "    return np.round(exp_profit, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_lr_setup():\n",
    "    # instantiate model\n",
    "    lr_model = LogisticRegression(\n",
    "        penalty='l1',\n",
    "        solver='liblinear',\n",
    "        C=0.13916392773859043,\n",
    "        max_iter=130,\n",
    "        tol=1.0683985965344678,\n",
    "        class_weight=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    # load train features, keep model features\n",
    "    home_train_features = load_home_train_features_with_drop_transformed()\n",
    "    lr_feats = home_train_features[['AHTGS5PG_UPoutlier', 'AHTGS5PHG_UPoutlier', 'AATGS5PAG_UPoutlier', 'AHTSOT5PG_UPoutlier',\n",
    "                                    'AATSOT5PG_UPoutlier', 'AHTSOT5PHG_UPoutlier', 'AHTGD5PHG_UPoutlier', 'HT_PrevSeasonPos_inv',\n",
    "                                    'AT_PrevSeasonPos_inv', 'HA_AHTGS5PG_diff_lowqrt', 'AHTGS5PG_upqrt_AATGC5PG_lowqrt',\n",
    "                                    'AHTSOT5PG_bxcx_pwrTRANSFORM', 'AATSOT5PG_bxcx_pwrTRANSFORM', 'AHTGD5PG_quantileTRANSFORM',\n",
    "                                    'AATGD5PG_quantileTRANSFORM', 'AwayCapacityDiff_bin_quantileTRANSFORM',\n",
    "                                    'bxcx_AHTSOT5PG_quantileTRANSFORM', 'bxcx_AATSOT5PG_quantileTRANSFORM',\n",
    "                                    'bxcx_AAT_GS_P5PG_ratio_quantileTRANSFORM']]\n",
    "    # load test features, keep model features\n",
    "    test_features = load_test_features()\n",
    "    lr_test_feats = test_features[['AHTGS5PG_UPoutlier', 'AHTGS5PHG_UPoutlier', 'AATGS5PAG_UPoutlier', 'AHTSOT5PG_UPoutlier',\n",
    "                                   'AATSOT5PG_UPoutlier', 'AHTSOT5PHG_UPoutlier', 'AHTGD5PHG_UPoutlier', 'HT_PrevSeasonPos_inv',\n",
    "                                   'AT_PrevSeasonPos_inv', 'HA_AHTGS5PG_diff_lowqrt', 'AHTGS5PG_upqrt_AATGC5PG_lowqrt',\n",
    "                                   'AHTSOT5PG_bxcx_pwrTRANSFORM', 'AATSOT5PG_bxcx_pwrTRANSFORM', 'AHTGD5PG_quantileTRANSFORM',\n",
    "                                   'AATGD5PG_quantileTRANSFORM', 'AwayCapacityDiff_bin_quantileTRANSFORM',\n",
    "                                   'bxcx_AHTSOT5PG_quantileTRANSFORM', 'bxcx_AATSOT5PG_quantileTRANSFORM',\n",
    "                                   'bxcx_AAT_GS_P5PG_ratio_quantileTRANSFORM']]\n",
    "    # instantiate pca and near miss undersampling\n",
    "    lr_pca = PCA(n_components=12, whiten=True)\n",
    "    lr_nm3 = NearMiss(version=3, n_neighbors=3, n_neighbors_ver3=3, n_jobs=-1)\n",
    "    lr_name = 'LR'\n",
    "    # create pipeline\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "    cal_lr_pipe = IMBPipeline(\n",
    "        steps=[\n",
    "            ('transformer', KeepColumnsTransformer(lr_feats.columns)),\n",
    "            ('scaler', RobustScaler(with_centering=False)),\n",
    "            ('sampling', lr_nm3),\n",
    "            ('pca', lr_pca),\n",
    "            ('model', CalibratedClassifierCV(lr_model, cv=cv, method='sigmoid'))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    lr_pipe = IMBPipeline(\n",
    "        steps=[\n",
    "            ('transformer', KeepColumnsTransformer(lr_feats.columns)),\n",
    "            ('scaler', RobustScaler(with_centering=False)),\n",
    "            ('sampling', lr_nm3),\n",
    "            ('pca', lr_pca),\n",
    "            ('model', lr_model)\n",
    "        ]\n",
    "    )\n",
    "    return lr_pipe, cal_lr_pipe, lr_test_feats, lr_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_xgb_setup():\n",
    "    # instantiate model\n",
    "    xgb_model = XGBClassifier(n_estimators=320,\n",
    "                              learning_rate=0.0488938809129075,\n",
    "                              max_depth=3,\n",
    "                              min_child_weight=8,\n",
    "                              gamma=0.6936419289666603,\n",
    "                              scale_pos_weight=1,\n",
    "                              colsample_bytree=0.5920903811620744,\n",
    "                              subsample=0.8374088758397853,\n",
    "                              reg_alpha=0.07425990654719038,\n",
    "                              reg_lambda=0.16768800738594583,\n",
    "                              use_label_encoder=False,\n",
    "                              n_jobs=-1,\n",
    "                              verbosity=0,\n",
    "                              random_state=42)\n",
    "    # load train_features & keep model features\n",
    "    home_train_features = load_home_train_features_with_drop()\n",
    "    xgb_feats = home_train_features[['AHTSOT5PG', 'AATSOT5PG', 'AATGD5PAG', 'season_month_sin', 'season_month_cos',\n",
    "                                     'HA_ATP5PG_diff', 'AwayCapacityDiff_bin', 'cluster_3', 'HT_PrevSeasonPos_inv',\n",
    "                                     'AT_PrevSeasonPos_inv', 'HT_GSGC_UPLOW_QRT', 'AHTGC5PG_upqrt_AATGC5PG_lowqrt']]\n",
    "    # predict cluster 3 for test features\n",
    "    test_cl_feats = load_cluster_test_feats()\n",
    "    gb_cl3_model = joblib.load('cl3_gb_model.sav')\n",
    "    gb_pred = gb_cl3_model.predict(test_cl_feats)\n",
    "    # load test features, add cluster 3 prediction, keep model features\n",
    "    test_features = load_test_features()\n",
    "    test_features['cluster_3'] = gb_pred\n",
    "    xgb_test_feats = test_features[['AHTSOT5PG', 'AATSOT5PG', 'AATGD5PAG', 'season_month_sin', 'season_month_cos',\n",
    "                                    'HA_ATP5PG_diff', 'AwayCapacityDiff_bin', 'cluster_3', 'HT_PrevSeasonPos_inv',\n",
    "                                    'AT_PrevSeasonPos_inv', 'HT_GSGC_UPLOW_QRT', 'AHTGC5PG_upqrt_AATGC5PG_lowqrt']]\n",
    "    # instantiate oversampling method\n",
    "    xgb_bsmote = BorderlineSMOTE(\n",
    "        k_neighbors=12, m_neighbors=20, kind='borderline-1', random_state=1, n_jobs=-1)\n",
    "    xgb_name = 'XGB'\n",
    "    # creat pipeline\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "    xgb_pipe = IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(xgb_feats.columns)),\n",
    "            ('scaler', StandardScaler(with_mean=False, with_std=True)),\n",
    "            ('os', xgb_bsmote),\n",
    "            ('model', xgb_model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cal_xgb_pipe = IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(xgb_feats.columns)),\n",
    "            ('scaler', StandardScaler(with_mean=False, with_std=True)),\n",
    "            ('os', xgb_bsmote),\n",
    "            ('model', CalibratedClassifierCV(xgb_model, cv=cv, method='sigmoid'))\n",
    "        ]\n",
    "    )\n",
    "    return xgb_pipe, cal_xgb_pipe, xgb_test_feats, xgb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def away_gb_setup():\n",
    "    # instantiate model\n",
    "    gb_model = GradientBoostingClassifier(n_estimators=650,\n",
    "                                          learning_rate=0.027115584500934167,\n",
    "                                          max_depth=3,\n",
    "                                          max_features=8,\n",
    "                                          min_samples_leaf=420,\n",
    "                                          min_samples_split=675,\n",
    "                                          subsample=0.43918481213848615,\n",
    "                                          #ccp_alpha =  1.1243946224171244,\n",
    "                                          random_state=42)\n",
    "    # load train features & keep model features\n",
    "    away_train_features = load_away_train_features_with_drop()\n",
    "    gb_feats = away_train_features[['AHTGC5PHG', 'AATSOT5PG', 'AHTSOT5PHG', 'HA_AHTGS5PG_diff', 'AHT_GS_P5PG_ratio',\n",
    "                                    'AwayCapacityDiff_bin', 'cluster_1', 'cluster_3', 'HT_PrevSeasonPos_inv',\n",
    "                                    'AT_PrevSeasonPos_inv', 'bxcx_AHTGC5PG', 'bxcx_AATSOT5PG', 'bxcx_AHT_GS_P5PG_ratio']]\n",
    "    # get predictions for cluster 1 & 3 features\n",
    "    test_cluster_feats = load_cluster_test_feats()\n",
    "    rf_cl1_model = joblib.load('cl1_rf_model.sav')\n",
    "    rf_pred = rf_cl1_model.predict(test_cluster_feats)\n",
    "    gb_cl3_model = joblib.load('cl3_gb_model.sav')\n",
    "    gb_pred = gb_cl3_model.predict(test_cluster_feats)\n",
    "    # load test features, add cluster 1 & 3 predictions, keep model features\n",
    "    test_features = load_test_features()\n",
    "    test_features['cluster_1'] = rf_pred\n",
    "    test_features['cluster_3'] = gb_pred\n",
    "    gb_test_feats = test_features[['AHTGC5PHG', 'AATSOT5PG', 'AHTSOT5PHG', 'HA_AHTGS5PG_diff', 'AHT_GS_P5PG_ratio',\n",
    "                                   'AwayCapacityDiff_bin', 'cluster_1', 'cluster_3', 'HT_PrevSeasonPos_inv',\n",
    "                                   'AT_PrevSeasonPos_inv', 'bxcx_AHTGC5PG', 'bxcx_AATSOT5PG', 'bxcx_AHT_GS_P5PG_ratio']]\n",
    "    # instantiate oversampling method\n",
    "    gb_adasyn = ADASYN(n_neighbors=6, random_state=1, n_jobs=-1)\n",
    "    gb_name = 'GB'\n",
    "    # creat pipeline\n",
    "    gb_pipe = IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(gb_feats.columns)),\n",
    "            ('scaler', StandardScaler(with_mean=False, with_std=True)),\n",
    "            ('os', gb_adasyn),\n",
    "            ('model', gb_model)\n",
    "        ]\n",
    "    )\n",
    "    return gb_pipe, gb_test_feats, gb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def away_xgb_setup():\n",
    "    # instantiate model\n",
    "    xgb_model = XGBClassifier(n_estimators=570,\n",
    "                              learning_rate=0.018277402480679054,\n",
    "                              max_depth=3,\n",
    "                              min_child_weight=10,\n",
    "                              gamma=0.6757959901913699,\n",
    "                              subsample=0.7962485851393263,\n",
    "                              colsample_bytree=0.5735095367483903,\n",
    "                              scale_pos_weight=1,\n",
    "                              reg_alpha=0.13029677939259385,\n",
    "                              reg_lambda=0.10315636718690373,\n",
    "                              use_label_encoder=False,\n",
    "                              n_jobs=-1,\n",
    "                              verbosity=0,\n",
    "                              random_state=42)\n",
    "    # load train features, keep model features\n",
    "    away_train_features = load_away_train_features_with_drop()\n",
    "    xgb_feats = away_train_features[['AHTGC5PG', 'AATP5PAG', 'DayofWeek', 'HA_ATP5PG_diff', 'cluster_1', 'HT_PrevSeasonPos_inv',\n",
    "                                     'AT_PrevSeasonPos_inv', 'HA_AHTGS5PG_diff_upqrt', 'AHTGC5PG_upqrt_AATGC5PG_lowqrt']]\n",
    "    # load test cluster features, get predictions for cluster 1 feature\n",
    "    test_cluster_feats = load_cluster_test_feats()\n",
    "    rf_cl1_model = joblib.load('cl1_rf_model.sav')\n",
    "    rf_pred = rf_cl1_model.predict(test_cluster_feats)\n",
    "    # load test features, add cluster 1 predictions, keep model features\n",
    "    test_features = load_test_features()\n",
    "    test_features['cluster_1'] = rf_pred\n",
    "    xgb_test_feats = test_features[['AHTGC5PG', 'AATP5PAG', 'DayofWeek', 'HA_ATP5PG_diff', 'cluster_1', 'HT_PrevSeasonPos_inv',\n",
    "                                    'AT_PrevSeasonPos_inv', 'HA_AHTGS5PG_diff_upqrt', 'AHTGC5PG_upqrt_AATGC5PG_lowqrt']]\n",
    "    # instantiate oversampling method\n",
    "    xgb_svms = SVMSMOTE(k_neighbors=8, m_neighbors=14,\n",
    "                        svm_estimator=SVC(), random_state=1, n_jobs=-1)\n",
    "    xgb_name = 'XGB'\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "    # creat pipeline\n",
    "    xgb_pipe = IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(xgb_feats.columns)),\n",
    "            ('scaler', StandardScaler(with_mean=False, with_std=True)),\n",
    "            ('os', xgb_svms),\n",
    "            ('model', xgb_model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cal_xgb_pipe = IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(xgb_feats.columns)),\n",
    "            ('scaler', StandardScaler(with_mean=False, with_std=True)),\n",
    "            ('os', xgb_svms),\n",
    "            ('model', CalibratedClassifierCV(xgb_model, cv=cv, method='sigmoid'))\n",
    "        ]\n",
    "    )\n",
    "    return xgb_pipe, cal_xgb_pipe, xgb_test_feats, xgb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def away_lgbm_setup():\n",
    "    lgbm_model = LGBMClassifier(n_estimators=470,\n",
    "                                learning_rate=0.04250057994580665,\n",
    "                                objective='binary',\n",
    "                                max_depth=4,\n",
    "                                num_leaves=35,\n",
    "                                min_child_samples=1320,\n",
    "                                colsample_bytree=0.7787949835735254,\n",
    "                                subsample=0.8073575692094029,\n",
    "                                reg_alpha=0.06951672237498768,\n",
    "                                reg_lambda=0.03784851967467663,\n",
    "                                is_unbalance=True,\n",
    "                                n_jobs=-1,\n",
    "                                random_state=42)\n",
    "    away_train_features = load_away_train_features_with_drop()\n",
    "    lgbm_feats = away_train_features[['AHTGS5PG', 'AHTGC5PG', 'AHTSOT5PHG', 'AATSOT5PAG', 'AHTP5PHG', 'AHTGD5PG',\n",
    "                                      'HA_AHTGS5PG_diff', 'HA_ATP5PG_diff', 'AHT_GS_P5PG_ratio', 'AwayCapacityDiff_bin',\n",
    "                                      'HT_PrevSeasonPos_inv', 'AT_PrevSeasonPos_inv']]\n",
    "    test_features = load_test_features()\n",
    "    lgbm_test_feats = test_features[['AHTGS5PG', 'AHTGC5PG', 'AHTSOT5PHG', 'AATSOT5PAG', 'AHTP5PHG', 'AHTGD5PG',\n",
    "                                     'HA_AHTGS5PG_diff', 'HA_ATP5PG_diff', 'AHT_GS_P5PG_ratio', 'AwayCapacityDiff_bin',\n",
    "                                     'HT_PrevSeasonPos_inv', 'AT_PrevSeasonPos_inv']]\n",
    "    lgbm_svms = SVMSMOTE(k_neighbors=3, m_neighbors=7,\n",
    "                         random_state=1, n_jobs=-1)\n",
    "    lgbm_name = 'LGBM'\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "    lgbm_pipe = IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(lgbm_feats.columns)),\n",
    "            ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
    "            ('os', lgbm_svms),\n",
    "            ('model', lgbm_model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cal_lgbm_pipe = IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(lgbm_feats.columns)),\n",
    "            ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
    "            ('os', lgbm_svms),\n",
    "            ('model', CalibratedClassifierCV(lgbm_model, cv=cv, method='sigmoid'))\n",
    "        ]\n",
    "    )\n",
    "    return lgbm_pipe, cal_lgbm_pipe, lgbm_test_feats, lgbm_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T10:09:09.164731Z",
     "start_time": "2021-04-07T10:09:09.158166Z"
    }
   },
   "outputs": [],
   "source": [
    "class KeepColumnsTransformer():\n",
    "    \"\"\" \n",
    "    custom transformer that keeps specified columns of dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        if len(self.columns) == 1:\n",
    "            drop_df = np.array(X[self.columns[0]].copy()).reshape(-1, 1)\n",
    "        else:\n",
    "            drop_df = X[self.columns].copy()\n",
    "        return drop_df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Data Cleansing --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T11:52:11.247911Z",
     "start_time": "2021-04-08T11:52:11.100274Z"
    }
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv(\"new_combined_leagues_avg_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove bookys odds..\n",
    "# remove referee.. high no. of nan values\n",
    "# models might rely on these columns too much, might benefit beating the bookys without these\n",
    "data.drop(columns=['Referee', 'LBH', 'LBD', 'LBA',\n",
    "                   'WHH', 'WHD', 'WHA'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove league 2 data\n",
    "data = data[data['Div'] != 'E3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nan Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing data\n",
    "null_data = data[data.isnull().any(axis=1)]\n",
    "null_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows from null data that contain 2 or less nan values\n",
    "# get rows from null data that contain more than 2 rows\n",
    "low_null_index = []\n",
    "high_null_index = []\n",
    "for row in range(len(null_data)):\n",
    "    if null_data.iloc[row, :].isna().sum() <= 2:\n",
    "        low_null_index.append(null_data.iloc[row, :].name)\n",
    "    elif null_data.iloc[row, :].isna().sum() > 2:\n",
    "        high_null_index.append(null_data.iloc[row, :].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows from data with high number of nan values\n",
    "#data.drop(labels = 'index', axis = 1, inplace = True)\n",
    "data.drop(labels=high_null_index, axis=0, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    data.iloc[:, :-1], data.iloc[:, -1], test_size=0.2, random_state=42, stratify=data['FTR'])\n",
    "train_features.reset_index(drop=True, inplace=True)\n",
    "train_target.reset_index(drop=True, inplace=True)\n",
    "test_features.reset_index(drop=True, inplace=True)\n",
    "test_target.reset_index(drop=True, inplace=True)\n",
    "# train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train features with nan values\n",
    "nan_cols = []\n",
    "for col in train_features:\n",
    "    if train_features[col].isnull().values.any():\n",
    "        nan_cols.append(col)\n",
    "\n",
    "print(nan_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train features for imputation re run\n",
    "train_features = pd.read_csv('combined_leagues_train features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# similarity impute train data\n",
    "num_cols = ['FTHG', 'AHTGS5PG', 'FTAG', 'AATGS5PG', 'AHTGC5PG', 'AATGC5PG', 'AHTGS5PHG',\n",
    "            'AATGS5PAG', 'AHTGC5PHG', 'AATGC5PAG', 'HS', 'AS', 'HST', 'AST', 'AHTSOT5PG',\n",
    "            'AATSOT5PG', 'AHTSOT5PHG', 'AATSOT5PAG', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY',\n",
    "            'HR', 'AR', 'AHTP5PG', 'AATP5PG', 'AHTP5PHG', 'AATP5PAG']\n",
    "\n",
    "# run similarity imputation on individual columns\n",
    "train_features_imputed, nan_values = similarity_imputation(\n",
    "    train_features_imputed, 'AATSOT5PAG', num_cols, missing_value='nan', dec_places=1, n_neighbours=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average stat for team in that season # 1359\n",
    "mask_df = train_features[train_features['HomeTeam'].str.contains('QPR') & train_features['Date'].str.contains('/02') & train_features['Div'].str.contains(\n",
    "    'E2') | train_features['HomeTeam'].str.contains('QPR') & train_features['Date'].str.contains('/03') & train_features['Div'].str.contains('E2')]\n",
    "mask_idx = []\n",
    "for i in range(len(mask_df)):\n",
    "    yr = int(mask_df.iloc[i, :]['Date'].split('/')[2])\n",
    "    mnth = int(mask_df.iloc[i, :]['Date'].split('/')[1])\n",
    "    if yr == int('02'):\n",
    "        if mnth >= int('08'):\n",
    "            mask_idx.append(i)\n",
    "    elif yr == int('03'):\n",
    "        if mnth <= int('04'):\n",
    "            mask_idx.append(i)\n",
    "mean = mask_df.iloc[mask_idx, :]['HS'].mean()\n",
    "mask = train_features[train_features['HS'].isnull()]['HomeTeam'] == 'QPR'\n",
    "mask_idx = mask[mask].index.values\n",
    "train_features.loc[mask_idx, 'HS'] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nans fromt test data\n",
    "test_nan_idx = test_features[test_features.isnull().any(axis=1)].index\n",
    "test_features.drop(labels=test_nan_idx, axis=0, inplace=True)\n",
    "test_target.drop(labels=test_nan_idx, inplace=True)\n",
    "test_features.reset_index(drop=True, inplace=True)\n",
    "test_target.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any duplicates\n",
    "train_features.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous outlier check\n",
    "train_features = load_train_features()\n",
    "outlier_dict = {}\n",
    "for col in train_features:\n",
    "    if train_features[col].dtype == 'int64' or train_features[col].dtype == 'float64':\n",
    "        stats = train_features[col].describe()\n",
    "        IQR = stats['75%'] - stats['25%']\n",
    "        upper = stats['75%'] + 1.5 * IQR\n",
    "        lower = stats['25%'] - 1.5 * IQR\n",
    "        lower_bound_outliers = train_features[train_features[col] < lower]\n",
    "        upper_bound_outliers = train_features[train_features[col] > upper]\n",
    "        # update dictionary\n",
    "        outlier_dict[col] = (upper, lower)\n",
    "        print('{}: {} upper outliers and {} lower outliers, bounds: upper bound = {}, lower bound = {}\\n'.format(\n",
    "            col, len(upper_bound_outliers), len(lower_bound_outliers), upper, lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save outlier dict for future use\n",
    "dict_file = open('outlier_dict.pkl', 'wb')\n",
    "pickle.dump(outlier_dict, dict_file)\n",
    "dict_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous histogram plots\n",
    "for col in train_features:\n",
    "    if train_features[col].dtype == 'int64' or train_features[col].dtype == 'float64':\n",
    "        train_features[col].hist(bins=100)\n",
    "        plt.title(f'{col} hist plot')\n",
    "        plt.xlabel(f'{col}')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no observational outliers, outliers within features can be put down to rare results that football throws out time to time and not errornous recorded observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarise target for home team win... H = 1, D & A = 0\n",
    "home_win_train_target = train_target.copy()\n",
    "home_win_test_target = test_target.copy()\n",
    "# train target\n",
    "h_idx = train_target[train_target == 'H'].index\n",
    "a_idx = train_target[train_target == 'A'].index\n",
    "d_idx = train_target[train_target == 'D'].index\n",
    "home_win_train_target[h_idx] = 1\n",
    "home_win_train_target[a_idx] = 0\n",
    "home_win_train_target[d_idx] = 0\n",
    "# test target\n",
    "h_idx = test_target[test_target == 'H'].index\n",
    "a_idx = test_target[test_target == 'A'].index\n",
    "d_idx = test_target[test_target == 'D'].index\n",
    "home_win_test_target[h_idx] = 1\n",
    "home_win_test_target[a_idx] = 0\n",
    "home_win_test_target[d_idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarise target for away team win... A = 1, D & H = 0\n",
    "away_win_train_target = train_target.copy()\n",
    "away_win_test_target = test_target.copy()\n",
    "# train target\n",
    "a_idx = train_target[train_target == 'A'].index\n",
    "h_idx = train_target[train_target == 'H'].index\n",
    "d_idx = train_target[train_target == 'D'].index\n",
    "away_win_train_target[a_idx] = 1\n",
    "away_win_train_target[h_idx] = 0\n",
    "away_win_train_target[d_idx] = 0\n",
    "# test target\n",
    "a_idx = test_target[test_target == 'A'].index\n",
    "h_idx = test_target[test_target == 'H'].index\n",
    "d_idx = test_target[test_target == 'D'].index\n",
    "away_win_test_target[a_idx] = 1\n",
    "away_win_test_target[h_idx] = 0\n",
    "away_win_test_target[d_idx] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Summary -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed 'Referee' feature as had a high number of nan values, also contains a high number of unique values and likely not to provide a great deal of information on the target.\n",
    "\n",
    "Bookmaker odds were also removed as didnt want these features to influence the models as the general idea is to use team and match variables to identify whether the home or away team are more likely to win. Ultimately the idea is to use team and match information to gain leverage over the bookmakers. Although this should come under review as bookmaker odds could provide latent information about the teams and matches being played, this will provide a good comparison for future analysis.\n",
    "\n",
    "A chunk of nan values were removed from the head of the data, these nan values were a result of averaging features from 5 previous games and as there are no previous games to take averages on they subsequently have nan value inputs. The data were also checked for rows containing more than 2 nan values and subsequently were removed, for rows containing 2 or less nan values similarity imputation was applied using euclidean distance and averages were imputed for team and features. For the test data rows containing nan values were removed.\n",
    "\n",
    "Description of data shows nothing unexpected.\n",
    "\n",
    "No observable outliers were found but using the interquartile range outliers are present in some features and will need to be addressed.\n",
    "\n",
    "Home win and away win targets have been engineered from the full time result with 1 representing win and 0 representing a draw or loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- EDA --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df = load_home_win_train_df()\n",
    "away_df = load_away_win_train_df()\n",
    "\n",
    "print('All Leagues:')\n",
    "ag_hw = home_df['HomeFTR'].value_counts()[1]\n",
    "ag_hnw = home_df['HomeFTR'].value_counts()[0]\n",
    "ag_aw = away_df['AwayFTR'].value_counts()[1]\n",
    "ag_anw = away_df['AwayFTR'].value_counts()[0]\n",
    "print(f'    Home Win Count:\\n        Win: {ag_hw}\\n       No Win: {ag_hnw}\\n')\n",
    "print(f'    Away Win Count:\\n        Win: {ag_aw}\\n       No Win: {ag_anw}\\n')\n",
    "ag_tot_games = ag_hw + ag_hnw\n",
    "ag_hw_perc = ag_hw / ag_tot_games\n",
    "ag_aw_perc = ag_aw / ag_tot_games\n",
    "print(\n",
    "    f'  All Leagues Since 00/01..  Home Win Percentage: {np.round(ag_hw_perc,2)}        Away Win Percentage: {np.round(ag_aw_perc,2)}\\n')\n",
    "\n",
    "print('Premier League:')\n",
    "prem_hw = len(home_df[(home_df['Div'] == 2) & (home_df['HomeFTR'] == 1)])\n",
    "prem_hnw = len(home_df[(home_df['Div'] == 2) & (home_df['HomeFTR'] == 0)])\n",
    "prem_aw = len(away_df[(away_df['Div'] == 2) & (away_df['AwayFTR'] == 1)])\n",
    "prem_anw = len(away_df[(home_df['Div'] == 2) & (away_df['AwayFTR'] == 0)])\n",
    "print(\n",
    "    f'    Prem Home Win Count:\\n        Win: {prem_hw}\\n       No Win: {prem_hnw}\\n')\n",
    "print(\n",
    "    f'    Prem Away Win Count:\\n        Win: {prem_aw}\\n       No Win: {prem_anw}\\n')\n",
    "prem_tot_games = prem_hw + prem_hnw\n",
    "prem_hw_perc = prem_hw / prem_tot_games\n",
    "prem_aw_perc = prem_aw / prem_tot_games\n",
    "print(\n",
    "    f'  Premier League Since 00,01..  Home Win Percentage: {np.round(prem_hw_perc,2)}        Away Win Percentage: {np.round(prem_aw_perc,2)}\\n')\n",
    "\n",
    "print('Championship:')\n",
    "champ_hw = len(home_df[(home_df['Div'] == 1) & (home_df['HomeFTR'] == 1)])\n",
    "champ_hnw = len(home_df[(home_df['Div'] == 1) & (home_df['HomeFTR'] == 0)])\n",
    "champ_aw = len(away_df[(away_df['Div'] == 1) & (away_df['AwayFTR'] == 1)])\n",
    "champ_anw = len(away_df[(home_df['Div'] == 1) & (away_df['AwayFTR'] == 0)])\n",
    "print(\n",
    "    f'    Champ Home Win Count:\\n        Win: {champ_hw}\\n       No Win: {champ_hnw}\\n')\n",
    "print(\n",
    "    f'    Champ Away Win Count:\\n        Win: {champ_aw}\\n       No Win: {champ_anw}\\n')\n",
    "champ_tot_games = champ_hw + champ_hnw\n",
    "champ_hw_perc = champ_hw / champ_tot_games\n",
    "champ_aw_perc = champ_aw / champ_tot_games\n",
    "print(\n",
    "    f'  Championship Since 00/01..  Home Win Percentage: {np.round(champ_hw_perc,2)}        Away Win Percentage: {np.round(champ_aw_perc,2)}\\n')\n",
    "\n",
    "print('League One:')\n",
    "l1_hw = len(home_df[(home_df['Div'] == 0) & (home_df['HomeFTR'] == 1)])\n",
    "l1_hnw = len(home_df[(home_df['Div'] == 0) & (home_df['HomeFTR'] == 0)])\n",
    "l1_aw = len(away_df[(away_df['Div'] == 0) & (away_df['AwayFTR'] == 1)])\n",
    "l1_anw = len(away_df[(home_df['Div'] == 0) & (away_df['AwayFTR'] == 0)])\n",
    "print(\n",
    "    f'    League 1 Home Win Count:\\n        Win: {l1_hw}\\n       No Win: {l1_hnw}\\n')\n",
    "print(\n",
    "    f'    League 1 Away Win Count:\\n        Win: {l1_aw}\\n       No Win: {l1_anw}\\n')\n",
    "l1_tot_games = l1_hw + l1_hnw\n",
    "l1_hw_perc = l1_hw / l1_tot_games\n",
    "l1_aw_perc = l1_aw / l1_tot_games\n",
    "print(\n",
    "    f'  League One Since 00/01..  Home Win Percentage: {np.round(l1_hw_perc,2)}        Away Win Percentage: {np.round(l1_aw_perc,2)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "home win rates and away win rates for each league are very similar with home win rates approx. 44% and away win rates approx. 29%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_train_target, _ = load_home_targets()\n",
    "away_train_target, _ = load_away_targets()\n",
    "htg = home_train_target.value_counts().sum()\n",
    "hw = home_train_target.value_counts()[1]\n",
    "hnw = home_train_target.value_counts()[0]\n",
    "hw_prop = hw/htg\n",
    "atg = away_train_target.value_counts().sum()\n",
    "aw = away_train_target.value_counts()[1]\n",
    "anw = away_train_target.value_counts()[0]\n",
    "aw_prop = aw/atg\n",
    "num_samps = len(home_train_target)\n",
    "#print(f'total samples: {num_samps},    home win prop: {hw_prop},    away win prop: {aw_prop}')\n",
    "hstat, hpval = proportions_ztest(count=hw, nobs=num_samps, value=.05)\n",
    "astat, apval = proportions_ztest(count=aw, nobs=num_samps, value=.05)\n",
    "bstat, bpval = proportions_ztest(count=np.array(\n",
    "    [hw, aw]), nobs=np.array([num_samps, num_samps]))\n",
    "if hpval <= 0.05:\n",
    "    print(\n",
    "        f'Home win proportion is statistically significant and not likely to have occured by chance.\\nProportion: {hw_prop}, Pvalue: {hpval}\\n')\n",
    "else:\n",
    "    print(\n",
    "        f'Home win proportion is not statistically significant and is likely to have occured by chance.\\nProportion: {hw_prop}, Pvalue: {hpval}\\n')\n",
    "\n",
    "if apval <= 0.05:\n",
    "    print(\n",
    "        f'Away win proportion is statistically significant and not likely to have occured by chance.\\nProportion: {aw_prop}, Pvalue: {apval}\\n')\n",
    "else:\n",
    "    print(\n",
    "        f'Away win proportion is not statistically significant and is likely to have occured by chance.\\nProportion: {aw_prop}, Pvalue: {apval}\\n')\n",
    "if bpval <= 0.05:\n",
    "    print(\n",
    "        f'Difference in proportions is statistically significant and not likely to have occured by chance.\\nPvalue: {bpval}\\n')\n",
    "else:\n",
    "    print(\n",
    "        f'Difference in proportions is not statistically significant and is likely to have occured by chance.\\nPvalue: {bpval}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = load_train_features()\n",
    "train_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varibale type\n",
    "train_features = load_train_features()\n",
    "\n",
    "ord_feat = ['Div', 'HT_PrevSeasonPos_inv', 'AT_PrevSeasonPos_inv']\n",
    "cyclical_feat = ['month', 'DayofWeek', 'season_month', 'season_month_sin',\n",
    "                 'season_month_cos', 'DayofWeek_sin', 'DayofWeek_cos']\n",
    "nominal_feat = ['HomeTeam', 'AwayTeam']\n",
    "dich_feat = [col for col in train_features.columns if 'UPoutlier' in col or 'LOWoutlier' in col or 'Local_Derby' in col or 'Dist>=100' in col or 'cluster' in col or 'upqrt' in col or 'lowqrt' in col or 'UPLOW' in col or 'bigcapacitydiff_' in col]\n",
    "cont_feat = [col for col in train_features.columns if col not in ord_feat +\n",
    "             cyclical_feat + nominal_feat + dich_feat]\n",
    "\n",
    "# combine cyclical feats for analysis\n",
    "season_df = pd.DataFrame(data={'season_month_sin': train_features.season_month_sin,\n",
    "                               'season_month_cos': train_features.season_month_cos})\n",
    "day_df = pd.DataFrame(data={'DayofWeek_sin': train_features.DayofWeek_sin,\n",
    "                            'DayofWeek_cos': train_features.DayofWeek_cos})\n",
    "\n",
    "cyclical_dfs = [season_df, day_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution plots for home win\n",
    "home_df = load_home_win_train_df()\n",
    "away_df = load_away_win_train_df()\n",
    "\n",
    "for col in home_df:\n",
    "    if col not in nominal_feat:\n",
    "        if col != 'HomeFTR':\n",
    "            fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)\n",
    "                  ) = plt.subplots(3, 2, figsize=(12, 8))\n",
    "            fig.suptitle(\n",
    "                f'{col} Distribution & Correlation/Association Plots\\n')\n",
    "            fig.tight_layout(pad=4.0)\n",
    "            # home distribution\n",
    "            hc_tab = pd.crosstab(home_df[col], home_df['HomeFTR'])\n",
    "            idx = hc_tab.index\n",
    "            hbar1 = ax1.bar(idx, hc_tab[0], width=0.6)\n",
    "            hbar2 = ax1.bar(idx, hc_tab[1], width=0.6)\n",
    "            ax1.set_title(f'{col} Home win/no win Distribution Chart')\n",
    "            ax1.set_xlabel(f'{col}')\n",
    "            ax1.set_ylabel('Frequency')\n",
    "            ax1.legend((hbar1[0], hbar2[0]), ('Home No Win', 'Home Win'))\n",
    "            ax1.grid(alpha=0.3)\n",
    "\n",
    "            # away distribution\n",
    "            ac_tab = pd.crosstab(away_df[col], away_df['AwayFTR'])\n",
    "            idx = ac_tab.index\n",
    "            abar1 = ax2.bar(idx, ac_tab[0], width=0.6)\n",
    "            abar2 = ax2.bar(idx, ac_tab[1], width=0.6)\n",
    "            ax2.set_title(f'{col} Away win/no win Distribution Chart')\n",
    "            ax2.set_xlabel(f'{col}')\n",
    "            ax2.set_ylabel('Frequency')\n",
    "            ax2.legend((abar1[0], abar2[0]), ('Away No Win', 'Away Win'))\n",
    "            ax2.grid(alpha=0.3)\n",
    "\n",
    "            if col in cont_feat or col in cyclical_feat:\n",
    "                # home boxplot\n",
    "                sns.boxplot(x=home_df['HomeFTR'], y=home_df[col], ax=ax3)\n",
    "                ax3.set_title(f'{col} home target Correlation')\n",
    "                ax3.set_xlabel('Home Full Time Result')\n",
    "                ax3.set_ylabel(f'{col}')\n",
    "                ax3.grid(alpha=0.3)\n",
    "\n",
    "                # away boxplot\n",
    "                sns.boxplot(x=away_df['AwayFTR'], y=away_df[col], ax=ax4)\n",
    "                ax4.set_title(f'{col} away target Correlation')\n",
    "                ax4.set_xlabel('Away Full Time Result')\n",
    "                ax4.set_ylabel(f'{col}')\n",
    "                ax4.grid(alpha=0.3)\n",
    "\n",
    "            if col in cont_feat:\n",
    "                # feature qqplot\n",
    "                qqplot(home_df[col], line='s', ax=ax5)\n",
    "                ax5.set_title(f'{col} Normality Plot')\n",
    "                ax5.grid(alpha=0.3)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# continuous feature power and quantile transforms\n",
    "train_features = load_train_features()\n",
    "\n",
    "yj_pt = PowerTransformer(method='yeo-johnson')\n",
    "bc_pt = PowerTransformer(method='box-cox')\n",
    "qt = QuantileTransformer(\n",
    "    n_quantiles=1000, output_distribution='normal', random_state=1)\n",
    "\n",
    "for col in train_features[cont_feat]:\n",
    "    feat = train_features[col]\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle(f'{col} Normality Transforms\\n')\n",
    "    fig.tight_layout(pad=4.0)\n",
    "\n",
    "    # original distribution\n",
    "    ax1.bar(feat.value_counts().index, feat.value_counts().values)\n",
    "    ax1.set_title(f'{col} Original Distribution')\n",
    "    ax1.set_xlabel(f'{col}')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.grid(alpha=0.3)\n",
    "\n",
    "    # yeo-johnson transform for data containing negative values\n",
    "    if feat.min() < 0:\n",
    "        feat_yj_trans = yj_pt.fit_transform(np.array(feat).reshape(-1, 1))\n",
    "        vals, freq = np.unique(feat_yj_trans, return_counts=True)\n",
    "        ax2.bar(vals, freq)\n",
    "        ax2.set_title(f'{col} Yeo-Johnson Transform')\n",
    "        ax2.set_xlabel(f'{col}')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.grid(alpha=0.3)\n",
    "    # box-cox and yeo-johnson transformations\n",
    "    else:\n",
    "        # yeo-johnson transform\n",
    "        feat_yj_trans = yj_pt.fit_transform(np.array(feat).reshape(-1, 1))\n",
    "        vals, freq = np.unique(feat_yj_trans, return_counts=True)\n",
    "        ax2.bar(vals, freq)\n",
    "        ax2.set_title(f'{col} Yeo-Johnson Transform')\n",
    "        ax2.set_xlabel(f'{col}')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.grid(alpha=0.3)\n",
    "        # box-cox transform\n",
    "        feat_bc_trans = bc_pt.fit_transform(np.array(feat + 1).reshape(-1, 1))\n",
    "        vals, freq = np.unique(feat_bc_trans, return_counts=True)\n",
    "        ax3.bar(vals, freq)\n",
    "        ax3.set_title(f'{col} Box-Cox Transform')\n",
    "        ax3.set_xlabel(f'{col}')\n",
    "        ax3.set_ylabel('Frequency')\n",
    "        ax3.grid(alpha=0.3)\n",
    "\n",
    "    # quantile transformation\n",
    "    feat_qt_trans = qt.fit_transform(np.array(feat).reshape(-1, 1))\n",
    "    vals, freq = np.unique(feat_qt_trans, return_counts=True)\n",
    "    ax4.bar(vals, freq)\n",
    "    ax4.set_title(f'{col} Quantile Transform')\n",
    "    ax4.set_xlabel(f'{col}')\n",
    "    ax4.set_ylabel('Frequency')\n",
    "    ax4.grid(alpha=0.3)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous pair plot for non transformed data with home win\n",
    "home_df = load_home_win_train_df()\n",
    "non_trans = [col for col in home_df.columns if 'TRANSFORM' not in col]\n",
    "home_df = home_df[non_trans]\n",
    "continuous = [\n",
    "    col for col in home_df.columns if col in cont_feat or col == 'HomeFTR']\n",
    "home_df = home_df[continuous]\n",
    "drop_cols = ['FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST',\n",
    "             'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR']\n",
    "home_df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "for i in home_df.columns:\n",
    "    for j in home_df.columns:\n",
    "        if i == j:\n",
    "            continue\n",
    "        elif i == 'HomeFTR':\n",
    "            continue\n",
    "        elif j == 'HomeFTR':\n",
    "            continue\n",
    "        else:\n",
    "            sns.scatterplot(data=home_df, x=i, y=j, hue='HomeFTR')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of nominal feats as far too large\n",
    "home_df = load_home_win_train_df()\n",
    "away_df = load_away_win_train_df()\n",
    "\n",
    "for col in home_df:\n",
    "    if col in nominal_feat:\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 16))\n",
    "        fig.suptitle(f'{col} Distribution & Correlation/Association Plots\\n')\n",
    "        fig.tight_layout(pad=10.0)\n",
    "\n",
    "        hc_tab = pd.crosstab(home_df[col], home_df['HomeFTR'])\n",
    "        h_idx = hc_tab.index\n",
    "        hbar1 = ax1.bar(h_idx, hc_tab[0], width=0.6)\n",
    "        hbar2 = ax1.bar(h_idx, hc_tab[1], width=0.6)\n",
    "        ax1.set_title(f'{col} Home win/no win Distribution Chart')\n",
    "        ax1.set_xlabel(f'{col}')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_xticklabels(h_idx, rotation=90)\n",
    "        ax1.legend((hbar1[0], hbar2[0]), ('Home No Win', 'Home Win'))\n",
    "        ax1.grid(alpha=0.3)\n",
    "\n",
    "        ac_tab = pd.crosstab(away_df[col], away_df['AwayFTR'])\n",
    "        a_idx = ac_tab.index\n",
    "        abar1 = ax2.bar(a_idx, ac_tab[0], width=0.6)\n",
    "        abar2 = ax2.bar(a_idx, ac_tab[1], width=0.6)\n",
    "        ax2.set_title(f'{col} Away win/no win Distribution Chart')\n",
    "        ax2.set_xlabel(f'{col}')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.set_xticklabels(a_idx, rotation=90)\n",
    "        ax2.legend((abar1[0], abar2[0]), ('Away No Win', 'Away Win'))\n",
    "        ax2.grid(alpha=0.3)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot proportions of win/no win for nominal features\n",
    "home_df = load_home_win_train_df()\n",
    "away_df = load_away_win_train_df()\n",
    "\n",
    "for col in home_df:\n",
    "    if col in nominal_feat:\n",
    "        # home df proportions\n",
    "        h_ct = pd.crosstab(home_df[col], home_df['HomeFTR'])\n",
    "        h_idx = h_ct.index\n",
    "        home_team_win_perc = []\n",
    "        home_team_nowin_perc = []\n",
    "        for h_team in h_idx:\n",
    "            ht_wins = h_ct[h_ct.index == h_team][1].values\n",
    "            ht_nowin = h_ct[h_ct.index == h_team][0].values\n",
    "            ht_tot = ht_wins + ht_nowin\n",
    "            hwin_perc = float(ht_wins / ht_tot)\n",
    "            hnowin_perc = float(ht_nowin / ht_tot)\n",
    "            home_team_win_perc.append(hwin_perc)\n",
    "            home_team_nowin_perc.append(hnowin_perc)\n",
    "\n",
    "        # away df proportions\n",
    "        a_ct = pd.crosstab(away_df[col], away_df['AwayFTR'])\n",
    "        a_idx = a_ct.index\n",
    "        away_team_win_perc = []\n",
    "        away_team_nowin_perc = []\n",
    "        for a_team in a_idx:\n",
    "            at_wins = a_ct[a_ct.index == a_team][1].values\n",
    "            at_nowin = a_ct[a_ct.index == a_team][0].values\n",
    "            at_tot = at_wins + at_nowin\n",
    "            awin_perc = float(at_wins / at_tot)\n",
    "            anowin_perc = float(at_nowin / at_tot)\n",
    "            away_team_win_perc.append(awin_perc)\n",
    "            away_team_nowin_perc.append(anowin_perc)\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 16))\n",
    "        fig.suptitle(f'{col} Win/NO Win Proportion Plots\\n')\n",
    "        fig.tight_layout(pad=13.0)\n",
    "        # home plot\n",
    "        hbar1 = ax1.bar(h_idx, home_team_nowin_perc, width=0.6)\n",
    "        hbar2 = ax1.bar(h_idx, home_team_win_perc, width=0.6)\n",
    "        ax1.set_title(f'{col} Home win/no win Proportions')\n",
    "        ax1.set_xlabel(f'{col}')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_xticklabels(h_idx, rotation=90)\n",
    "        ax1.legend((hbar1[0], hbar2[0]), ('Home No Win', 'Home Win'))\n",
    "        ax1.grid(alpha=0.3)\n",
    "\n",
    "        # away plot\n",
    "        hbar1 = ax2.bar(a_idx, away_team_nowin_perc, width=0.6)\n",
    "        hbar2 = ax2.bar(a_idx, away_team_win_perc, width=0.6)\n",
    "        ax2.set_title(f'{col} Away win/no win Proportions')\n",
    "        ax2.set_xlabel(f'{col}')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.set_xticklabels(a_idx, rotation=90)\n",
    "        ax2.legend((hbar1[0], hbar2[0]), ('Away No Win', 'Away Win'))\n",
    "        ax2.grid(alpha=0.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normality statistical test\n",
    "train_features = load_train_features()\n",
    "gaussian = []\n",
    "non_gaussian = []\n",
    "\n",
    "for col in train_features.columns:\n",
    "    alpha = 0.05\n",
    "    if col in cont_feat:\n",
    "        print(f'\\n{col}:')\n",
    "        data = train_features[col].copy()\n",
    "        shap_stat, shap_p = shapiro(data)\n",
    "        dagos_stat, dagos_p = normaltest(data)\n",
    "        stat_result = anderson(data)\n",
    "\n",
    "        count = 0\n",
    "        if shap_p > alpha:\n",
    "            count += 1\n",
    "            print(\n",
    "                f'Shapiro test:  Sample looks gaussian, stat = {shap_stat}, p = {shap_p}')\n",
    "        else:\n",
    "            print(\n",
    "                f'Shapiro test:  Sample does not look gaussian, stat = {shap_stat}, p = {shap_p}')\n",
    "\n",
    "        if dagos_p > alpha:\n",
    "            count += 1\n",
    "            print(\n",
    "                f\"D'agostino test:  Sample looks gaussian, stat = {dagos_stat}, p = {dagos_p}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"D'agostino test:  Sample does not look gaussian, stat = {dagos_stat}, p = {dagos_p}\")\n",
    "\n",
    "        if stat_result.statistic < stat_result.critical_values[0]:\n",
    "            count += 1\n",
    "            print(f\"Anderson test:  Sample looks gaussian\")\n",
    "        else:\n",
    "            print(f\"Anderson test:  Sample does not look gaussian\")\n",
    "        for i in range(len(stat_result.critical_values)):\n",
    "            sl, cv = stat_result.significance_level[i], stat_result.critical_values[i]\n",
    "            print(\n",
    "                f\"Anderson test:  stat = {stat_result.statistic}, sig = {sl}, crit val = {cv}\")\n",
    "\n",
    "        if count >= 2:\n",
    "            gaussian.append(col)\n",
    "        elif count <= 1:\n",
    "            non_gaussian.append(col)\n",
    "\n",
    "print(f'\\nGaussian Features: {gaussian}')\n",
    "print(f'\\nNon Gaussian Features: {non_gaussian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap for colinearity\n",
    "features = load_train_features()\n",
    "#home_df = load_home_win_train_df()\n",
    "#away_df = load_away_win_train_df()\n",
    "\n",
    "heatmap_dict = {}\n",
    "columns = []\n",
    "\n",
    "for col1 in features:\n",
    "    if col1 not in cyclical_feat:\n",
    "        columns.append(col1)\n",
    "        corr_vals = []\n",
    "        f1 = features[col1].copy()\n",
    "        for col2 in features:\n",
    "            if col2 not in cyclical_feat:\n",
    "                f2 = features[col2].copy()\n",
    "                if col1 in cont_feat and col2 in cont_feat:  # continuous - continuous.. spearman\n",
    "                    score = spearmanr(f1, f2)[0]\n",
    "                    corr_vals.append(score)\n",
    "                if col1 in cont_feat and col2 in ord_feat:  # continuous - ordinal.. spearman\n",
    "                    score = spearmanr(f1, f2)[0]\n",
    "                    corr_vals.append(score)\n",
    "                if col1 in cont_feat and col2 in nominal_feat:  # continuous - nominal.. logistic regression fbeta\n",
    "                    model = LogisticRegression(\n",
    "                        class_weight='balanced', multi_class='multinomial')\n",
    "                    scores = evaluate_model(\n",
    "                        np.array(f1).reshape(-1, 1), f2, model)\n",
    "                    corr_vals.append(np.mean(scores))\n",
    "                if col1 in cont_feat and col2 in dich_feat:  # continuous - dichotomous.. logitsic regression\n",
    "                    model = LogisticRegression(class_weight='balanced')\n",
    "                    scores = evaluate_model(\n",
    "                        np.array(f1).reshape(-1, 1), f2, model, k_splits=3)\n",
    "                    corr_vals.append(np.mean(scores))\n",
    "                if col1 in nominal_feat and col2 in cont_feat:  # nominal - continuous.. mars R2\n",
    "                    oh_f1 = pd.get_dummies(f1)\n",
    "                    model = Earth()\n",
    "                    scores = cross_val_score(\n",
    "                        model, oh_f1, f2, scoring='r2', cv=5, n_jobs=-1)\n",
    "                    corr_vals.append(np.mean(scores))\n",
    "                if col1 in nominal_feat and col2 in ord_feat:  # nominal - ordinal.. cramers v\n",
    "                    c_table = pd.crosstab(f1, f2).values\n",
    "                    score = cramers_corrected_stat(c_table)\n",
    "                    corr_vals.append(score)\n",
    "                if col1 in nominal_feat and col2 in nominal_feat:  # nominal - nominal.. cramers v\n",
    "                    c_table = pd.crosstab(f1, f2).values\n",
    "                    score = cramers_corrected_stat(c_table)\n",
    "                    corr_vals.append(score)\n",
    "                if col1 in nominal_feat and col2 in dich_feat:  # nominal - dichotomous.. cramers v\n",
    "                    c_table = pd.crosstab(f1, f2).values\n",
    "                    score = cramers_corrected_stat(c_table)\n",
    "                    corr_vals.append(score)\n",
    "                if col1 in ord_feat and col2 in cont_feat:  # ordinal - continuous.. spearman\n",
    "                    score = spearmanr(f1, f2)[0]\n",
    "                    corr_vals.append(score)\n",
    "                if col1 in ord_feat and col2 in ord_feat:  # ordinal - ordinal.. spearman\n",
    "                    score = spearmanr(f1, f2)[0]\n",
    "                    corr_vals.append(score)\n",
    "                if col1 in ord_feat and col2 in nominal_feat:  # ordinal - nominal.. cramers v\n",
    "                    c_table = pd.crosstab(f1, f2).values\n",
    "                    score = cramers_corrected_stat(c_table)\n",
    "                    corr_vals.append(score)\n",
    "                if col1 in ord_feat and col2 in dich_feat:  # ordinal - dichtomous.. spearman\n",
    "                    score = spearmanr(f1, f2)[0]\n",
    "                    corr_vals.append(score)\n",
    "                if col1 in dich_feat and col2 in cont_feat:  # dichotomous - continuous.. mars r2\n",
    "                    model = Earth()\n",
    "                    scores = cross_val_score(\n",
    "                        model, f1, f2, scoring='r2', cv=5, n_jobs=-1)\n",
    "                    corr_vals.append(np.mean(scores))\n",
    "                if col1 in dich_feat and col2 in ord_feat:  # dichotomous - ordinal.. spearman\n",
    "                    score = spearmanr(f1, f2)[0]\n",
    "                    corr_vals.append(score)\n",
    "                if col1 in dich_feat and col2 in nominal_feat:  # dichotomous - nominal.. cramers v\n",
    "                    c_table = pd.crosstab(f1, f2).values\n",
    "                    score = cramers_corrected_stat(c_table)\n",
    "                    corr_vals.append(score)\n",
    "                if col1 in dich_feat and col2 in dich_feat:  # dichotmous - dichotomous.. phi\n",
    "                    c_table = pd.crosstab(f1, f2).values\n",
    "                    score = phi(c_table)\n",
    "                    corr_vals.append(score)\n",
    "\n",
    "        heatmap_dict[col1] = corr_vals\n",
    "\n",
    "corr_grid = pd.DataFrame(heatmap_dict, index=columns)\n",
    "\n",
    "plt.figure(figsize=(30, 24))\n",
    "plt.title('Feature Colinearity Plot')\n",
    "\n",
    "sns.heatmap(corr_grid, vmin=-1, vmax=1, cmap='RdBu_r', linewidths=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# home feature / target .. correlation / association.. mutual info\n",
    "home_df = load_home_win_train_df()\n",
    "heatmap_dict = {}\n",
    "columns = []\n",
    "m_info = []\n",
    "alpha = 0.05\n",
    "h_significant = []\n",
    "h_non_significant = []\n",
    "\n",
    "for col in home_df:\n",
    "    if col not in cyclical_feat and col != 'HomeFTR':\n",
    "        columns.append(col)\n",
    "        feat = home_df[col].copy()\n",
    "        targ = home_df['HomeFTR'].copy()\n",
    "        # continuous - dichotomous.. fbeta maximizing recall (minimise false negs)\n",
    "        if col in cont_feat:\n",
    "            model = LogisticRegression(class_weight='balanced')\n",
    "            scores = evaluate_model(np.array(feat).reshape(-1, 1), targ, model)\n",
    "            heatmap_dict[col] = np.mean(scores)\n",
    "            # mutual info\n",
    "            mi = mutual_info_classif(np.array(feat).reshape(-1, 1), targ)\n",
    "            m_info.append(mi)\n",
    "            # hypothesis test - convert to categorical\n",
    "            feat_bin = pd.qcut(feat, 10, duplicates='drop')\n",
    "            bin_ctable = pd.crosstab(feat_bin, targ)\n",
    "            chi2_stats = chi2_contingency(bin_ctable, correction=True)\n",
    "            print(f'\\n{col}/HomeFTR hypothesis test:\\n')\n",
    "            if chi2_stats[1] > alpha:\n",
    "                print(\n",
    "                    f'Not statistically significant, likely to have occured by chance\\nChi2: {chi2_stats[0]}, Pvalue : {chi2_stats[1]}')\n",
    "                h_non_significant.append(col)\n",
    "            else:\n",
    "                print(\n",
    "                    f'Statistically significant, not likely to have occured by chance\\nChi2: {chi2_stats[0]}, Pvalue : {chi2_stats[1]}')\n",
    "                h_significant.append(col)\n",
    "        if col in nominal_feat:  # nominal - dichotomous.. cramers v\n",
    "            c_table = pd.crosstab(feat, targ).values\n",
    "            score = cramers_corrected_stat(c_table)\n",
    "            heatmap_dict[col] = score\n",
    "            # mutual info\n",
    "            onehot_df = pd.get_dummies(feat)\n",
    "            mi = mutual_info_classif(onehot_df, targ)\n",
    "            m_info.append(np.sum(mi))\n",
    "            # hypothesis test\n",
    "            chi2_stats = chi2_contingency(c_table, correction=True)\n",
    "            print(f'\\n{col}/HomeFTR hypothesis test:\\n')\n",
    "            if chi2_stats[1] > alpha:\n",
    "                print(\n",
    "                    f'Not statistically significant, likely to have occured by chance\\nCramers V: {score}, Pvalue : {chi2_stats[1]}')\n",
    "                h_non_significant.append(col)\n",
    "            else:\n",
    "                print(\n",
    "                    f'Statistically significant, not likely to have occured by chance\\nCramers V: {score}, Pvalue : {chi2_stats[1]}')\n",
    "                h_significant.append(col)\n",
    "        if col in ord_feat:  # ordinal - dichtomous.. spearman rank\n",
    "            spman_test = spearmanr(feat, targ)\n",
    "            heatmap_dict[col] = spman_test[0]\n",
    "            # mutual info\n",
    "            mi = mutual_info_classif(np.array(feat).reshape(-1, 1), targ)\n",
    "            m_info.append(mi)\n",
    "            # hypothesis test\n",
    "            print(f'\\n{col}/HomeFTR hypothesis test:\\n')\n",
    "            if spman_test[1] > alpha:\n",
    "                print(\n",
    "                    f'Not statistically significant, likely to have occured by chance\\nSpearman stat: {spman_test[0]}, Pvalue : {spman_test[1]}')\n",
    "                h_non_significant.append(col)\n",
    "            else:\n",
    "                print(\n",
    "                    f'Statistically significant, not likely to have occured by chance\\nSpearman stat: {spman_test[0]}, Pvalue : {spman_test[1]}')\n",
    "                h_significant.append(col)\n",
    "        if col in dich_feat:  # dichtomous - dichotomous.. phi\n",
    "            c_table = pd.crosstab(feat, targ).values\n",
    "            score = phi(c_table)\n",
    "            heatmap_dict[col] = score\n",
    "            # mutual info\n",
    "            mi = mutual_info_classif(np.array(feat).reshape(-1, 1), targ)\n",
    "            m_info.append(mi)\n",
    "            # hypothesis test\n",
    "            print(f'\\n{col}/HomeFTR hypothesis test:\\n')\n",
    "            chi2_stats = chi2_contingency(c_table, correction=True)\n",
    "            if chi2_stats[1] > alpha:\n",
    "                print(\n",
    "                    f'Not statistically significant, likely to have occured by chance\\nPhi: {score}, Pvalue : {chi2_stats[1]}')\n",
    "                h_non_significant.append(col)\n",
    "            else:\n",
    "                print(\n",
    "                    f'Statistically significant, not likely to have occured by chance\\nPhi: {score}, Pvalue : {chi2_stats[1]}')\n",
    "                h_significant.append(col)\n",
    "\n",
    "print(\n",
    "    f'\\nSignificant: {h_significant}\\n\\nNon-Significant: {h_non_significant}')\n",
    "\n",
    "for df in cyclical_dfs:\n",
    "    if 'DayofWeek_sin' in df:\n",
    "        col_name = 'DayofWeek'\n",
    "        columns.append(col_name)\n",
    "    if 'season_month_sin' in df:\n",
    "        col_name = 'season_month'\n",
    "        columns.append(col_name)\n",
    "\n",
    "    corr_vals = []\n",
    "    model = LogisticRegression(class_weight='balanced')\n",
    "    scores = evaluate_model(df, targ, model)\n",
    "    corr_vals.append(np.mean(scores))\n",
    "    heatmap_dict[col_name] = corr_vals\n",
    "    # mutual info\n",
    "    mi = mutual_info_classif(df, targ)\n",
    "    m_info.append(np.sum(mi))\n",
    "\n",
    "corr_grid = pd.DataFrame(heatmap_dict)\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(20, 16))\n",
    "fig.tight_layout(pad=12.0)\n",
    "sns.heatmap(corr_grid, vmin=-1, vmax=1,\n",
    "            cmap='RdBu_r', yticklabels=False, ax=ax1)\n",
    "ax1.set_title('Home Dataframe Feature/Target Correlation/Association')\n",
    "ax1.set_ylabel('HomeFTR')\n",
    "\n",
    "ax2.bar(columns, m_info)\n",
    "ax2.set_title('Home Dataframe Feature/Target Mutual Information')\n",
    "ax2.set_xlabel('Features')\n",
    "ax2.set_ylabel('Mutual Information')\n",
    "ax2.set_xticklabels(columns, rotation=90)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away feature / target .. correlation / association.. mutual info\n",
    "away_df = load_away_win_train_df()\n",
    "heatmap_dict = {}\n",
    "columns = []\n",
    "m_info = []\n",
    "alpha = 0.05\n",
    "a_significant = []\n",
    "a_non_significant = []\n",
    "\n",
    "for col in away_df:\n",
    "    if col not in cyclical_feat and col != 'AwayFTR':\n",
    "        columns.append(col)\n",
    "        feat = away_df[col].copy()\n",
    "        targ = away_df['AwayFTR'].copy()\n",
    "        if col in cont_feat:  # continuous - dichotomous.. roc auc score\n",
    "            model = LogisticRegression(class_weight='balanced')\n",
    "            scores = evaluate_model(np.array(feat).reshape(-1, 1), targ, model)\n",
    "            heatmap_dict[col] = np.mean(scores)\n",
    "            # mutual info\n",
    "            mi = mutual_info_classif(np.array(feat).reshape(-1, 1), targ)\n",
    "            m_info.append(mi)\n",
    "            # hypothesis test - convert to categorical\n",
    "            feat_bin = pd.qcut(feat, 10, duplicates='drop')\n",
    "            bin_ctable = pd.crosstab(feat_bin, targ)\n",
    "            chi2_stats = chi2_contingency(bin_ctable, correction=True)\n",
    "            print(f'\\n{col}/AwayFTR hypothesis test:\\n')\n",
    "            if chi2_stats[1] > alpha:\n",
    "                print(\n",
    "                    f'Not statistically significant, likely to have occured by chance\\nChi2: {chi2_stats[0]}, Pvalue : {chi2_stats[1]}')\n",
    "                a_non_significant.append(col)\n",
    "            else:\n",
    "                print(\n",
    "                    f'Statistically significant, not likely to have occured by chance\\nChi2: {chi2_stats[0]}, Pvalue : {chi2_stats[1]}')\n",
    "                a_significant.append(col)\n",
    "        if col in nominal_feat:  # nominal - dichotomous.. cramers v\n",
    "            c_table = pd.crosstab(feat, targ).values\n",
    "            score = cramers_corrected_stat(c_table)\n",
    "            heatmap_dict[col] = score\n",
    "            # mutual info\n",
    "            onehot_df = pd.get_dummies(feat)\n",
    "            mi = mutual_info_classif(onehot_df, targ)\n",
    "            m_info.append(np.sum(mi))\n",
    "            # hypothesis test\n",
    "            chi2_stats = chi2_contingency(c_table, correction=True)\n",
    "            print(f'\\n{col}/AwayFTR hypothesis test:\\n')\n",
    "            if chi2_stats[1] > alpha:\n",
    "                print(\n",
    "                    f'Not statistically significant, likely to have occured by chance\\nCramers V: {score}, Pvalue : {chi2_stats[1]}')\n",
    "                a_non_significant.append(col)\n",
    "            else:\n",
    "                print(\n",
    "                    f'Statistically significant, not likely to have occured by chance\\nCramers V: {score}, Pvalue : {chi2_stats[1]}')\n",
    "                a_significant.append(col)\n",
    "        if col in ord_feat:  # ordinal - dichtomous.. spearman rank\n",
    "            score = spearmanr(feat, targ)[0]\n",
    "            heatmap_dict[col] = score\n",
    "            # mutual info\n",
    "            mi = mutual_info_classif(np.array(feat).reshape(-1, 1), targ)\n",
    "            m_info.append(mi)\n",
    "            # hypothesis test\n",
    "            print(f'\\n{col}/AwayFTR hypothesis test:\\n')\n",
    "            if spman_test[1] > alpha:\n",
    "                print(\n",
    "                    f'Not statistically significant, likely to have occured by chance\\nSpearman stat: {spman_test[0]}, Pvalue : {spman_test[1]}')\n",
    "                a_non_significant.append(col)\n",
    "            else:\n",
    "                print(\n",
    "                    f'Statistically significant, not likely to have occured by chance\\nSpearman stat: {spman_test[0]}, Pvalue : {spman_test[1]}')\n",
    "                a_significant.append(col)\n",
    "        if col in dich_feat:  # dichtomous - dichotomous.. phi\n",
    "            c_table = pd.crosstab(feat, targ).values\n",
    "            score = phi(c_table)\n",
    "            heatmap_dict[col] = score\n",
    "            # mutual info\n",
    "            mi = mutual_info_classif(np.array(feat).reshape(-1, 1), targ)\n",
    "            m_info.append(mi)\n",
    "            # hypothesis test\n",
    "            print(f'\\n{col}/AwayFTR hypothesis test:\\n')\n",
    "            chi2_stats = chi2_contingency(c_table, correction=True)\n",
    "            if chi2_stats[1] > alpha:\n",
    "                print(\n",
    "                    f'Not statistically significant, likely to have occured by chance\\nPhi: {score}, Pvalue : {chi2_stats[1]}')\n",
    "                a_non_significant.append(col)\n",
    "            else:\n",
    "                print(\n",
    "                    f'Statistically significant, not likely to have occured by chance\\nPhi: {score}, Pvalue : {chi2_stats[1]}')\n",
    "                a_significant.append(col)\n",
    "\n",
    "print(\n",
    "    f'\\nSignificant: {a_significant}\\n\\nNon-Significant: {a_non_significant}')\n",
    "\n",
    "for df in cyclical_dfs:\n",
    "    if 'DayofWeek_sin' in df:\n",
    "        col_name = 'DayofWeek'\n",
    "        columns.append(col_name)\n",
    "    if 'season_month_sin' in df:\n",
    "        col_name = 'season_month'\n",
    "        columns.append(col_name)\n",
    "\n",
    "    corr_vals = []\n",
    "    model = LogisticRegression(class_weight='balanced')\n",
    "    scores = evaluate_model(df, targ, model)\n",
    "    corr_vals.append(np.mean(scores))\n",
    "    heatmap_dict[col_name] = corr_vals\n",
    "    # mutual info\n",
    "    mi = mutual_info_classif(df, targ)\n",
    "    m_info.append(np.sum(mi))\n",
    "\n",
    "corr_grid = pd.DataFrame(heatmap_dict)\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(20, 16))\n",
    "fig.tight_layout(pad=12.0)\n",
    "sns.heatmap(corr_grid, vmin=-1, vmax=1,\n",
    "            cmap='RdBu_r', yticklabels=False, ax=ax1)\n",
    "ax1.set_title('Away Dataframe Feature/Target Correlation/Association')\n",
    "ax1.set_ylabel('AwayFTR')\n",
    "\n",
    "ax2.bar(columns, m_info)\n",
    "ax2.set_title('Away Dataframe Feature/Target Mutual Information')\n",
    "ax2.set_xlabel('Features')\n",
    "ax2.set_ylabel('Mutual Information')\n",
    "ax2.set_xticklabels(columns, rotation=90)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for natural forming clusters... home data\n",
    "home_df = load_home_win_train_df()\n",
    "oh_home_df = football_data_team_ohe(home_df)\n",
    "\n",
    "drop_cols = ['Div', 'FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC',\n",
    "             'AC', 'HY', 'AY', 'HR', 'AR', 'year', 'AHTGS5PG_UPoutlier',  'AATGS5PG_UPoutlier', 'AATGS5PG_LOWoutlier',\n",
    "             'AHTGC5PG_LOWoutlier', 'AATGC5PG_UPoutlier', 'AHTGS5PHG_UPoutlier', 'AHTSOT5PG_LOWoutlier', 'AHTSOT5PHG_UPoutlier',\n",
    "             'AATSOT5PAG_LOWoutlier', 'AHTGS_SOT5PG_ratio_UPoutlier', 'AATGS_SOT5PG_ratio_UPoutlier', 'AATGS_SOT5PAG_ratio_UPoutlier',\n",
    "             'AHTGD5PG_LOWoutlier', 'AATGD5PG_UPoutlier', 'AATGD5PG_LOWoutlier', 'AHTGD5PHG_UPoutlier', 'AHTGD5PHG_LOWoutlier',\n",
    "             'Local_Derby', 'Dist>=100', 'HomeFTR']\n",
    "oh_home_df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# elbow method for kmeans\n",
    "distortions = []\n",
    "inertias = []\n",
    "n_k = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=2).fit(oh_home_df)\n",
    "\n",
    "    # avg square distances from cluster centres... euclidean distance\n",
    "    distortions.append(sum(np.min(cdist(oh_home_df, kmeans.cluster_centers_,\n",
    "                                        'euclidean'), axis=1)) / oh_home_df.shape[0])\n",
    "    # sum of squared distances from the cluster centres\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    n_k.append(k)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(16, 10))\n",
    "fig.suptitle('Home Data Elbow Methods')\n",
    "ax1.plot(n_k, distortions, 'bx-')\n",
    "ax1.set_title('Elbow Method Using Distortion')\n",
    "ax1.set_xlabel('Values of K')\n",
    "ax1.set_ylabel('Distortion')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.plot(n_k, inertias, 'bx-')\n",
    "ax2.set_title('Elbow Method Using Inertia')\n",
    "ax2.set_xlabel('Values of K')\n",
    "ax2.set_ylabel('Inertia')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for natural forming clusters... away data\n",
    "away_df = load_away_win_train_df()\n",
    "oh_away_df = football_data_team_ohe(away_df)\n",
    "\n",
    "drop_cols = ['Div', 'FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC',\n",
    "             'AC', 'HY', 'AY', 'HR', 'AR', 'year', 'AHTGS5PG_UPoutlier', 'AHTGC5PG_LOWoutlier', 'AATGC5PG_UPoutlier',\n",
    "             'AHTGS5PHG_UPoutlier', 'AATGS5PAG_UPoutlier', 'AHTGC5PHG_UPoutlier', 'AATGC5PAG_UPoutlier',\n",
    "             'AHTGS_SOT5PHG_ratio_UPoutlier', 'AHTGD5PG_UPoutlier', 'AATGD5PAG_UPoutlier', 'AATGD5PAG_LOWoutlier',\n",
    "             'Local_Derby', 'Dist>=100', 'AwayFTR']\n",
    "oh_away_df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# elbow method for kmeans\n",
    "distortions = []\n",
    "inertias = []\n",
    "n_k = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=2).fit(oh_away_df)\n",
    "\n",
    "    # avg square distances from cluster centres... euclidean distance\n",
    "    distortions.append(sum(np.min(cdist(oh_away_df, kmeans.cluster_centers_,\n",
    "                                        'euclidean'), axis=1)) / oh_away_df.shape[0])\n",
    "    # sum of squared distances from the cluster centres\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    n_k.append(k)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(16, 10))\n",
    "fig.suptitle('Away Data Elbow Methods')\n",
    "ax1.plot(n_k, distortions, 'bx-')\n",
    "ax1.set_title('Elbow Method Using Distortion')\n",
    "ax1.set_xlabel('Values of K')\n",
    "ax1.set_ylabel('Distortion')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.plot(n_k, inertias, 'bx-')\n",
    "ax2.set_title('Elbow Method Using Inertia')\n",
    "ax2.set_xlabel('Values of K')\n",
    "ax2.set_ylabel('Inertia')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for natural forming clusters... all train data\n",
    "train_features = load_train_features()\n",
    "oh_train_feat = football_data_team_ohe(train_features)\n",
    "\n",
    "drop_cols = ['Div', 'FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC',\n",
    "             'AC', 'HY', 'AY', 'HR', 'AR']\n",
    "oh_train_feat.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# elbow method for kmeans\n",
    "distortions = []\n",
    "inertias = []\n",
    "n_k = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=2).fit(oh_train_feat)\n",
    "\n",
    "    # avg square distances from cluster centres... euclidean distance\n",
    "    distortions.append(sum(np.min(cdist(oh_train_feat, kmeans.cluster_centers_,\n",
    "                                        'euclidean'), axis=1)) / oh_train_feat.shape[0])\n",
    "    # sum of squared distances from the cluster centres\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    n_k.append(k)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(16, 10))\n",
    "fig.suptitle('Train Features Elbow Methods')\n",
    "ax1.plot(n_k, distortions, 'bx-')\n",
    "ax1.set_title('Elbow Method Using Distortion')\n",
    "ax1.set_xlabel('Values of K')\n",
    "ax1.set_ylabel('Distortion')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.plot(n_k, inertias, 'bx-')\n",
    "ax2.set_title('Elbow Method Using Inertia')\n",
    "ax2.set_xlabel('Values of K')\n",
    "ax2.set_ylabel('Inertia')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca for home features\n",
    "pca_home_df = load_home_train_features_with_drop()  # load features\n",
    "pca_home_df = football_data_team_ohe(pca_home_df)  # ohe football teams\n",
    "sc = StandardScaler()\n",
    "pca_home_df = sc.fit_transform(pca_home_df)\n",
    "# fit pca algorithm\n",
    "pca = PCA().fit(pca_home_df)\n",
    "# Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)')  # for each component\n",
    "plt.title('Explained Variance of Home Features')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca for home features without home/away teams\n",
    "pca_home_df = load_home_train_features_with_drop()  # load features\n",
    "pca_home_df.drop(columns=['HomeTeam', 'AwayTeam'],\n",
    "                 inplace=True)  # ohe football teams\n",
    "sc = StandardScaler()\n",
    "pca_home_df = sc.fit_transform(pca_home_df)\n",
    "# fit pca algorithm\n",
    "pca = PCA().fit(pca_home_df)\n",
    "# Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)')  # for each component\n",
    "plt.title('Explained Variance of Home Features Without H/A Teams')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca for away features\n",
    "pca_away_df = load_away_train_features_with_drop()  # load features\n",
    "pca_away_df = football_data_team_ohe(pca_away_df)  # ohe football teams\n",
    "sc = StandardScaler()\n",
    "pca_away_df = sc.fit_transform(pca_away_df)\n",
    "# fit pca algorithm\n",
    "pca = PCA().fit(pca_away_df)\n",
    "# Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)')  # for each component\n",
    "plt.title('Explained Variance of Away Features')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca for away features without home/away teams\n",
    "pca_away_df = load_away_train_features_with_drop()  # load features\n",
    "pca_away_df.drop(columns=['HomeTeam', 'AwayTeam'],\n",
    "                 inplace=True)  # ohe football teams\n",
    "sc = StandardScaler()\n",
    "pca_away_df = sc.fit_transform(pca_away_df)\n",
    "# fit pca algorithm\n",
    "pca = PCA().fit(pca_away_df)\n",
    "# Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)')  # for each component\n",
    "plt.title('Explained Variance of Away Features Withot H/A Teams')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Summary -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proprotions for home and away win seem to be statistically significant and not likely to have occured by chance. Home win proportion is approx. 0.45 and away win proportion is approx. 0.29. The difference between these proportions is also likely not to have occured by chance.\n",
    "\n",
    "The data after engineering contains ordinal, nominal, dichtomous, continuous and cyclical features.\n",
    "\n",
    "Majority of continuous data appears to be skewed to the right, which makes sense as with football extreme values tend to be higher... i.e a high number of goals scored will be more rare than a few goals scored. There also seems to be some gaussian like features.\n",
    "\n",
    "Box-cox, Yeo-johnson power and Quantile transforms applied to continuous data to reduce skewness\n",
    "\n",
    "Shapiro, D'agostino and Anderson Normality tests performed using majority vote to determine if a feature is normally distributed. All features appear to be non-gaussian.\n",
    "\n",
    "High multicollinearity from engineered indicator features which is to be expected with a mix of none to high for other features. For numerical modelling algorithms PCA can be used to alleviate the effects of collinearity aswell as reduce dimensionality. Tree based algorithms will be unaffected by multicollinearity.\n",
    "\n",
    "Chi sqaured and Spearmans rho stastistical significance tests performed for feature/target correlation and association with features being removed if they are likely to have occured by chance as they could affect generalisation to the population. \n",
    "\n",
    "Spearmans rho, Cramers v, phi and information gain tests used to analyse feature/target correlation/association with the least correlated/associated features removed. During model feature selection more features may be cut.\n",
    "\n",
    "Looked for natural forming clusters within the data and found 4 undetermined clusters, these clusters are used as features for predicting. \n",
    "\n",
    "Found that reducing to 30 feature components using pca we still obtain 98% variance, this will likely change if features are cut during model feature selection but will be useful for initial model testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Feature Engineering --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate month from date\n",
    "month = []\n",
    "for i in range(len(train_features)):\n",
    "    date = train_features['Date'][i]\n",
    "    month.append(int(date.split('/')[1]))\n",
    "\n",
    "train_features['month'] = pd.Series(data=month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate year from date\n",
    "year = []\n",
    "for i in range(len(train_features)):\n",
    "    date = train_features['Date'][i]\n",
    "    if len(date.split('/')[2]) <= 2:  # 2 digits for year\n",
    "        year.append(datetime.datetime.strptime(\n",
    "            train_features['Date'][i], '%d/%m/%y').strftime('%Y'))\n",
    "    else:  # 4 digits for year\n",
    "        year.append(datetime.datetime.strptime(\n",
    "            train_features['Date'][i], '%d/%m/%Y').strftime('%Y'))\n",
    "\n",
    "train_features['year'] = pd.Series(data=year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day of week... 0 = monday, 6 = sunday\n",
    "date = pd.to_datetime(train_features['Date'], dayfirst=True)\n",
    "train_features['DayofWeek'] = date.dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# season month\n",
    "# start august\n",
    "train_features['season_month'] = 0\n",
    "s_mnth_order = [8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7]\n",
    "count = 0\n",
    "for mnth in s_mnth_order:\n",
    "    count += 1\n",
    "    fm = train_features['month'] == mnth\n",
    "    fm_idx = fm[fm].index.values\n",
    "    train_features.loc[fm_idx, 'season_month'] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract cyclical nature from season month and day of week\n",
    "# month cyclical\n",
    "train_features['season_month_sin'] = np.sin(\n",
    "    2*np.pi*train_features.season_month/12)\n",
    "train_features['season_month_cos'] = np.cos(\n",
    "    2*np.pi*train_features.season_month/12)\n",
    "# day of week cyclical\n",
    "train_features['DayofWeek_sin'] = np.sin(2*np.pi*train_features.DayofWeek/7)\n",
    "train_features['DayofWeek_cos'] = np.cos(2*np.pi*train_features.DayofWeek/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average goals scored to shots on target ratio (goals scored / shots on target)\n",
    "# 5 previous games for home team and away team\n",
    "train_features['AHTGS_SOT5PG_ratio'] = np.round(\n",
    "    train_features.AHTGS5PG / train_features.AHTSOT5PG, 2)\n",
    "train_features['AATGS_SOT5PG_ratio'] = np.round(\n",
    "    train_features.AATGS5PG / train_features.AATSOT5PG, 2)\n",
    "\n",
    "# 5 previous home games for home team\n",
    "train_features['AHTGS_SOT5PHG_ratio'] = np.round(\n",
    "    train_features.AHTGS5PHG / train_features.AHTSOT5PHG, 2)\n",
    "\n",
    "# 5 previous away games for away team\n",
    "train_features['AATGS_SOT5PAG_ratio'] = np.round(\n",
    "    train_features.AATGS5PAG / train_features.AATSOT5PAG, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average goal difference (goals scored - goals conceded)\n",
    "# 5 previous games for home team and away team\n",
    "train_features['AHTGD5PG'] = train_features.AHTGS5PG - train_features.AHTGC5PG\n",
    "train_features['AATGD5PG'] = train_features.AATGS5PG - train_features.AATGC5PG\n",
    "\n",
    "# 5 previous home games for home team\n",
    "train_features['AHTGD5PHG'] = train_features.AHTGS5PHG - \\\n",
    "    train_features.AHTGC5PHG\n",
    "\n",
    "# 5 previous away games for away team\n",
    "train_features['AATGD5PAG'] = train_features.AATGS5PAG - \\\n",
    "    train_features.AATGC5PAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove date column\n",
    "train_features.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert division into ordinal numbers\n",
    "# premier league\n",
    "prem = train_features['Div'] == 'E0'\n",
    "prem_idx = prem[prem].index.values\n",
    "train_features.loc[prem_idx, 'Div'] = 2\n",
    "# championship\n",
    "champ = train_features['Div'] == 'E1'\n",
    "champ_idx = champ[champ].index.values\n",
    "train_features.loc[champ_idx, 'Div'] = 1\n",
    "# league 1\n",
    "leag1 = train_features['Div'] == 'E2'\n",
    "leag1_idx = leag1[leag1].index.values\n",
    "train_features.loc[leag1_idx, 'Div'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['Div'] = train_features['Div'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home/away all avg sot... boxcox transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values above/below continuous outlier bounds\n",
    "features = load_train_features()\n",
    "for key in outlier_dict:\n",
    "    # if df has values above upper outlier bound\n",
    "    if np.sum(features[key] > outlier_dict[key][0]):\n",
    "        features[f'{key}_UPoutlier'] = 0\n",
    "        mask = features[key] > outlier_dict[key][0]\n",
    "        upper_idx = mask[mask].index.values\n",
    "        features.loc[upper_idx, f'{key}_UPoutlier'] = 1\n",
    "    # if df has values below lower outlier bound\n",
    "    if np.sum(features[key] < outlier_dict[key][1]):\n",
    "        features[f'{key}_LOWoutlier'] = 0\n",
    "        mask = features[key] < outlier_dict[key][1]\n",
    "        lower_idx = mask[mask].index.values\n",
    "        features.loc[lower_idx, f'{key}_LOWoutlier'] = 1\n",
    "\n",
    "# drop outliers for features we cant use\n",
    "non_feats = ['FTHG_UPoutlier', 'FTAG_UPoutlier', 'HS_UPoutlier', 'AS_UPoutlier', 'HST_UPoutlier', 'AST_UPoutlier',\n",
    "             'HF_UPoutlier', 'HF_LOWoutlier', 'AF_UPoutlier', 'HC_UPoutlier', 'AC_UPoutlier', 'HY_UPoutlier', 'AY_UPoutlier',\n",
    "             'HR_UPoutlier', 'AR_UPoutlier']\n",
    "features.drop(columns=non_feats, inplace=True)\n",
    "\n",
    "\n",
    "# save train_features\n",
    "save_train_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home/away team AHTGS5PG difference\n",
    "features = load_train_features()\n",
    "features['HA_AHTGS5PG_diff'] = features['AHTGS5PG'] - features['AATGS5PG']\n",
    "\n",
    "# save train_features\n",
    "save_train_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home/away team AHTP5PG difference\n",
    "features = load_train_features()\n",
    "features['HA_ATP5PG_diff'] = features['AHTP5PG'] - features['AATP5PG']\n",
    "\n",
    "# save train_features\n",
    "save_train_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average goals scored to average points ratio\n",
    "features = load_train_features()\n",
    "features.drop(columns=['AHT_GS_P5PG_ratio', 'AAT_GS_P5PG_ratio'], inplace=True)\n",
    "# home team\n",
    "features['AHT_GS_P5PG_ratio'] = (\n",
    "    features['AHTGS5PG'] + 1) / (features['AHTP5PG'] + 1)\n",
    "# away team\n",
    "features['AAT_GS_P5PG_ratio'] = (\n",
    "    features['AATGS5PG'] + 1) / (features['AATP5PG'] + 1)\n",
    "\n",
    "# save train_features\n",
    "save_train_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home - away football ground distance\n",
    "features = load_train_features()\n",
    "features['AwayTeamDist'] = np.nan\n",
    "geolocator = Nominatim(user_agent=\"football_ground_distance\")\n",
    "\n",
    "team_geo_loc_dict = {}\n",
    "for team in sorted(features['HomeTeam'].value_counts().index):\n",
    "    t = get_football_ground(team)\n",
    "    t_loc = geolocator.geocode(t[0])\n",
    "    t_geo_loc = (t_loc.latitude, t_loc.longitude)\n",
    "    team_geo_loc_dict[team] = t_geo_loc\n",
    "\n",
    "\n",
    "for h_team in sorted(features['HomeTeam'].value_counts().index):\n",
    "    away_teams = list(\n",
    "        set(features[(features['HomeTeam'] == h_team)]['AwayTeam'].values))\n",
    "    for a_team in away_teams:\n",
    "        h_team_loc = team_geo_loc_dict.get(h_team)\n",
    "        a_team_loc = team_geo_loc_dict.get(a_team)\n",
    "        a_team_dist = np.round(geodesic(h_team_loc, a_team_loc).miles, 2)\n",
    "        mask = (features['HomeTeam'] == h_team) & (\n",
    "            features['AwayTeam'] == a_team)\n",
    "        g_idx = mask[mask].index.values\n",
    "        features.loc[g_idx, 'AwayTeamDist'] = a_team_dist\n",
    "\n",
    "save_train_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home/ away stadium capacity difference\n",
    "features = load_train_features()\n",
    "\n",
    "features['AwayCapacityDiff'] = np.nan\n",
    "\n",
    "for h_team in sorted(features['HomeTeam'].value_counts().index):\n",
    "    away_teams = list(\n",
    "        set(features[(features['HomeTeam'] == h_team)]['AwayTeam'].values))\n",
    "    for a_team in away_teams:\n",
    "        htg = get_football_ground(h_team)\n",
    "        atg = get_football_ground(a_team)\n",
    "        cap_diff = atg[1] - htg[1]\n",
    "        mask = (features['HomeTeam'] == h_team) & (\n",
    "            features['AwayTeam'] == a_team)\n",
    "        g_idx = mask[mask].index.values\n",
    "        features.loc[g_idx, 'AwayCapacityDiff'] = cap_diff\n",
    "\n",
    "save_train_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin away ground distance\n",
    "features = load_train_features()\n",
    "features['AwayTeamDist_bin'] = np.floor_divide(features['AwayTeamDist'], 10)\n",
    "\n",
    "save_train_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin capacity difference\n",
    "features = load_train_features()\n",
    "features['AwayCapacityDiff_bin'] = np.floor_divide(\n",
    "    features['AwayCapacityDiff'], 1000)\n",
    "\n",
    "save_train_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local derby - distance 10 or below\n",
    "features = load_train_features()\n",
    "features['Local_Derby'] = 0\n",
    "\n",
    "mask = features['AwayTeamDist'] <= 10.0\n",
    "ld_idx = mask[mask].index.values\n",
    "features.loc[ld_idx, 'Local_Derby'] = 1\n",
    "\n",
    "save_train_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance > = 100\n",
    "features = load_train_features()\n",
    "features['Dist>=100'] = 0\n",
    "\n",
    "mask = features['AwayTeamDist'] >= 100\n",
    "d_idx = mask[mask].index.values\n",
    "features.loc[d_idx, 'Dist>=100'] = 1\n",
    "\n",
    "save_train_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run k means on train features with 4 clusters\n",
    "# observe clusters\n",
    "# engineer features for clusters\n",
    "# check association\n",
    "\n",
    "train_features = load_train_features()\n",
    "oh_train_feat = football_data_team_ohe(train_features)\n",
    "\n",
    "drop_cols = ['Div', 'FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC',\n",
    "             'AC', 'HY', 'AY', 'HR', 'AR']\n",
    "oh_train_feat.drop(columns=drop_cols, inplace=True)\n",
    "kmeans = KMeans(n_clusters=4, random_state=2).fit(oh_train_feat)\n",
    "train_features['cluster'] = kmeans.labels_\n",
    "\n",
    "for i in range(0, 4):\n",
    "    train_features[f'cluster_{i}'] = 0\n",
    "    mask = train_features['cluster'] == i\n",
    "    cl_idx = mask[mask].index.values\n",
    "    train_features.loc[cl_idx, f'cluster_{i}'] = 1\n",
    "\n",
    "train_features.drop(columns=['cluster'], inplace=True)\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# previous end of season position\n",
    "\n",
    "# load dictionary\n",
    "dict_file = open('season_dictionary.pkl', 'rb')\n",
    "season_dict = pickle.load(dict_file)\n",
    "dict_file.close()\n",
    "# load train features\n",
    "train_features = load_train_features()\n",
    "# create features for new data\n",
    "train_features['HT_PrevSeasonPos'] = np.nan\n",
    "train_features['AT_PrevSeasonPos'] = np.nan\n",
    "\n",
    "for i in range(0, 21):\n",
    "    if i == 0:\n",
    "        # get dict season.. change for dif vals of i!!\n",
    "        season = season_dict.get(f'99/0{i}')\n",
    "        first_half = train_features[(train_features['year'] == int(f'200{i}')) & (\n",
    "            train_features['month'] >= 8)]  # first half season\n",
    "        second_half = train_features[(train_features['year'] == int(\n",
    "            f'200{i+1}')) & (train_features['month'] < 8)]  # second half season\n",
    "    elif 0 < i < 10:\n",
    "        season = season_dict.get(f'0{i-1}/0{i}')\n",
    "        first_half = train_features[(train_features['year'] == int(f'200{i}')) & (\n",
    "            train_features['month'] >= 8)]  # first half season\n",
    "        if i == 9:\n",
    "            second_half = train_features[(train_features['year'] == int(\n",
    "                f'20{i+1}')) & (train_features['month'] < 8)]  # second half season\n",
    "        else:\n",
    "            second_half = train_features[(train_features['year'] == int(\n",
    "                f'200{i+1}')) & (train_features['month'] < 8)]  # second half season\n",
    "    elif i == 10:\n",
    "        season = season_dict.get(f'0{i-1}/{i}')\n",
    "        first_half = train_features[(train_features['year'] == int(f'20{i}')) & (\n",
    "            train_features['month'] >= 8)]  # first half season\n",
    "        second_half = train_features[(train_features['year'] == int(\n",
    "            f'20{i+1}')) & (train_features['month'] < 8)]  # second half season\n",
    "    else:\n",
    "        season = season_dict.get(f'{i-1}/{i}')\n",
    "        first_half = train_features[(train_features['year'] == int(f'20{i}')) & (\n",
    "            train_features['month'] >= 8)]  # first half season\n",
    "        second_half = train_features[(train_features['year'] == int(\n",
    "            f'20{i+1}')) & (train_features['month'] < 8)]  # second half season\n",
    "\n",
    "    table = season[0][1:]  # prem league but appending all standings into this\n",
    "    champ = season[1][1:]\n",
    "    le1 = season[2][1:]  # join each season to make full standings df\n",
    "    le2 = season[3][1:]\n",
    "    for l in [champ, le1, le2]:\n",
    "        for standing in l:\n",
    "            table.append(standing)\n",
    "    full_season = first_half.append(\n",
    "        second_half, ignore_index=True)  # first and second joined\n",
    "    h_teams = sorted(\n",
    "        full_season['HomeTeam'].value_counts().index)  # home teams\n",
    "    a_teams = sorted(\n",
    "        full_season['AwayTeam'].value_counts().index)  # away teams\n",
    "    for h_team in h_teams:\n",
    "        #     get masks for team in dictionary from data\n",
    "        h_first_mask = first_half['HomeTeam'] == h_team\n",
    "        h_second_mask = second_half['HomeTeam'] == h_team\n",
    "        # index of home team in data\n",
    "        h_first_idx = list(h_first_mask[h_first_mask].index.values)\n",
    "        h_second_idx = list(h_second_mask[h_second_mask].index.values)\n",
    "        h_mask_idx = sorted(h_first_idx + h_second_idx)\n",
    "#     get position from team in dictionary into new column\n",
    "        for position in table:\n",
    "            if position[1] == 'Wimbledon' and h_team == 'Milton Keynes Dons' and i == 4:\n",
    "                train_features.loc[h_mask_idx,\n",
    "                                   'HT_PrevSeasonPos'] = position[0]\n",
    "            if position[1] == 'Wimbledon' and h_team == 'AFC Wimbledon':\n",
    "                train_features.loc[h_mask_idx,\n",
    "                                   'HT_PrevSeasonPos'] = position[0]\n",
    "            if position[1] == 'Cheltenham Town' and h_team == 'Cheltenham':\n",
    "                train_features.loc[h_mask_idx,\n",
    "                                   'HT_PrevSeasonPos'] = position[0]\n",
    "            if position[1] == h_team:\n",
    "                # insert prev position if table team = h_team\n",
    "                train_features.loc[h_mask_idx,\n",
    "                                   'HT_PrevSeasonPos'] = position[0]\n",
    "    for a_team in a_teams:\n",
    "        a_first_mask = first_half['AwayTeam'] == a_team\n",
    "        a_second_mask = second_half['AwayTeam'] == a_team\n",
    "        # index of home team in data\n",
    "        a_first_idx = list(a_first_mask[a_first_mask].index.values)\n",
    "        a_second_idx = list(a_second_mask[a_second_mask].index.values)\n",
    "        a_mask_idx = sorted(a_first_idx + a_second_idx)\n",
    "        for position in table:\n",
    "            # season before mk dons were formed\n",
    "            if position[1] == 'Wimbledon' and a_team == 'Milton Keynes Dons' and i == 4:\n",
    "                train_features.loc[a_mask_idx,\n",
    "                                   'AT_PrevSeasonPos'] = position[0]\n",
    "            # wimbledon in dictionary afc wimbledon in data\n",
    "            if position[1] == 'Wimbledon' and a_team == 'AFC Wimbledon':\n",
    "                train_features.loc[a_mask_idx,\n",
    "                                   'AT_PrevSeasonPos'] = position[0]\n",
    "            # cheltenham town in dict and cheltenham in data\n",
    "            if position[1] == 'Cheltenham Town' and a_team == 'Cheltenham':\n",
    "                train_features.loc[a_mask_idx,\n",
    "                                   'AT_PrevSeasonPos'] = position[0]\n",
    "            if position[1] == a_team:\n",
    "                train_features.loc[a_mask_idx,\n",
    "                                   'AT_PrevSeasonPos'] = position[0]\n",
    "\n",
    "# save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert prev season position for ordinality\n",
    "# max(num_list) + 1 - x for x in num_list\n",
    "train_features = load_train_features()\n",
    "\n",
    "# change dtype from float to int\n",
    "train_features['HT_PrevSeasonPos'] = train_features['HT_PrevSeasonPos'].astype(\n",
    "    'int64')\n",
    "train_features['AT_PrevSeasonPos'] = train_features['AT_PrevSeasonPos'].astype(\n",
    "    'int64')\n",
    "# insert inv feat\n",
    "train_features['HT_PrevSeasonPos_inv'] = 0\n",
    "train_features['AT_PrevSeasonPos_inv'] = 0\n",
    "\n",
    "# home team prev season\n",
    "for i in range(1, max(train_features['HT_PrevSeasonPos']) + 1):  # max = 75\n",
    "    mask = train_features['HT_PrevSeasonPos'] == i\n",
    "    mask_idx = mask[mask].index.values\n",
    "    invert_val = max(train_features['HT_PrevSeasonPos']) + 1 - i\n",
    "    train_features.loc[mask_idx, 'HT_PrevSeasonPos_inv'] = invert_val\n",
    "\n",
    "for i in range(1, max(train_features['AT_PrevSeasonPos']) + 1):  # max = 75\n",
    "    mask = train_features['AT_PrevSeasonPos'] == i\n",
    "    mask_idx = mask[mask].index.values\n",
    "    invert_val = max(train_features['AT_PrevSeasonPos']) + 1 - i\n",
    "    train_features.loc[mask_idx, 'AT_PrevSeasonPos_inv'] = invert_val\n",
    "\n",
    "# drop original columns\n",
    "train_features.drop(columns=['HT_PrevSeasonPos',\n",
    "                             'AT_PrevSeasonPos'], inplace=True)\n",
    "# save features\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log of some features\n",
    "# exp width bins for away capacity diff\n",
    "# upper/ lowr quartile indicators for some features\n",
    "# any transaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box-cox power transform\n",
    "train_features = load_train_features()\n",
    "\n",
    "# goals scored 5pg\n",
    "train_features['bxcx_AATGS5PG'] = boxcox(\n",
    "    train_features['AATGS5PG'] + 1, lmbda=0.1677360888986696)\n",
    "train_features['bxcx_AHTGS5PG'] = boxcox(\n",
    "    train_features['AHTGS5PG'] + 1, lmbda=0.15663078083826068)\n",
    "# goals conceded 5pg\n",
    "train_features['bxcx_AHTGC5PG'] = boxcox(\n",
    "    train_features['AHTGC5PG'] + 1, lmbda=0.37450136993128647)\n",
    "train_features['bxcx_AATGC5PG'] = boxcox(\n",
    "    train_features['AATGC5PG'] + 1, lmbda=0.3435345631007946)\n",
    "# shots on target 5pg\n",
    "train_features['bxcx_AHTSOT5PG'] = boxcox(\n",
    "    train_features['AHTSOT5PG'] + 1, lmbda=0.13473011722266465)\n",
    "train_features['bxcx_AATSOT5PG'] = boxcox(\n",
    "    train_features['AATSOT5PG'] + 1, lmbda=0.15580637160487532)\n",
    "# goals scored/point 5pg ratio\n",
    "train_features['bxcx_AHT_GS_P5PG_ratio'] = boxcox(\n",
    "    train_features['AHT_GS_P5PG_ratio'] + 1, lmbda=-0.4193818135094843)\n",
    "train_features['bxcx_AAT_GS_P5PG_ratio'] = boxcox(\n",
    "    train_features['AAT_GS_P5PG_ratio'] + 1, lmbda=-0.42013380790196936)\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper/ lower quartiles\n",
    "\n",
    "train_features = load_train_features()\n",
    "\n",
    "# difference between home/away golas scored 5pg.. upper/lower quartiles\n",
    "train_features['HA_AHTGS5PG_diff_upqrt'] = 0\n",
    "train_features['HA_AHTGS5PG_diff_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['HA_AHTGS5PG_diff'].quantile([.25, .5, .75])[0.75]\n",
    "low_qrt = train_features['HA_AHTGS5PG_diff'].quantile([.25, .5, .75])[0.25]\n",
    "\n",
    "up_mask = train_features['HA_AHTGS5PG_diff'] >= up_qrt\n",
    "low_mask = train_features['HA_AHTGS5PG_diff'] <= low_qrt\n",
    "\n",
    "up_idx = up_mask[up_mask].index.values\n",
    "low_idx = low_mask[low_mask].index.values\n",
    "\n",
    "train_features.loc[up_idx, 'HA_AHTGS5PG_diff_upqrt'] = 1\n",
    "train_features.loc[low_idx, 'HA_AHTGS5PG_diff_lowqrt'] = 1\n",
    "\n",
    "# average goals conceded 5pg.. upper/lower quartiles\n",
    "\n",
    "train_features['AHTGC5PG_upqrt'] = 0\n",
    "train_features['AHTGC5PG_lowqrt'] = 0\n",
    "train_features['AATGC5PG_upqrt'] = 0\n",
    "train_features['AATGC5PG_lowqrt'] = 0\n",
    "\n",
    "h_up_qrt = train_features['AHTGC5PG'].quantile([.25, .5, .75])[0.75]\n",
    "h_low_qrt = train_features['AHTGC5PG'].quantile([.25, .5, .75])[0.25]\n",
    "a_up_qrt = train_features['AATGC5PG'].quantile([.25, .5, .75])[0.75]\n",
    "a_low_qrt = train_features['AATGC5PG'].quantile([.25, .5, .75])[0.25]\n",
    "\n",
    "h_up_mask = train_features['AHTGC5PG'] >= h_up_qrt\n",
    "h_low_mask = train_features['AHTGC5PG'] <= h_low_qrt\n",
    "a_up_mask = train_features['AATGC5PG'] >= a_up_qrt\n",
    "a_low_mask = train_features['AATGC5PG'] <= a_low_qrt\n",
    "\n",
    "h_up_idx = h_up_mask[h_up_mask].index.values\n",
    "h_low_idx = h_low_mask[h_low_mask].index.values\n",
    "a_up_idx = a_up_mask[a_up_mask].index.values\n",
    "a_low_idx = a_low_mask[a_low_mask].index.values\n",
    "\n",
    "train_features.loc[h_up_idx, 'AHTGC5PG_upqrt'] = 1\n",
    "train_features.loc[h_low_idx, 'AHTGC5PG_lowqrt'] = 1\n",
    "train_features.loc[a_up_idx, 'AATGC5PG_upqrt'] = 1\n",
    "train_features.loc[a_low_idx, 'AATGC5PG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction feature.. ahtgs5pg upper quartile, ahtgc5pg lower quartile\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['HT_GSGC_UPLOW_QRT'] = 0\n",
    "\n",
    "up_qrt = train_features['AHTGS5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTGC5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AHTGS5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AHTGC5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'HT_GSGC_UPLOW_QRT'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction feature.. aatgs5pg upper quartile, aatgc5pg lower quartile\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AT_GSGC_UPLOW_QRT'] = 0\n",
    "\n",
    "up_qrt = train_features['AATGS5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATGC5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AATGS5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AATGC5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AT_GSGC_UPLOW_QRT'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction feature.. ahtgs5pg upper qrt, aatgc5pg lower qrt\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AHTGS5PG_upqrt_AATGC5PG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AHTGS5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATGC5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AHTGS5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AATGC5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AHTGS5PG_upqrt_AATGC5PG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction feature.. aatgs5pg upper qrt, ahtgc5pg lower qrt\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AATGS5PG_upqrt_AHTGC5PG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AATGS5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTGC5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AATGS5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AHTGC5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AATGS5PG_upqrt_AHTGC5PG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. ahtgs5pg upper qrt, aatgs5pg lower qrt\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AHTGS5PG_upqrt_AATGS5PG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AHTGS5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATGS5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AHTGS5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AATGS5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AHTGS5PG_upqrt_AATGS5PG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. aatgs5pg upper qrt, ahtgs5pg lower qrt\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AATGS5PG_upqrt_AHTGS5PG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AATGS5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTGS5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AATGS5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AHTGS5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AATGS5PG_upqrt_AHTGS5PG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. ahtgs5phg upper qrt, aatgs5pag lower qrt\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AHTGS5PHG_upqrt_AATGS5PAG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AHTGS5PHG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATGS5PAG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AHTGS5PHG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AATGS5PAG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AHTGS5PHG_upqrt_AATGS5PAG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. aatgs5pag upper qrt, ahtgs5phg lower qrt\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AATGS5PAG_upqrt_AHTGS5PHG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AATGS5PAG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTGS5PHG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AATGS5PAG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AHTGS5PHG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AATGS5PAG_upqrt_AHTGS5PHG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. ahtsot5pg upper qrt, aatsot5pg lower qrt\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AHTSOT5PG_upqrt_AATSOT5PG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AHTSOT5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATSOT5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AHTSOT5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AATSOT5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AHTSOT5PG_upqrt_AATSOT5PG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. aatsot5pg upper qrt, ahtsot5pg lower qrt\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AATSOT5PG_upqrt_AHTSOT5PG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AATSOT5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTSOT5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AATSOT5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AHTSOT5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AATSOT5PG_upqrt_AHTSOT5PG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. ahtsot5phg upper qrt, aatsot5pag lower qrt\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AHTSOT5PHG_upqrt_AATSOT5PAG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AHTSOT5PHG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATSOT5PAG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AHTSOT5PHG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AATSOT5PAG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AHTSOT5PHG_upqrt_AATSOT5PAG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. aatsot5pag upper qrt, ahtsot5phg lower qrt\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AATSOT5PAG_upqrt_AHTSOT5PHG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AATSOT5PAG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTSOT5PHG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AATSOT5PAG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AHTSOT5PHG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AATSOT5PAG_upqrt_AHTSOT5PHG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. ahtgc5pg upper qrt, aatgc5pg lower qrt\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AHTGC5PG_upqrt_AATGC5PG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AHTGC5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATGC5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AHTGC5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AATGC5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AHTGC5PG_upqrt_AATGC5PG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. aatgc5pg upper qrt, ahtgc5pg lower qrt\n",
    "train_features = load_train_features()\n",
    "\n",
    "train_features['AATGC5PG_upqrt_AHTGC5PG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AATGC5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTGC5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = train_features['AATGC5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = train_features['AHTGC5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "train_features.loc[common_indices, 'AATGC5PG_upqrt_AHTGC5PG_lowqrt'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# awaycapacitydiff_bin below 0.2 quantiles, ahtgs5pg >= 2.2 & ahtgc5pg < 0.8\n",
    "train_features = load_train_features()\n",
    "train_features['HTbigcapacitydiff_highgs5pg_lowgc5pg'] = 0\n",
    "\n",
    "qnt = train_features['AwayCapacityDiff_bin'].quantile(\n",
    "    [.1, .2, .3, .4, .5, .6, .7, .8, .9])[0.2]\n",
    "acd_b = train_features[train_features['AwayCapacityDiff_bin'] < qnt]\n",
    "mask = (acd_b['AHTGS5PG'] >= 2.2) & (acd_b['AHTGC5PG'] < 0.8)\n",
    "mask_idx = mask[mask].index.values\n",
    "train_features.loc[mask_idx, 'HTbigcapacitydiff_highgs5pg_lowgc5pg'] = 1\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power and quantile normality transformations of continuous features\n",
    "train_features = load_train_features()\n",
    "\n",
    "box_cox = ['AHTSOT5PG', 'AATSOT5PG', 'AHTSOT5PHG',\n",
    "           'AATSOT5PAG', 'AHTP5PG', 'AHTGS_SOT5PHG_ratio']\n",
    "quant = ['AHTGS5PG', 'AATGS5PG', 'AHTGC5PG', 'AATGC5PG', 'AHTGS5PHG', 'AATGS5PAG', 'AHTGC5PHG', 'AATGC5PAG', 'AHTGS_SOT5PG_ratio',\n",
    "         'AATGS_SOT5PG_ratio', 'AATGS_SOT5PAG_ratio', 'AHTGD5PG', 'AATGD5PG', 'AHTGD5PHG', 'AATGD5PAG', 'HA_AHTGS5PG_diff',\n",
    "         'HA_ATP5PG_diff', 'AHT_GS_P5PG_ratio', 'AAT_GS_P5PG_ratio', 'AwayTeamDist', 'AwayCapacityDiff_bin', 'AwayTeamDist_bin',\n",
    "         'bxcx_AATGS5PG', 'bxcx_AHTGS5PG', 'bxcx_AHTGC5PG', 'bxcx_AHTSOT5PG', 'bxcx_AATSOT5PG', 'bxcx_AHT_GS_P5PG_ratio',\n",
    "         'bxcx_AAT_GS_P5PG_ratio', 'bxcx_AATGC5PG']\n",
    "\n",
    "bc_pt = PowerTransformer(method='box-cox')\n",
    "qt = QuantileTransformer(\n",
    "    n_quantiles=1000, output_distribution='normal', random_state=1)\n",
    "\n",
    "for col in train_features:\n",
    "    if col in box_cox:\n",
    "        train_features[f'{col}_bxcx_pwrTRANSFORM'] = bc_pt.fit_transform(\n",
    "            np.array(train_features[col] + 1).reshape(-1, 1))\n",
    "    elif col in quant:\n",
    "        train_features[f'{col}_quantileTRANSFORM'] = qt.fit_transform(\n",
    "            np.array(train_features[col]).reshape(-1, 1))\n",
    "\n",
    "save_train_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" all feature engineering above executed and saved \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate month from date\n",
    "test_features = load_test_features()\n",
    "month = []\n",
    "for i in range(len(test_features)):\n",
    "    date = test_features['Date'][i]\n",
    "    month.append(int(date.split('/')[1]))\n",
    "\n",
    "test_features['month'] = pd.Series(data=month)\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate year from date\n",
    "test_features = load_test_features()\n",
    "year = []\n",
    "for i in range(len(test_features)):\n",
    "    date = test_features['Date'][i]\n",
    "    if len(date.split('/')[2]) <= 2:  # 2 digits for year\n",
    "        year.append(datetime.datetime.strptime(\n",
    "            test_features['Date'][i], '%d/%m/%y').strftime('%Y'))\n",
    "    else:  # 4 digits for year\n",
    "        year.append(datetime.datetime.strptime(\n",
    "            test_features['Date'][i], '%d/%m/%Y').strftime('%Y'))\n",
    "\n",
    "test_features['year'] = pd.Series(data=year)\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day of week... 0 = monday, 6 = sunday\n",
    "test_features = load_test_features()\n",
    "date = pd.to_datetime(test_features['Date'], dayfirst=True)\n",
    "test_features['DayofWeek'] = date.dt.dayofweek\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# season month\n",
    "# start august\n",
    "test_features = load_test_features()\n",
    "test_features['season_month'] = 0\n",
    "s_mnth_order = [8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7]\n",
    "count = 0\n",
    "for mnth in s_mnth_order:\n",
    "    count += 1\n",
    "    fm = test_features['month'] == mnth\n",
    "    fm_idx = fm[fm].index.values\n",
    "    test_features.loc[fm_idx, 'season_month'] = count\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract cyclical nature from season month and day of week\n",
    "# month cyclical\n",
    "test_features = load_test_features()\n",
    "test_features['season_month_sin'] = np.sin(\n",
    "    2*np.pi*test_features.season_month/12)\n",
    "test_features['season_month_cos'] = np.cos(\n",
    "    2*np.pi*test_features.season_month/12)\n",
    "# day of week cyclical\n",
    "test_features['DayofWeek_sin'] = np.sin(2*np.pi*test_features.DayofWeek/7)\n",
    "test_features['DayofWeek_cos'] = np.cos(2*np.pi*test_features.DayofWeek/7)\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average goals scored to shots on target ratio (goals scored / shots on target)\n",
    "test_features = load_test_features()\n",
    "# 5 previous games for home team and away team\n",
    "test_features['AHTGS_SOT5PG_ratio'] = np.round(\n",
    "    test_features.AHTGS5PG / test_features.AHTSOT5PG, 2)\n",
    "test_features['AATGS_SOT5PG_ratio'] = np.round(\n",
    "    test_features.AATGS5PG / test_features.AATSOT5PG, 2)\n",
    "\n",
    "# 5 previous home games for home team\n",
    "test_features['AHTGS_SOT5PHG_ratio'] = np.round(\n",
    "    test_features.AHTGS5PHG / test_features.AHTSOT5PHG, 2)\n",
    "\n",
    "# 5 previous away games for away team\n",
    "test_features['AATGS_SOT5PAG_ratio'] = np.round(\n",
    "    test_features.AATGS5PAG / test_features.AATSOT5PAG, 2)\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average goal difference (goals scored - goals conceded)\n",
    "test_features = load_test_features()\n",
    "# 5 previous games for home team and away team\n",
    "test_features['AHTGD5PG'] = test_features.AHTGS5PG - test_features.AHTGC5PG\n",
    "test_features['AATGD5PG'] = test_features.AATGS5PG - test_features.AATGC5PG\n",
    "\n",
    "# 5 previous home games for home team\n",
    "test_features['AHTGD5PHG'] = test_features.AHTGS5PHG - test_features.AHTGC5PHG\n",
    "\n",
    "# 5 previous away games for away team\n",
    "test_features['AATGD5PAG'] = test_features.AATGS5PAG - test_features.AATGC5PAG\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove date column\n",
    "test_features = load_test_features()\n",
    "test_features.drop(columns=['Date'], inplace=True)\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert division into ordinal numbers\n",
    "test_features = load_test_features()\n",
    "# premier league\n",
    "prem = test_features['Div'] == 'E0'\n",
    "prem_idx = prem[prem].index.values\n",
    "test_features.loc[prem_idx, 'Div'] = 2\n",
    "# championship\n",
    "champ = test_features['Div'] == 'E1'\n",
    "champ_idx = champ[champ].index.values\n",
    "test_features.loc[champ_idx, 'Div'] = 1\n",
    "# league 1\n",
    "leag1 = test_features['Div'] == 'E2'\n",
    "leag1_idx = leag1[leag1].index.values\n",
    "test_features.loc[leag1_idx, 'Div'] = 0\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features['Div'] = test_features['Div'].astype('int64')\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# values above/below continuous outlier bounds\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "# remove wrong outlier columns from test features\n",
    "for f in test_features.columns:\n",
    "    if 'UPoutlier' in f or 'LOWoutlier' in f:\n",
    "        test_features.drop(columns=[f], inplace=True)\n",
    "\n",
    "# get correct columns for outlier features from train features\n",
    "# get outlier features\n",
    "of = [f for f in train_features.columns if 'UPoutlier' in f or 'LOWoutlier' in f]\n",
    "of = [f.replace('_UPoutlier', '')\n",
    "      for f in of]  # remove text to get original feature\n",
    "of = [f.replace('_LOWoutlier', '')\n",
    "      for f in of]  # remove text to get original feature\n",
    "of = [f for f in set(of)]  # get unique features\n",
    "\n",
    "for key in of:\n",
    "    # if df has values above upper outlier bound\n",
    "    if np.sum(test_features[key] > outlier_dict[key][0]):\n",
    "        # check if the same column exists in train features\n",
    "        if f'{key}_UPoutlier' in train_features.columns:\n",
    "            test_features[f'{key}_UPoutlier'] = 0\n",
    "            mask = test_features[key] > outlier_dict[key][0]\n",
    "            upper_idx = mask[mask].index.values\n",
    "            test_features.loc[upper_idx, f'{key}_UPoutlier'] = 1\n",
    "    # if df doesnt have values above create columns of 0's\n",
    "    if not np.sum(test_features[key] > outlier_dict[key][0]):\n",
    "        if f'{key}_UPoutlier' in train_features.columns:\n",
    "            test_features[f'{key}_UPoutlier'] = 0\n",
    "    # if df has values below lower outlier bound\n",
    "    if np.sum(test_features[key] < outlier_dict[key][1]):\n",
    "        if f'{key}_LOWoutlier' in train_features.columns:\n",
    "            test_features[f'{key}_LOWoutlier'] = 0\n",
    "            mask = test_features[key] < outlier_dict[key][1]\n",
    "            lower_idx = mask[mask].index.values\n",
    "            test_features.loc[lower_idx, f'{key}_LOWoutlier'] = 1\n",
    "    # if df doesnt have values below create columns of 0's\n",
    "    if not np.sum(test_features[key] < outlier_dict[key][1]):\n",
    "        if f'{key}_LOWoutlier' in train_features.columns:\n",
    "            test_features[f'{key}_LOWoutlier'] = 0\n",
    "    # if key == 'AATGD5PAG':\n",
    "    #    break\n",
    "\n",
    "# drop outliers for features we cant use\n",
    "# non_feats = ['FTHG_UPoutlier','FTAG_UPoutlier','HS_UPoutlier','AS_UPoutlier','HST_UPoutlier','AST_UPoutlier',\n",
    "#             'HF_UPoutlier','HF_LOWoutlier','AF_UPoutlier','HC_UPoutlier','AC_UPoutlier','HY_UPoutlier','AY_UPoutlier',\n",
    "#             'HR_UPoutlier','AR_UPoutlier']\n",
    "#test_features.drop(columns = non_feats, inplace = True)\n",
    "\n",
    "\n",
    "# save test_features\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home/away team AHTGS5PG difference\n",
    "test_features = load_test_features()\n",
    "test_features['HA_AHTGS5PG_diff'] = test_features['AHTGS5PG'] - \\\n",
    "    test_features['AATGS5PG']\n",
    "\n",
    "# save train_features\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home/away team AHTP5PG difference\n",
    "test_features = load_test_features()\n",
    "test_features['HA_ATP5PG_diff'] = test_features['AHTP5PG'] - \\\n",
    "    test_features['AATP5PG']\n",
    "\n",
    "# save train_features\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average goals scored to average points ratio\n",
    "test_features = load_test_features()\n",
    "#test_features.drop(columns = ['AHT_GS_P5PG_ratio', 'AAT_GS_P5PG_ratio'], inplace = True)\n",
    "# home team\n",
    "test_features['AHT_GS_P5PG_ratio'] = (\n",
    "    test_features['AHTGS5PG'] + 1) / (test_features['AHTP5PG'] + 1)\n",
    "# away team\n",
    "test_features['AAT_GS_P5PG_ratio'] = (\n",
    "    test_features['AATGS5PG'] + 1) / (test_features['AATP5PG'] + 1)\n",
    "\n",
    "# save train_features\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home - away football ground distance\n",
    "test_features = load_test_features()\n",
    "test_features['AwayTeamDist'] = np.nan\n",
    "geolocator = Nominatim(user_agent=\"football_ground_distance\")\n",
    "\n",
    "team_geo_loc_dict = {}\n",
    "for team in sorted(test_features['HomeTeam'].value_counts().index):\n",
    "    t = get_football_ground(team)\n",
    "    t_loc = geolocator.geocode(t[0])\n",
    "    t_geo_loc = (t_loc.latitude, t_loc.longitude)\n",
    "    team_geo_loc_dict[team] = t_geo_loc\n",
    "\n",
    "\n",
    "for h_team in sorted(test_features['HomeTeam'].value_counts().index):\n",
    "    away_teams = list(\n",
    "        set(test_features[(test_features['HomeTeam'] == h_team)]['AwayTeam'].values))\n",
    "    for a_team in away_teams:\n",
    "        h_team_loc = team_geo_loc_dict.get(h_team)\n",
    "        a_team_loc = team_geo_loc_dict.get(a_team)\n",
    "        a_team_dist = np.round(geodesic(h_team_loc, a_team_loc).miles, 2)\n",
    "        mask = (test_features['HomeTeam'] == h_team) & (\n",
    "            test_features['AwayTeam'] == a_team)\n",
    "        g_idx = mask[mask].index.values\n",
    "        test_features.loc[g_idx, 'AwayTeamDist'] = a_team_dist\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home/ away stadium capacity difference\n",
    "test_features = load_test_features()\n",
    "\n",
    "test_features['AwayCapacityDiff'] = np.nan\n",
    "\n",
    "for h_team in sorted(test_features['HomeTeam'].value_counts().index):\n",
    "    away_teams = list(\n",
    "        set(test_features[(test_features['HomeTeam'] == h_team)]['AwayTeam'].values))\n",
    "    for a_team in away_teams:\n",
    "        htg = get_football_ground(h_team)\n",
    "        atg = get_football_ground(a_team)\n",
    "        cap_diff = atg[1] - htg[1]\n",
    "        mask = (test_features['HomeTeam'] == h_team) & (\n",
    "            test_features['AwayTeam'] == a_team)\n",
    "        g_idx = mask[mask].index.values\n",
    "        test_features.loc[g_idx, 'AwayCapacityDiff'] = cap_diff\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin away ground distance\n",
    "test_features = load_test_features()\n",
    "test_features['AwayTeamDist_bin'] = np.floor_divide(\n",
    "    test_features['AwayTeamDist'], 10)\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin capacity difference\n",
    "test_features = load_test_features()\n",
    "test_features['AwayCapacityDiff_bin'] = np.floor_divide(\n",
    "    test_features['AwayCapacityDiff'], 1000)\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local derby - distance 10 or below\n",
    "test_features = load_test_features()\n",
    "test_features['Local_Derby'] = 0\n",
    "\n",
    "mask = test_features['AwayTeamDist'] <= 10.0\n",
    "ld_idx = mask[mask].index.values\n",
    "test_features.loc[ld_idx, 'Local_Derby'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance > = 100\n",
    "test_features = load_test_features()\n",
    "test_features['Dist>=100'] = 0\n",
    "\n",
    "mask = test_features['AwayTeamDist'] >= 100\n",
    "d_idx = mask[mask].index.values\n",
    "test_features.loc[d_idx, 'Dist>=100'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# previous end of season position\n",
    "\n",
    "# load dictionary\n",
    "dict_file = open('season_dictionary.pkl', 'rb')\n",
    "season_dict = pickle.load(dict_file)\n",
    "dict_file.close()\n",
    "# load test features\n",
    "test_features = load_test_features()\n",
    "# create features for new data\n",
    "test_features['HT_PrevSeasonPos'] = np.nan\n",
    "test_features['AT_PrevSeasonPos'] = np.nan\n",
    "\n",
    "for i in range(0, 21):\n",
    "    if i == 0:\n",
    "        # get dict season.. change for dif vals of i!!\n",
    "        season = season_dict.get(f'99/0{i}')\n",
    "        first_half = test_features[(test_features['year'] == int(f'200{i}')) & (\n",
    "            test_features['month'] >= 8)]  # first half season\n",
    "        second_half = test_features[(test_features['year'] == int(\n",
    "            f'200{i+1}')) & (test_features['month'] < 8)]  # second half season\n",
    "    elif 0 < i < 10:\n",
    "        season = season_dict.get(f'0{i-1}/0{i}')\n",
    "        first_half = test_features[(test_features['year'] == int(f'200{i}')) & (\n",
    "            test_features['month'] >= 8)]  # first half season\n",
    "        if i == 9:\n",
    "            second_half = test_features[(test_features['year'] == int(\n",
    "                f'20{i+1}')) & (test_features['month'] < 8)]  # second half season\n",
    "        else:\n",
    "            second_half = test_features[(test_features['year'] == int(\n",
    "                f'200{i+1}')) & (test_features['month'] < 8)]  # second half season\n",
    "    elif i == 10:\n",
    "        season = season_dict.get(f'0{i-1}/{i}')\n",
    "        first_half = test_features[(test_features['year'] == int(f'20{i}')) & (\n",
    "            test_features['month'] >= 8)]  # first half season\n",
    "        second_half = test_features[(test_features['year'] == int(\n",
    "            f'20{i+1}')) & (test_features['month'] < 8)]  # second half season\n",
    "    else:\n",
    "        season = season_dict.get(f'{i-1}/{i}')\n",
    "        first_half = test_features[(test_features['year'] == int(f'20{i}')) & (\n",
    "            test_features['month'] >= 8)]  # first half season\n",
    "        second_half = test_features[(test_features['year'] == int(\n",
    "            f'20{i+1}')) & (test_features['month'] < 8)]  # second half season\n",
    "\n",
    "    table = season[0][1:]  # prem league but appending all standings into this\n",
    "    champ = season[1][1:]\n",
    "    le1 = season[2][1:]  # join each season to make full standings df\n",
    "    le2 = season[3][1:]\n",
    "    for l in [champ, le1, le2]:\n",
    "        for standing in l:\n",
    "            table.append(standing)\n",
    "    full_season = first_half.append(\n",
    "        second_half, ignore_index=True)  # first and second joined\n",
    "    h_teams = sorted(\n",
    "        full_season['HomeTeam'].value_counts().index)  # home teams\n",
    "    a_teams = sorted(\n",
    "        full_season['AwayTeam'].value_counts().index)  # away teams\n",
    "    for h_team in h_teams:\n",
    "        #     get masks for team in dictionary from data\n",
    "        h_first_mask = first_half['HomeTeam'] == h_team\n",
    "        h_second_mask = second_half['HomeTeam'] == h_team\n",
    "        # index of home team in data\n",
    "        h_first_idx = list(h_first_mask[h_first_mask].index.values)\n",
    "        h_second_idx = list(h_second_mask[h_second_mask].index.values)\n",
    "        h_mask_idx = sorted(h_first_idx + h_second_idx)\n",
    "#     get position from team in dictionary into new column\n",
    "        for position in table:\n",
    "            if position[1] == 'Wimbledon' and h_team == 'Milton Keynes Dons' and i == 4:\n",
    "                test_features.loc[h_mask_idx, 'HT_PrevSeasonPos'] = position[0]\n",
    "            if position[1] == 'Wimbledon' and h_team == 'AFC Wimbledon':\n",
    "                test_features.loc[h_mask_idx, 'HT_PrevSeasonPos'] = position[0]\n",
    "            if position[1] == 'Cheltenham Town' and h_team == 'Cheltenham':\n",
    "                test_features.loc[h_mask_idx, 'HT_PrevSeasonPos'] = position[0]\n",
    "            if position[1] == h_team:\n",
    "                # insert prev position if table team = h_team\n",
    "                test_features.loc[h_mask_idx, 'HT_PrevSeasonPos'] = position[0]\n",
    "    for a_team in a_teams:\n",
    "        a_first_mask = first_half['AwayTeam'] == a_team\n",
    "        a_second_mask = second_half['AwayTeam'] == a_team\n",
    "        # index of home team in data\n",
    "        a_first_idx = list(a_first_mask[a_first_mask].index.values)\n",
    "        a_second_idx = list(a_second_mask[a_second_mask].index.values)\n",
    "        a_mask_idx = sorted(a_first_idx + a_second_idx)\n",
    "        for position in table:\n",
    "            # season before mk dons were formed\n",
    "            if position[1] == 'Wimbledon' and a_team == 'Milton Keynes Dons' and i == 4:\n",
    "                test_features.loc[a_mask_idx, 'AT_PrevSeasonPos'] = position[0]\n",
    "            # wimbledon in dictionary afc wimbledon in data\n",
    "            if position[1] == 'Wimbledon' and a_team == 'AFC Wimbledon':\n",
    "                test_features.loc[a_mask_idx, 'AT_PrevSeasonPos'] = position[0]\n",
    "            # cheltenham town in dict and cheltenham in data\n",
    "            if position[1] == 'Cheltenham Town' and a_team == 'Cheltenham':\n",
    "                test_features.loc[a_mask_idx, 'AT_PrevSeasonPos'] = position[0]\n",
    "            if position[1] == a_team:\n",
    "                test_features.loc[a_mask_idx, 'AT_PrevSeasonPos'] = position[0]\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert prev season position for ordinality\n",
    "# max(num_list) + 1 - x for x in num_list\n",
    "test_features = load_test_features()\n",
    "\n",
    "# change dtype from float to int\n",
    "test_features['HT_PrevSeasonPos'] = test_features['HT_PrevSeasonPos'].astype(\n",
    "    'int64')\n",
    "test_features['AT_PrevSeasonPos'] = test_features['AT_PrevSeasonPos'].astype(\n",
    "    'int64')\n",
    "# insert inv feat\n",
    "test_features['HT_PrevSeasonPos_inv'] = 0\n",
    "test_features['AT_PrevSeasonPos_inv'] = 0\n",
    "\n",
    "# home team prev season\n",
    "for i in range(1, max(test_features['HT_PrevSeasonPos']) + 1):  # max = 75\n",
    "    mask = test_features['HT_PrevSeasonPos'] == i\n",
    "    mask_idx = mask[mask].index.values\n",
    "    invert_val = max(test_features['HT_PrevSeasonPos']) + 1 - i\n",
    "    test_features.loc[mask_idx, 'HT_PrevSeasonPos_inv'] = invert_val\n",
    "\n",
    "for i in range(1, max(test_features['AT_PrevSeasonPos']) + 1):  # max = 75\n",
    "    mask = test_features['AT_PrevSeasonPos'] == i\n",
    "    mask_idx = mask[mask].index.values\n",
    "    invert_val = max(test_features['AT_PrevSeasonPos']) + 1 - i\n",
    "    test_features.loc[mask_idx, 'AT_PrevSeasonPos_inv'] = invert_val\n",
    "\n",
    "# drop original columns\n",
    "test_features.drop(columns=['HT_PrevSeasonPos',\n",
    "                            'AT_PrevSeasonPos'], inplace=True)\n",
    "# save features\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box-cox power transform\n",
    "test_features = load_test_features()\n",
    "\n",
    "# goals scored 5pg\n",
    "test_features['bxcx_AATGS5PG'] = boxcox(\n",
    "    test_features['AATGS5PG'] + 1, lmbda=0.1677360888986696)\n",
    "test_features['bxcx_AHTGS5PG'] = boxcox(\n",
    "    test_features['AHTGS5PG'] + 1, lmbda=0.15663078083826068)\n",
    "# goals conceded 5pg\n",
    "test_features['bxcx_AHTGC5PG'] = boxcox(\n",
    "    test_features['AHTGC5PG'] + 1, lmbda=0.37450136993128647)\n",
    "test_features['bxcx_AATGC5PG'] = boxcox(\n",
    "    test_features['AATGC5PG'] + 1, lmbda=0.3435345631007946)\n",
    "# shots on target 5pg\n",
    "test_features['bxcx_AHTSOT5PG'] = boxcox(\n",
    "    test_features['AHTSOT5PG'] + 1, lmbda=0.13473011722266465)\n",
    "test_features['bxcx_AATSOT5PG'] = boxcox(\n",
    "    test_features['AATSOT5PG'] + 1, lmbda=0.15580637160487532)\n",
    "# goals scored/point 5pg ratio\n",
    "test_features['bxcx_AHT_GS_P5PG_ratio'] = boxcox(\n",
    "    test_features['AHT_GS_P5PG_ratio'] + 1, lmbda=-0.4193818135094843)\n",
    "test_features['bxcx_AAT_GS_P5PG_ratio'] = boxcox(\n",
    "    test_features['AAT_GS_P5PG_ratio'] + 1, lmbda=-0.42013380790196936)\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper/ lower quartiles\n",
    "\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "# difference between home/away golas scored 5pg.. upper/lower quartiles\n",
    "test_features['HA_AHTGS5PG_diff_upqrt'] = 0\n",
    "test_features['HA_AHTGS5PG_diff_lowqrt'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['HA_AHTGS5PG_diff'].quantile([.25, .5, .75])[0.75]\n",
    "low_qrt = train_features['HA_AHTGS5PG_diff'].quantile([.25, .5, .75])[0.25]\n",
    "\n",
    "up_mask = test_features['HA_AHTGS5PG_diff'] >= up_qrt\n",
    "low_mask = test_features['HA_AHTGS5PG_diff'] <= low_qrt\n",
    "\n",
    "up_idx = up_mask[up_mask].index.values\n",
    "low_idx = low_mask[low_mask].index.values\n",
    "\n",
    "test_features.loc[up_idx, 'HA_AHTGS5PG_diff_upqrt'] = 1\n",
    "test_features.loc[low_idx, 'HA_AHTGS5PG_diff_lowqrt'] = 1\n",
    "\n",
    "# average goals conceded 5pg.. upper/lower quartiles\n",
    "\n",
    "test_features['AHTGC5PG_upqrt'] = 0\n",
    "test_features['AHTGC5PG_lowqrt'] = 0\n",
    "test_features['AATGC5PG_upqrt'] = 0\n",
    "test_features['AATGC5PG_lowqrt'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "h_up_qrt = train_features['AHTGC5PG'].quantile([.25, .5, .75])[0.75]\n",
    "h_low_qrt = train_features['AHTGC5PG'].quantile([.25, .5, .75])[0.25]\n",
    "a_up_qrt = train_features['AATGC5PG'].quantile([.25, .5, .75])[0.75]\n",
    "a_low_qrt = train_features['AATGC5PG'].quantile([.25, .5, .75])[0.25]\n",
    "\n",
    "h_up_mask = test_features['AHTGC5PG'] >= h_up_qrt\n",
    "h_low_mask = test_features['AHTGC5PG'] <= h_low_qrt\n",
    "a_up_mask = test_features['AATGC5PG'] >= a_up_qrt\n",
    "a_low_mask = test_features['AATGC5PG'] <= a_low_qrt\n",
    "\n",
    "h_up_idx = h_up_mask[h_up_mask].index.values\n",
    "h_low_idx = h_low_mask[h_low_mask].index.values\n",
    "a_up_idx = a_up_mask[a_up_mask].index.values\n",
    "a_low_idx = a_low_mask[a_low_mask].index.values\n",
    "\n",
    "test_features.loc[h_up_idx, 'AHTGC5PG_upqrt'] = 1\n",
    "test_features.loc[h_low_idx, 'AHTGC5PG_lowqrt'] = 1\n",
    "test_features.loc[a_up_idx, 'AATGC5PG_upqrt'] = 1\n",
    "test_features.loc[a_low_idx, 'AATGC5PG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction feature.. ahtgs5pg upper quartile, ahtgc5pg lower quartile\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['HT_GSGC_UPLOW_QRT'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['AHTGS5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTGC5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AHTGS5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AHTGC5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'HT_GSGC_UPLOW_QRT'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction feature.. aatgs5pg upper quartile, aatgc5pg lower quartile\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AT_GSGC_UPLOW_QRT'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['AATGS5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATGC5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AATGS5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AATGC5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AT_GSGC_UPLOW_QRT'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction feature.. ahtgs5pg upper qrt, aatgc5pg lower qrt\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AHTGS5PG_upqrt_AATGC5PG_lowqrt'] = 0\n",
    "\n",
    "up_qrt = train_features['AHTGS5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATGC5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AHTGS5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AATGC5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AHTGS5PG_upqrt_AATGC5PG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction feature.. aatgs5pg upper qrt, ahtgc5pg lower qrt\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AATGS5PG_upqrt_AHTGC5PG_lowqrt'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['AATGS5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTGC5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AATGS5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AHTGC5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AATGS5PG_upqrt_AHTGC5PG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. ahtgs5pg upper qrt, aatgs5pg lower qrt\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AHTGS5PG_upqrt_AATGS5PG_lowqrt'] = 0\n",
    "# get upper/lowwr quantiles from train data\n",
    "up_qrt = train_features['AHTGS5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATGS5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AHTGS5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AATGS5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AHTGS5PG_upqrt_AATGS5PG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. aatgs5pg upper qrt, ahtgs5pg lower qrt\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AATGS5PG_upqrt_AHTGS5PG_lowqrt'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['AATGS5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTGS5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AATGS5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AHTGS5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AATGS5PG_upqrt_AHTGS5PG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. ahtgs5phg upper qrt, aatgs5pag lower qrt\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AHTGS5PHG_upqrt_AATGS5PAG_lowqrt'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['AHTGS5PHG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATGS5PAG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AHTGS5PHG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AATGS5PAG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AHTGS5PHG_upqrt_AATGS5PAG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. aatgs5pag upper qrt, ahtgs5phg lower qrt\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AATGS5PAG_upqrt_AHTGS5PHG_lowqrt'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['AATGS5PAG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTGS5PHG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AATGS5PAG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AHTGS5PHG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AATGS5PAG_upqrt_AHTGS5PHG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. ahtsot5pg upper qrt, aatsot5pg lower qrt\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AHTSOT5PG_upqrt_AATSOT5PG_lowqrt'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['AHTSOT5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATSOT5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AHTSOT5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AATSOT5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AHTSOT5PG_upqrt_AATSOT5PG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. aatsot5pg upper qrt, ahtsot5pg lower qrt\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AATSOT5PG_upqrt_AHTSOT5PG_lowqrt'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['AATSOT5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTSOT5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AATSOT5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AHTSOT5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AATSOT5PG_upqrt_AHTSOT5PG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. ahtsot5phg upper qrt, aatsot5pag lower qrt\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AHTSOT5PHG_upqrt_AATSOT5PAG_lowqrt'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['AHTSOT5PHG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATSOT5PAG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AHTSOT5PHG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AATSOT5PAG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AHTSOT5PHG_upqrt_AATSOT5PAG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. aatsot5pag upper qrt, ahtsot5phg lower qrt\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AATSOT5PAG_upqrt_AHTSOT5PHG_lowqrt'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['AATSOT5PAG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTSOT5PHG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AATSOT5PAG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AHTSOT5PHG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AATSOT5PAG_upqrt_AHTSOT5PHG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. ahtgc5pg upper qrt, aatgc5pg lower qrt\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AHTGC5PG_upqrt_AATGC5PG_lowqrt'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['AHTGC5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AATGC5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AHTGC5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AATGC5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AHTGC5PG_upqrt_AATGC5PG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interation feature.. aatgc5pg upper qrt, ahtgc5pg lower qrt\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "\n",
    "test_features['AATGC5PG_upqrt_AHTGC5PG_lowqrt'] = 0\n",
    "# get upper/lower quantiles from train data\n",
    "up_qrt = train_features['AATGC5PG'].quantile([.75])[0.75]\n",
    "low_qrt = train_features['AHTGC5PG'].quantile([.25])[0.25]\n",
    "\n",
    "up_qrt_mask = test_features['AATGC5PG'] >= up_qrt\n",
    "up_qrt_mask_idx = up_qrt_mask[up_qrt_mask].index.values\n",
    "low_qrt_mask = test_features['AHTGC5PG'] <= low_qrt\n",
    "low_qrt_mask_idx = low_qrt_mask[low_qrt_mask].index.values\n",
    "\n",
    "up_qrt_mask_set = set(up_qrt_mask_idx)\n",
    "common_indices = list(sorted(up_qrt_mask_set.intersection(low_qrt_mask_idx)))\n",
    "\n",
    "test_features.loc[common_indices, 'AATGC5PG_upqrt_AHTGC5PG_lowqrt'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# awaycapacitydiff_bin below 0.2 quantiles, ahtgs5pg >= 2.2 & ahtgc5pg < 0.8\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "test_features['HTbigcapacitydiff_highgs5pg_lowgc5pg'] = 0\n",
    "# get lower quantile from train data\n",
    "qnt = train_features['AwayCapacityDiff_bin'].quantile(\n",
    "    [.1, .2, .3, .4, .5, .6, .7, .8, .9])[0.2]\n",
    "acd_b = test_features[test_features['AwayCapacityDiff_bin'] < qnt]\n",
    "mask = (acd_b['AHTGS5PG'] >= 2.2) & (acd_b['AHTGC5PG'] < 0.8)\n",
    "mask_idx = mask[mask].index.values\n",
    "test_features.loc[mask_idx, 'HTbigcapacitydiff_highgs5pg_lowgc5pg'] = 1\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power and quantile normality transformations of continuous features\n",
    "test_features = load_test_features()\n",
    "train_features = load_train_features()\n",
    "# drop columns from previous execution\n",
    "for col in test_features.columns:\n",
    "    if 'TRANSFORM' in col:\n",
    "        test_features.drop(columns=[col], inplace=True)\n",
    "\n",
    "box_cox = ['AHTSOT5PG', 'AATSOT5PG', 'AHTSOT5PHG',\n",
    "           'AATSOT5PAG', 'AHTP5PG', 'AHTGS_SOT5PHG_ratio']\n",
    "quant = ['AHTGS5PG', 'AATGS5PG', 'AHTGC5PG', 'AATGC5PG', 'AHTGS5PHG', 'AATGS5PAG', 'AHTGC5PHG', 'AATGC5PAG', 'AHTGS_SOT5PG_ratio',\n",
    "         'AATGS_SOT5PG_ratio', 'AATGS_SOT5PAG_ratio', 'AHTGD5PG', 'AATGD5PG', 'AHTGD5PHG', 'AATGD5PAG', 'HA_AHTGS5PG_diff',\n",
    "         'HA_ATP5PG_diff', 'AHT_GS_P5PG_ratio', 'AAT_GS_P5PG_ratio', 'AwayTeamDist', 'AwayCapacityDiff_bin', 'AwayTeamDist_bin',\n",
    "         'bxcx_AATGS5PG', 'bxcx_AHTGS5PG', 'bxcx_AHTGC5PG', 'bxcx_AHTSOT5PG', 'bxcx_AATSOT5PG', 'bxcx_AHT_GS_P5PG_ratio',\n",
    "         'bxcx_AAT_GS_P5PG_ratio', 'bxcx_AATGC5PG']\n",
    "\n",
    "for col in test_features:\n",
    "    bc_pt = PowerTransformer(method='box-cox')\n",
    "    qt = QuantileTransformer(\n",
    "        n_quantiles=1000, output_distribution='normal', random_state=1)\n",
    "    if col in box_cox:\n",
    "        # fit on train data, transform test data\n",
    "        bc_pt.fit(np.array(train_features[col] + 1).reshape(-1, 1))\n",
    "        test_features[f'{col}_bxcx_pwrTRANSFORM'] = bc_pt.transform(\n",
    "            np.array(test_features[col] + 1).reshape(-1, 1))\n",
    "    elif col in quant:\n",
    "        # fit on train data, transform test data\n",
    "        qt.fit(np.array(train_features[col]).reshape(-1, 1))\n",
    "        test_features[f'{col}_quantileTRANSFORM'] = qt.transform(\n",
    "            np.array(test_features[col]).reshape(-1, 1))\n",
    "\n",
    "save_test_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" all feature engineering above executed and saved \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Summary -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of features engineered; \n",
    "\n",
    "date extraction (days, months, years), cyclical nature (days, months, years), ratios, differences, conversions, indicators for upper and lower outliers, binned features, ordinality inversion, indicators for less than or greater than, box-cox power transforms, upper/lower quartile indicators, feature interactions, quantile indicators and normality transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Baseline --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home baseline test\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_features = football_data_team_ohe(home_train_features)\n",
    "sc = StandardScaler()\n",
    "home_train_features = sc.fit_transform(home_train_features)\n",
    "home_train_target, _ = load_home_targets()\n",
    "model = DummyClassifier(strategy='constant', constant=0)\n",
    "scores = evaluate_model(home_train_features,\n",
    "                        home_train_target, model, k_splits=10)\n",
    "print(f'Home baseline Fbeta Score: {np.mean(scores)}, Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away baseline test\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_train_features = football_data_team_ohe(away_train_features)\n",
    "sc = StandardScaler()\n",
    "away_train_features = sc.fit_transform(away_train_features)\n",
    "away_train_target, _ = load_away_targets()\n",
    "model = DummyClassifier(strategy='constant', constant=0)\n",
    "scores = evaluate_model(away_train_features,\n",
    "                        away_train_target, model, k_splits=10)\n",
    "print(f'Away baseline Fbeta Score: {np.mean(scores)}, Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home data simple model\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_best_feat = home_train_features['AwayCapacityDiff']\n",
    "home_train_target, _ = load_home_targets()\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "scores = evaluate_model(np.array(home_best_feat).reshape(-1, 1),\n",
    "                        home_train_target, model, k_splits=10)\n",
    "print(\n",
    "    f'Home simple model avg Fbeta score: {np.mean(scores)}, Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away data simple model\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_best_feat = away_train_features['AwayCapacityDiff']\n",
    "away_train_target, _ = load_away_targets()\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "scores = evaluate_model(np.array(away_best_feat).reshape(-1, 1),\n",
    "                        away_train_target, model, k_splits=10)\n",
    "print(\n",
    "    f'AWay simple model avg Fbeta score: {np.mean(scores)}, Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Summary -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fbeta metric is setup to provide slightly more weight to maximise recall (minimise false negatives) which can be seen in this domain to allow the models to be more risk accepting (decrease false negatives increase false positives (trade off)), which in english is reduce the number of no win predictions when it should be win but with a non negotiable trade off of inccurring more win predictions when it should be no win therefore allowing more risk. If we were to maximise precision (minimise false positives) this can be seen as making the model more conservative (decrease false positives increase false negatives (trade off)), which in english is reducing the number of win predictions when it should be no win but with a non negotiable trade off of inccurring more no win predictions when it should be win therefore a more conservative model. \n",
    "\n",
    "Fbeta for the models being tested is weighted .2 above the harmonic mean. Altering this weighting could provide better or worse performing models for this domain and should be looked into when rerunnng analaysis.\n",
    "\n",
    "Home and away fbeta score baselines for predicting majority class:\n",
    "\n",
    "    Home fbeta baseline: 0.4183104482317975\n",
    "    Away fbeta baseline: 0.6102523359914978\n",
    "    \n",
    "Home and away simple model fbeta scores, where only the best feature is used with a logistic regression model:\n",
    "\n",
    "    Home simple model Fbeta score: 0.555328458299842\n",
    "    Away simple model Fbeta score: 0.5644830306923153\n",
    "    \n",
    "It can be seen that the home model performance increases substantially when the top feature is used to predict but the away model performance decreases some what. This performance decrease could be due to the bigger class imbalance for the away model with only an approx. 29% away win proportion compared to approx. 45% home win proportion. The decrease could be due to the away simple model predicting more false positives (predicting away win when its actually away no win (lose or draw)). This can be alleviated by performing oversampling and undersampling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Modelling --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home model test with home/away teams\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_features = football_data_team_ohe(home_train_features)\n",
    "home_train_target, _ = load_home_targets()\n",
    "sc = StandardScaler()\n",
    "\n",
    "ml_models, ml_names = get_ml_models()\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('model', ml_models[i])\n",
    "        ]\n",
    "    )\n",
    "    scores = evaluate_model(home_train_features,\n",
    "                            home_train_target, pipe, k_splits=10)\n",
    "    model_list.append(ml_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg Fbeta': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg Fbeta', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home model test without home/away teams\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "ml_models, ml_names = get_ml_models()\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    print(f'Running {ml_names[i]} Model')\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('model', ml_models[i])\n",
    "        ]\n",
    "    )\n",
    "    scores = evaluate_model(home_train_features, np.array(\n",
    "        home_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "    model_list.append(ml_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg Fbeta': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg Fbeta', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hypothesis test for ml models with home data\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit_transform(home_train_features)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "mod_names = ['GNB', 'GB', 'AB', 'XGB', 'RF']\n",
    "ml_models, ml_names = get_ml_models()\n",
    "\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    if ml_names[i] == 'LR':\n",
    "        for j in range(len(ml_models)):\n",
    "            if ml_names[j] in mod_names:\n",
    "\n",
    "                t, p = paired_ttest_5x2cv(\n",
    "                    estimator1=ml_models[i],\n",
    "                    estimator2=ml_models[j],\n",
    "                    X=home_train_features,\n",
    "                    y=np.array(home_train_target).reshape(-1,),\n",
    "                    scoring=fbeta_metric,\n",
    "                    random_seed=1\n",
    "                )\n",
    "                if p <= 0.05:\n",
    "                    print(\n",
    "                        f'{ml_names[i]} & {ml_names[j]}: Difference in model performance is most likely real')\n",
    "                else:\n",
    "                    print(\n",
    "                        f'{ml_names[i]} & {ml_names[j]}: Both models are most likely to have the same performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home model test without home/away teams and transformed continuous data\n",
    "home_train_features = load_home_train_features_with_drop_transformed()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "ml_models, ml_names = get_ml_models()\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    print(f'Running {ml_names[i]} Model')\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('model', ml_models[i])\n",
    "        ]\n",
    "    )\n",
    "    scores = evaluate_model(home_train_features, np.array(\n",
    "        home_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "    model_list.append(ml_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg Fbeta': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg Fbeta', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hypothesis test for ml models with home data transformed\n",
    "home_train_features = load_home_train_features_with_drop_transformed()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit_transform(home_train_features)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "mod_names = ['GNB', 'GB', 'AB', 'XGB', 'RF']\n",
    "ml_models, ml_names = get_ml_models()\n",
    "\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    if ml_names[i] == 'LR':\n",
    "        for j in range(len(ml_models)):\n",
    "            if ml_names[j] in mod_names:\n",
    "\n",
    "                t, p = paired_ttest_5x2cv(\n",
    "                    estimator1=ml_models[i],\n",
    "                    estimator2=ml_models[j],\n",
    "                    X=home_train_features,\n",
    "                    y=np.array(home_train_target).reshape(-1,),\n",
    "                    scoring=fbeta_metric,\n",
    "                    random_seed=1\n",
    "                )\n",
    "                if p <= 0.05:\n",
    "                    print(\n",
    "                        f'{ml_names[i]} & {ml_names[j]}: Difference in model performance is most likely real')\n",
    "                else:\n",
    "                    print(\n",
    "                        f'{ml_names[i]} & {ml_names[j]}: Both models are most likely to have the same performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost and lightgbm\n",
    "# home model test without home/away teams\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "cb = CatBoostClassifier(n_estimators=200, learning_rate=0.1, random_seed=42)\n",
    "lgbmc = LGBMClassifier(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "xgb = XGBClassifier(n_estimators=200, learning_rate=0.1,\n",
    "                    max_depth=3, use_label_encoder=False, random_state=42)\n",
    "\n",
    "ml_models = [cb, lgbmc, xgb]\n",
    "ml_names = ['CB', 'LGBMC', 'XGB']\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    print(f'Running {ml_names[i]} Model')\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('model', ml_models[i])\n",
    "        ]\n",
    "    )\n",
    "    scores = evaluate_model(home_train_features, np.array(\n",
    "        home_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "    model_list.append(ml_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg Fbeta': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg Fbeta', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Svc, logistic Regression and Gaussian nb with rbf kernel approximation\n",
    "home_train_features = load_home_train_features_with_drop_transformed()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "\n",
    "rs = RobustScaler()\n",
    "sc = StandardScaler(with_mean=False)\n",
    "rbf = RBFSampler(gamma=2.0, random_state=1)\n",
    "nys = Nystroem(random_state=1)\n",
    "\n",
    "lin_svc = LinearSVC(random_state=42)\n",
    "lr = LogisticRegression(\n",
    "    solver='liblinear', class_weight='balanced', random_state=42)\n",
    "gnb = GaussianNB()\n",
    "\n",
    "models = [lin_svc, lr, gnb]\n",
    "model_names = ['LSVC', 'LR', 'GNB']\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', rs),\n",
    "            ('nys', nys),\n",
    "            ('model', models[i])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scores = evaluate_model(home_train_features, np.array(\n",
    "        home_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "    model_list.append(model_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg Fbeta': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg Fbeta', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home model test without home/away teams and pca\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "sc = StandardScaler()\n",
    "pca = PCA(n_components=30)\n",
    "\n",
    "ml_models, ml_names = get_ml_models()\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('pca', pca),\n",
    "            ('model', ml_models[i])\n",
    "        ]\n",
    "    )\n",
    "    scores = evaluate_model(home_train_features,\n",
    "                            home_train_target, pipe, k_splits=10)\n",
    "    model_list.append(ml_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg Fbeta': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg Fbeta', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Away Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away model test with home/away teams\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_train_features = football_data_team_ohe(away_train_features)\n",
    "away_train_target, _ = load_away_targets()\n",
    "sc = StandardScaler()\n",
    "\n",
    "ml_models, ml_names = get_ml_models()\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('model', ml_models[i])\n",
    "        ]\n",
    "    )\n",
    "    scores = evaluate_model(away_train_features,\n",
    "                            away_train_target, pipe, k_splits=10)\n",
    "    model_list.append(ml_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg Fbeta': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg Fbeta', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away model test without home/away teams\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "away_train_target, _ = load_away_targets()\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "ml_models, ml_names = get_ml_models()\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    print(f'Running {ml_names[i]} Model')\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('model', ml_models[i])\n",
    "        ]\n",
    "    )\n",
    "    scores = evaluate_model(away_train_features, np.array(\n",
    "        away_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "    model_list.append(ml_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg Fbeta': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg Fbeta', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hypothesis test for ml models with away data\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "away_train_target, _ = load_away_targets()\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit_transform(home_train_features)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "mod_names = ['AB', 'GB', 'XGBRF', 'KNN']\n",
    "ml_models, ml_names = get_ml_models()\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    if ml_names[i] == 'XGB':\n",
    "        for j in range(len(ml_models)):\n",
    "            if ml_names[j] in mod_names:\n",
    "\n",
    "                t, p = paired_ttest_5x2cv(\n",
    "                    estimator1=ml_models[i],\n",
    "                    estimator2=ml_models[j],\n",
    "                    X=away_train_features,\n",
    "                    y=np.array(away_train_target).reshape(-1,),\n",
    "                    scoring=fbeta_metric,\n",
    "                    random_seed=1\n",
    "                )\n",
    "                if p <= 0.05:\n",
    "                    print(\n",
    "                        f'{ml_names[i]} & {ml_names[j]}: Difference in model performance is most likely real')\n",
    "                else:\n",
    "                    print(\n",
    "                        f'{ml_names[i]} & {ml_names[j]}: Both models are most likely to have the same performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost and lightgbm\n",
    "# away model test without home/away teams\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "away_train_target, _ = load_away_targets()\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "cb = CatBoostClassifier(n_estimators=200, learning_rate=0.1, random_seed=42)\n",
    "lgbmc = LGBMClassifier(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "xgb = XGBClassifier(n_estimators=200, learning_rate=0.1,\n",
    "                    max_depth=3, use_label_encoder=False, random_state=42)\n",
    "\n",
    "ml_models = [cb, lgbmc, xgb]\n",
    "ml_names = ['CB', 'LGBMC', 'XGB']\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    print(f'Running {ml_names[i]} Model')\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('model', ml_models[i])\n",
    "        ]\n",
    "    )\n",
    "    scores = evaluate_model(away_train_features, np.array(\n",
    "        away_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "    model_list.append(ml_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg Fbeta': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg Fbeta', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away model test without home/away teams and tansformed continuous data\n",
    "away_train_features = load_away_train_features_with_drop_transformed()\n",
    "away_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "away_train_target, _ = load_away_targets()\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "ml_models, ml_names = get_ml_models()\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    print(f'Running {ml_names[i]} Model')\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('model', ml_models[i])\n",
    "        ]\n",
    "    )\n",
    "    scores = evaluate_model(away_train_features, np.array(\n",
    "        away_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "    model_list.append(ml_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg Fbeta': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg Fbeta', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away model test without home/away teams and pca\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "away_train_target, _ = load_away_targets()\n",
    "sc = StandardScaler()\n",
    "pca = PCA(n_components=30)\n",
    "\n",
    "ml_models, ml_names = get_ml_models()\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(ml_models)):\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('pca', pca),\n",
    "            ('model', ml_models[i])\n",
    "        ]\n",
    "    )\n",
    "    scores = evaluate_model(away_train_features,\n",
    "                            away_train_target, pipe, k_splits=10)\n",
    "    model_list.append(ml_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg Fbeta': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg Fbeta', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  - Summary -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found that the removal of the home and away teams from the data resulted in negligable performance loss whilst gaining computational speed, this was seen during eda where the majority of teams individually provide very little information with exceptions to the major teams like manchester united and chelsea.\n",
    "\n",
    "As outlined, with this data numerical function algorithms will benefit from pca being applied due to multicollinearity and tree based algorithms should fair pretty well. A number of models were tested.\n",
    "\n",
    "Home models to proceed with:\n",
    "\n",
    "    Logistic Regression fbeta:\t0.587389\n",
    "\tGradient Boosting fbeta:\t0.579037\n",
    "    XGBoost\tfbeta:          0.578781\n",
    "\tGausian NB fbeta:\t0.578502\n",
    "\tAdaboost fbeta: \t0.577135\n",
    "    Catboost fbeta:   \t0.577177\n",
    "    \n",
    "a paired t test with 5x2 cross validation was used for statistical significance for individual models perfomance against the top performing model, all model performance is statistically likely to be different from logistic regression. A Nystroem kernel approximation was applied to logistic regression and gaussian naive bayes to see if non-linear transforms of the data would increase performance, it resulted with negligable increase in performance. Results with PCA were marginal probably due to the initial amount of features that were used for extraction but pca will be repeated after model feature selection. Surprisingly Logistic Regression and gaussian nb performed very well with multicollinearity.\n",
    "\n",
    "Away models to proceed with:\n",
    "\n",
    "    Adaboost fbeta:          0.643416\n",
    "    Gradient Boosting fbeta: 0.639838\n",
    "    XGBoost fbeta:           0.645075\n",
    "    Light Gradient Boosting fbeta: 0.645203\n",
    "    CatBoost fbeta:          0.640387\n",
    "    \n",
    "a paired t test with 5x2 cross validation was used for statistical significance for individual models perfomance against the top performing model, all top performing models are statistically likely to have the same performance as the best model. All away models were tested with the same procedures as the home models\n",
    "  \n",
    "  \n",
    "Both Numerical function and tree based algorithms were tested on transformed and untransformed continuous data as numerical function algorithms are susceptable to outliers and tree based algorithms are not. Going forward numerical function algorithms will be tested on data that has continuous features transformed to make them more gaussian like and a robust scaler will be used to stop any influence given by outliers if any after continuous transforms, tree based algorithms are unaffected by outliers so they will be tested on untransformed continuous data and a standard scaler will be used.\n",
    "\n",
    "As can be seen all the top home models outperform the simple model baseline of 0.555328458299842, all away top models out perform the simple model baseline of 0.5644830306923153 and majority class baseline of 0.6102523359914978. All models have gained skill which is great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Feature Selection --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new models to run.. lr, gnb, gb.... catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rfe followed by sequential forward feature selection with grid search... gradient boosting\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "rfe_sc = StandardScaler(with_mean=False)\n",
    "home_train_features_sc = rfe_sc.fit_transform(home_train_features)\n",
    "\n",
    "print('Performing RFE')\n",
    "rfe_model = GradientBoostingClassifier(\n",
    "    n_estimators=200, max_features='sqrt', random_state=42)\n",
    "rfe = RFE(rfe_model, n_features_to_select=25).fit(\n",
    "    home_train_features_sc, np.array(home_train_target).reshape(-1,))\n",
    "rfe_score_df = pd.DataFrame(\n",
    "    {'Home Features': home_train_features.columns.tolist(), 'Ranking': rfe.ranking_})\n",
    "# get top rfe features\n",
    "msk = rfe_score_df['Ranking'] == 1\n",
    "msk_idx = msk[msk].index.values\n",
    "top_rfe_feats = rfe_score_df.iloc[msk_idx, 0].values\n",
    "top_rfe_feats = home_train_features[top_rfe_feats]\n",
    "\n",
    "print('Performing Sequential Forward Selection')\n",
    "sfs_model = GradientBoostingClassifier(\n",
    "    n_estimators=200, max_features='sqrt', random_state=42)\n",
    "sfs_sc = StandardScaler(with_mean=False)\n",
    "top_rfe_feats_sc = sc.fit_transform(top_rfe_feats)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=sfs_model,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring=fbeta_metric,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs = sfs.fit(top_rfe_feats_sc, np.array(\n",
    "    home_train_target).reshape(-1,), custom_feature_names=top_rfe_feats.columns)\n",
    "\n",
    "\n",
    "gb_sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "gb_sfs_df = gb_sfs_df.sort_values(\n",
    "    by='avg_score', ascending=False).reset_index(drop=True)\n",
    "t_fts = gb_sfs_df.iloc[0, :]['feature_names']\n",
    "print(f'Num Features: {len(t_fts)}\\nTop Features: {t_fts}')\n",
    "gb_sfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select k best followed by sequential forward feature selection with grid search... gaussian nb\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "skb_sc = StandardScaler(with_mean=False)\n",
    "home_train_features_sc = skb_sc.fit_transform(home_train_features)\n",
    "\n",
    "print('Performing SkB')\n",
    "# select k best, home features\n",
    "skb = SelectKBest(score_func=mutual_info_classif, k='all').fit(\n",
    "    home_train_features_sc, np.array(home_train_target).reshape(-1,))\n",
    "feat_score_df = pd.DataFrame(\n",
    "    {'Home Features': home_train_features.columns.tolist(), 'Mutual Info': skb.scores_})\n",
    "feat_score_df = feat_score_df.sort_values(\n",
    "    by='Mutual Info', ascending=False).reset_index(drop=True)\n",
    "top_skb_feats = feat_score_df[0:25]['Home Features'].values\n",
    "top_skb_feats = home_train_features[top_skb_feats]\n",
    "\n",
    "print('Performing Sequential Forward Selection')\n",
    "sfs_model = GaussianNB()\n",
    "sfs_sc = StandardScaler(with_mean=False)\n",
    "top_skb_feats_sc = sfs_sc.fit_transform(top_skb_feats)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=sfs_model,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring=fbeta_metric,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs = sfs.fit(top_skb_feats_sc, np.array(\n",
    "    home_train_target).reshape(-1,), custom_feature_names=top_skb_feats.columns)\n",
    "\n",
    "gnb_sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "gnb_sfs_df = gnb_sfs_df.sort_values(\n",
    "    by='avg_score', ascending=False).reset_index(drop=True)\n",
    "t_fts = gnb_sfs_df.iloc[0, :]['feature_names']\n",
    "print(f'Num Features: {len(t_fts)}\\nTop Features: {t_fts}')\n",
    "gnb_sfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select k best followed by sequential forward feature selection with grid search...\n",
    "# gaussian nb with transformed features and robust scaler\n",
    "home_train_features = load_home_train_features_with_drop_transformed()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "skb_rc = RobustScaler()\n",
    "home_train_features_rc = skb_rc.fit_transform(home_train_features)\n",
    "\n",
    "print('Performing SkB')\n",
    "# select k best, home features\n",
    "skb = SelectKBest(score_func=mutual_info_classif, k='all').fit(\n",
    "    home_train_features_rc, np.array(home_train_target).reshape(-1,))\n",
    "feat_score_df = pd.DataFrame(\n",
    "    {'Home Features': home_train_features.columns.tolist(), 'Mutual Info': skb.scores_})\n",
    "feat_score_df = feat_score_df.sort_values(\n",
    "    by='Mutual Info', ascending=False).reset_index(drop=True)\n",
    "top_skb_feats = feat_score_df[0:25]['Home Features'].values\n",
    "top_skb_feats = home_train_features[top_skb_feats]\n",
    "\n",
    "print('Performing Sequential Forward Selection')\n",
    "sfs_model = GaussianNB()\n",
    "sfs_rc = RobustScaler()\n",
    "top_skb_feats_rc = sfs_rc.fit_transform(top_skb_feats)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=sfs_model,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring=fbeta_metric,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs = sfs.fit(top_skb_feats_rc, np.array(\n",
    "    home_train_target).reshape(-1,), custom_feature_names=top_skb_feats.columns)\n",
    "\n",
    "gnb_sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "gnb_sfs_df = gnb_sfs_df.sort_values(\n",
    "    by='avg_score', ascending=False).reset_index(drop=True)\n",
    "t_fts = gnb_sfs_df.iloc[0, :]['feature_names']\n",
    "print(f'Num Features: {len(t_fts)}\\nTop Features: {t_fts}')\n",
    "gnb_sfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RFE selection followed by sequential forward feature selection with grid search... logistic regression\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "rfe_sc = StandardScaler(with_mean=False)\n",
    "home_train_features_sc = rfe_sc.fit_transform(home_train_features)\n",
    "\n",
    "print('Performing RFE')\n",
    "rfe_model = LogisticRegression(\n",
    "    solver='liblinear', class_weight='balanced', random_state=42)\n",
    "rfe = RFE(rfe_model, n_features_to_select=25).fit(\n",
    "    home_train_features_sc, np.array(home_train_target).reshape(-1,))\n",
    "rfe_score_df = pd.DataFrame(\n",
    "    {'Home Features': home_train_features.columns.tolist(), 'Ranking': rfe.ranking_})\n",
    "# get top rfe features\n",
    "msk = rfe_score_df['Ranking'] == 1\n",
    "msk_idx = msk[msk].index.values\n",
    "top_rfe_feats = rfe_score_df.iloc[msk_idx, 0].values\n",
    "top_rfe_feats = home_train_features[top_rfe_feats]\n",
    "\n",
    "print('Performing Sequential Forward Selection')\n",
    "sfs_model = LogisticRegression(\n",
    "    solver='liblinear', class_weight='balanced', random_state=42)\n",
    "sfs_sc = StandardScaler(with_mean=False)\n",
    "top_rfe_feats_sc = sfs_sc.fit_transform(top_rfe_feats)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=sfs_model,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring=fbeta_metric,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs = sfs.fit(top_rfe_feats_sc, np.array(\n",
    "    home_train_target).reshape(-1,), custom_feature_names=top_rfe_feats.columns)\n",
    "\n",
    "lr_sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "lr_sfs_df = lr_sfs_df.sort_values(\n",
    "    by='avg_score', ascending=False).reset_index(drop=True)\n",
    "t_fts = lr_sfs_df.iloc[0, :]['feature_names']\n",
    "print(f'Num Features: {len(t_fts)}Top Features: {t_fts}')\n",
    "lr_sfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RFE selection followed by sequential forward feature selection with grid search...\n",
    "# logistic regression with transformed features and robust scaler\n",
    "home_train_features = load_home_train_features_with_drop_transformed()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "rfe_rc = RobustScaler()\n",
    "home_train_features_rc = rfe_rc.fit_transform(home_train_features)\n",
    "\n",
    "print('Performing RFE')\n",
    "rfe_model = LogisticRegression(\n",
    "    solver='liblinear', class_weight='balanced', random_state=42)\n",
    "rfe = RFE(rfe_model, n_features_to_select=25).fit(\n",
    "    home_train_features_rc, np.array(home_train_target).reshape(-1,))\n",
    "rfe_score_df = pd.DataFrame(\n",
    "    {'Home Features': home_train_features.columns.tolist(), 'Ranking': rfe.ranking_})\n",
    "# get top rfe features\n",
    "msk = rfe_score_df['Ranking'] == 1\n",
    "msk_idx = msk[msk].index.values\n",
    "top_rfe_feats = rfe_score_df.iloc[msk_idx, 0].values\n",
    "top_rfe_feats = home_train_features[top_rfe_feats]\n",
    "\n",
    "print('Performing Sequential Forward Selection')\n",
    "sfs_model = LogisticRegression(\n",
    "    solver='liblinear', class_weight='balanced', random_state=42)\n",
    "sfs_rc = RobustScaler()\n",
    "top_rfe_feats_rc = sfs_rc.fit_transform(top_rfe_feats)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=sfs_model,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring=fbeta_metric,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs = sfs.fit(top_rfe_feats_rc, np.array(\n",
    "    home_train_target).reshape(-1,), custom_feature_names=top_rfe_feats.columns)\n",
    "\n",
    "lr_sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "lr_sfs_df = lr_sfs_df.sort_values(\n",
    "    by='avg_score', ascending=False).reset_index(drop=True)\n",
    "t_fts = lr_sfs_df.iloc[0, :]['feature_names']\n",
    "print(f'Num Features: {len(t_fts)}Top Features: {t_fts}')\n",
    "lr_sfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RFE selection followed by sequential forward feature selection with grid search... xgboost\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "rfe_sc = StandardScaler(with_mean=False)\n",
    "home_train_features_sc = rfe_sc.fit_transform(home_train_features)\n",
    "\n",
    "print('Performing RFE')\n",
    "rfe_model = XGBClassifier(n_estimators=200,\n",
    "                          learning_rate=0.1,\n",
    "                          max_depth=3,\n",
    "                          min_child_weight=1,\n",
    "                          gamma=0,\n",
    "                          scale_pos_weight=1,\n",
    "                          use_label_encoder=False,\n",
    "                          n_jobs=-1,\n",
    "                          verbosity=0,\n",
    "                          random_state=42)\n",
    "rfe = RFE(rfe_model, n_features_to_select=25).fit(\n",
    "    home_train_features_sc, np.array(home_train_target).reshape(-1,))\n",
    "rfe_score_df = pd.DataFrame(\n",
    "    {'Home Features': home_train_features.columns.tolist(), 'Ranking': rfe.ranking_})\n",
    "# get top rfe features\n",
    "msk = rfe_score_df['Ranking'] == 1\n",
    "msk_idx = msk[msk].index.values\n",
    "top_rfe_feats = rfe_score_df.iloc[msk_idx, 0].values\n",
    "top_rfe_feats = home_train_features[top_rfe_feats]\n",
    "\n",
    "print('Performing Sequential Forward Selection')\n",
    "sfs_model = XGBClassifier(n_estimators=200,\n",
    "                          learning_rate=0.1,\n",
    "                          max_depth=3,\n",
    "                          min_child_weight=1,\n",
    "                          gamma=0,\n",
    "                          scale_pos_weight=1,\n",
    "                          use_label_encoder=False,\n",
    "                          n_jobs=-1,\n",
    "                          verbosity=0,\n",
    "                          random_state=42)\n",
    "sfs_sc = StandardScaler(with_mean=False)\n",
    "top_rfe_feats_sc = sfs_sc.fit_transform(top_rfe_feats)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=sfs_model,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring=fbeta_metric,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs = sfs.fit(top_rfe_feats_sc, np.array(\n",
    "    home_train_target).reshape(-1,), custom_feature_names=top_rfe_feats.columns)\n",
    "\n",
    "xgb_sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "xgb_sfs_df = xgb_sfs_df.sort_values(\n",
    "    by='avg_score', ascending=False).reset_index(drop=True)\n",
    "t_fts = xgb_sfs_df.iloc[0, :]['feature_names']\n",
    "print(f'Num Features: {len(t_fts)}\\nTop Features: {t_fts}')\n",
    "xgb_sfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RFE selection followed by sequential forward feature selection with grid search... adaboost\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "rfe_sc = StandardScaler(with_mean=False)\n",
    "home_train_features_sc = rfe_sc.fit_transform(home_train_features)\n",
    "\n",
    "print('Performing RFE')\n",
    "rfe_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "rfe = RFE(rfe_model, n_features_to_select=25).fit(\n",
    "    home_train_features_sc, np.array(home_train_target).reshape(-1,))\n",
    "rfe_score_df = pd.DataFrame(\n",
    "    {'Home Features': home_train_features.columns.tolist(), 'Ranking': rfe.ranking_})\n",
    "# get top rfe features\n",
    "msk = rfe_score_df['Ranking'] == 1\n",
    "msk_idx = msk[msk].index.values\n",
    "top_rfe_feats = rfe_score_df.iloc[msk_idx, 0].values\n",
    "top_rfe_feats = home_train_features[top_rfe_feats]\n",
    "\n",
    "print('Performing Sequential Forward Selection')\n",
    "sfs_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "sfs_sc = StandardScaler(with_mean=False)\n",
    "top_rfe_feats_sc = sfs_sc.fit_transform(top_rfe_feats)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=sfs_model,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring=fbeta_metric,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs = sfs.fit(top_rfe_feats_sc, np.array(home_train_target).reshape(-1,))\n",
    "\n",
    "ab_sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "ab_sfs_df = ab_sfs_df.sort_values(\n",
    "    by='avg_score', ascending=False).reset_index(drop=True)\n",
    "t_fts = ab_sfs_df.iloc[0, :]['feature_names']\n",
    "print(f'\\nNum Features: {len(t_fts)}\\nTop Features: {t_fts}')\n",
    "ab_sfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca for logistic regression home features with transformed data and robust scaler\n",
    "pca_home_df = load_home_train_features_with_drop_transformed()  # load features\n",
    "pca_home_df = pca_home_df[['AHTGS5PG_UPoutlier', 'AHTGS5PHG_UPoutlier', 'AATGS5PAG_UPoutlier', 'AHTSOT5PG_UPoutlier',\n",
    "                           'AATSOT5PG_UPoutlier', 'AHTSOT5PHG_UPoutlier', 'AHTGD5PHG_UPoutlier', 'HT_PrevSeasonPos_inv',\n",
    "                           'AT_PrevSeasonPos_inv', 'HA_AHTGS5PG_diff_lowqrt', 'AHTGS5PG_upqrt_AATGC5PG_lowqrt',\n",
    "                           'AHTSOT5PG_bxcx_pwrTRANSFORM', 'AATSOT5PG_bxcx_pwrTRANSFORM', 'AHTGD5PG_quantileTRANSFORM',\n",
    "                           'AATGD5PG_quantileTRANSFORM', 'AwayCapacityDiff_bin_quantileTRANSFORM',\n",
    "                           'bxcx_AHTSOT5PG_quantileTRANSFORM', 'bxcx_AATSOT5PG_quantileTRANSFORM',\n",
    "                           'bxcx_AAT_GS_P5PG_ratio_quantileTRANSFORM']]\n",
    "\n",
    "rc = RobustScaler()\n",
    "pca_home_df = rc.fit_transform(pca_home_df)\n",
    "# fit pca algorithm\n",
    "pca = PCA(whiten=True).fit(pca_home_df)\n",
    "# Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)')  # for each component\n",
    "plt.title('Explained Variance of Home Features')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca for gaussian nb home features with transformed data and robust scaler\n",
    "pca_home_df = load_home_train_features_with_drop_transformed()  # load features\n",
    "pca_home_df = pca_home_df[['AwayCapacityDiff_bin_quantileTRANSFORM', 'HT_PrevSeasonPos_inv', 'HA_ATP5PG_diff_quantileTRANSFORM',\n",
    "                           'AATSOT5PAG_bxcx_pwrTRANSFORM', 'season_month_sin', 'AHTGC5PG_UPoutlier', 'AT_PrevSeasonPos_inv',\n",
    "                           'season_month']]\n",
    "\n",
    "rc = RobustScaler()\n",
    "pca_home_df = rc.fit_transform(pca_home_df)\n",
    "# fit pca algorithm\n",
    "pca = PCA(whiten=True).fit(pca_home_df)\n",
    "# Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)')  # for each component\n",
    "plt.title('Explained Variance of Home Features')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian nb / linear regression with pca reduced transformed features and robust scaler\n",
    "home_train_features = load_home_train_features_with_drop_transformed()\n",
    "lr_home_train_feats = home_train_features[['AHTGS5PG_UPoutlier', 'AHTGS5PHG_UPoutlier', 'AATGS5PAG_UPoutlier', 'AHTSOT5PG_UPoutlier',\n",
    "                                           'AATSOT5PG_UPoutlier', 'AHTSOT5PHG_UPoutlier', 'AHTGD5PHG_UPoutlier', 'HT_PrevSeasonPos_inv',\n",
    "                                           'AT_PrevSeasonPos_inv', 'HA_AHTGS5PG_diff_lowqrt', 'AHTGS5PG_upqrt_AATGC5PG_lowqrt',\n",
    "                                           'AHTSOT5PG_bxcx_pwrTRANSFORM', 'AATSOT5PG_bxcx_pwrTRANSFORM', 'AHTGD5PG_quantileTRANSFORM',\n",
    "                                           'AATGD5PG_quantileTRANSFORM', 'AwayCapacityDiff_bin_quantileTRANSFORM',\n",
    "                                           'bxcx_AHTSOT5PG_quantileTRANSFORM', 'bxcx_AATSOT5PG_quantileTRANSFORM',\n",
    "                                           'bxcx_AAT_GS_P5PG_ratio_quantileTRANSFORM']]\n",
    "gnb_home_train_feats = home_train_features[['AwayCapacityDiff_bin_quantileTRANSFORM', 'HT_PrevSeasonPos_inv',\n",
    "                                            'HA_ATP5PG_diff_quantileTRANSFORM', 'AATSOT5PAG_bxcx_pwrTRANSFORM',\n",
    "                                            'season_month_sin', 'AHTGC5PG_UPoutlier', 'AT_PrevSeasonPos_inv', 'season_month']]\n",
    "home_train_target, _ = load_home_targets()\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "lr_model = LogisticRegression(\n",
    "    solver='liblinear', class_weight='balanced', random_state=42)\n",
    "\n",
    "rc = RobustScaler()\n",
    "\n",
    "lr_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('rc', rc),\n",
    "        ('pca', PCA(n_components=12, whiten=True)),\n",
    "        ('model', lr_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "gnb_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('rc', rc),\n",
    "        ('pca', PCA(n_components=7, whiten=True)),\n",
    "        ('model', gnb_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "lr_scores = evaluate_model(\n",
    "    lr_home_train_feats, home_train_target, lr_pipe, k_splits=10)\n",
    "gnb_scores = evaluate_model(\n",
    "    gnb_home_train_feats, home_train_target, gnb_pipe, k_splits=10)\n",
    "\n",
    "print(\n",
    "    f'logistic Regression with PCA:  Avg Fbeta: {np.mean(lr_scores)}        Std: {np.std(lr_scores)}')\n",
    "print(\n",
    "    f'Gaussian NB with PCA:  Avg Fbeta: {np.mean(gnb_scores)}        Std: {np.std(gnb_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost feature importance\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "home_train_target, _ = load_home_targets()\n",
    "rfe_sc = StandardScaler(with_mean=False)\n",
    "home_train_features_sc = rfe_sc.fit_transform(home_train_features)\n",
    "\n",
    "\n",
    "cb = CatBoostClassifier(n_estimators=200,\n",
    "                        learning_rate=0.1,\n",
    "                        objective='Logloss',\n",
    "                        bootstrap_type='Bayesian',\n",
    "                        bagging_temperature=0.5,\n",
    "                        max_depth=6,\n",
    "                        verbose=3,\n",
    "                        random_state=42)\n",
    "\n",
    "pool = Pool(data=home_train_features_sc, label=home_train_target)\n",
    "\n",
    "cb.fit(pool)\n",
    "importances = cb.get_feature_importance(\n",
    "    data=pool, fstr_type=EFstrType.FeatureImportance, verbose=2, prettified=False)\n",
    "fi = pd.DataFrame({'Feature': home_train_features.columns,\n",
    "                   'Importance': importances})\n",
    "fi.sort_values(by='Importance', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model = CatBoostClassifier(n_estimators=200,\n",
    "                              learning_rate=0.1,\n",
    "                              objective='Logloss',\n",
    "                              bootstrap_type='Bayesian',\n",
    "                              bagging_temperature=0.5,\n",
    "                              max_depth=6,\n",
    "                              verbose=3,\n",
    "                              random_state=42)\n",
    "home_train_features = load_home_train_features_with_drop()\n",
    "home_train_target, _ = load_home_targets()\n",
    "cb_feats = home_train_features[['HT_PrevSeasonPos_inv', 'AT_PrevSeasonPos_inv', 'AwayCapacityDiff_bin', 'AHTSOT5PHG', 'AATGD5PG',\n",
    "                                'AATGS_SOT5PG_ratio', 'AATGD5PAG', 'AATGS_SOT5PAG_ratio', 'AATSOT5PAG', 'bxcx_AHTSOT5PG', 'AHTSOT5PG',\n",
    "                                'bxcx_AAT_GS_P5PG_ratio', 'AHTGD5PHG', 'AHTGD5PG', 'AAT_GS_P5PG_ratio', 'AATP5PG', 'AATGC5PAG',\n",
    "                                'AATSOT5PG']]\n",
    "\n",
    "sc = StandardScaler(with_mean=True)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('sc', sc),\n",
    "        ('model', cb_model)\n",
    "    ]\n",
    ")\n",
    "scores = evaluate_model(cb_feats, np.array(\n",
    "    home_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "print(\n",
    "    f'CB model top features fbeta score: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "home features:\n",
    "\n",
    "gradient boosting fbeta score: 0.584344, std: 0.011447\n",
    "\n",
    "xgboost fbeta score: 0.584726, std: 0.00986\n",
    "\n",
    "adaboost fbeta score: 0.581842, std: 0.009721\n",
    "\n",
    "logistic regression fbeta: 0.592269, std: 0.009448.... logistic regression with pca fbeta score: 0.591103, std: 0.009015\n",
    "\n",
    "gaussian nb fbeta score: 0.585609, std: 0.008748.... gaussian nb with pca fbeta score: 0.584452, std: 0.007734\n",
    "\n",
    "catboost fbeta score: 0.578077,    std: 0.0090299\n",
    "\n",
    "models to proceed with:     gradient boosting, xgboost, gaussian nb with pca, logistic regression with pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Away Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new models... xgb, gb, ab, knn... lightgbm, catboost, xgb with lr rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RFE selection followed by sequential forward feature selection with grid search... adaboost\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "away_train_target, _ = load_away_targets()\n",
    "rfe_sc = StandardScaler(with_mean=False)\n",
    "away_train_features_sc = rfe_sc.fit_transform(away_train_features)\n",
    "\n",
    "print('Performing RFE')\n",
    "rfe_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "rfe = RFE(rfe_model, n_features_to_select=25).fit(\n",
    "    away_train_features_sc, np.array(away_train_target).reshape(-1,))\n",
    "rfe_score_df = pd.DataFrame(\n",
    "    {'Away Features': away_train_features.columns.tolist(), 'Ranking': rfe.ranking_})\n",
    "# get top rfe features\n",
    "msk = rfe_score_df['Ranking'] == 1\n",
    "msk_idx = msk[msk].index.values\n",
    "top_rfe_feats = rfe_score_df.iloc[msk_idx, 0].values\n",
    "top_rfe_feats = away_train_features[top_rfe_feats]\n",
    "\n",
    "print('Performing Sequential Forward Selection')\n",
    "sfs_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "sfs_sc = StandardScaler(with_mean=False)\n",
    "top_rfe_feats_sc = sfs_sc.fit_transform(top_rfe_feats)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=sfs_model,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring=fbeta_metric,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs = sfs.fit(top_rfe_feats_sc, np.array(\n",
    "    away_train_target).reshape(-1,), custom_feature_names=top_rfe_feats.columns)\n",
    "\n",
    "ab_sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "ab_sfs_df = ab_sfs_df.sort_values(\n",
    "    by='avg_score', ascending=False).reset_index(drop=True)\n",
    "t_fts = ab_sfs_df.iloc[0, :]['feature_names']\n",
    "print(f'\\nTop Features: {t_fts}')\n",
    "ab_sfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RFE selection followed by sequential forward feature selection with grid search... gradient boosting\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "away_train_target, _ = load_away_targets()\n",
    "rfe_sc = StandardScaler(with_mean=False)\n",
    "away_train_features_sc = rfe_sc.fit_transform(away_train_features)\n",
    "\n",
    "print('Performing RFE')\n",
    "rfe_model = GradientBoostingClassifier(\n",
    "    n_estimators=200, max_features='sqrt', random_state=42)\n",
    "rfe = RFE(rfe_model, n_features_to_select=25).fit(\n",
    "    away_train_features_sc, np.array(away_train_target).reshape(-1,))\n",
    "rfe_score_df = pd.DataFrame(\n",
    "    {'Away Features': away_train_features.columns.tolist(), 'Ranking': rfe.ranking_})\n",
    "# get top rfe features\n",
    "msk = rfe_score_df['Ranking'] == 1\n",
    "msk_idx = msk[msk].index.values\n",
    "top_rfe_feats = rfe_score_df.iloc[msk_idx, 0].values\n",
    "top_rfe_feats = away_train_features[top_rfe_feats]\n",
    "\n",
    "print('Performing Sequential Forward Selection')\n",
    "sfs_model = GradientBoostingClassifier(\n",
    "    n_estimators=200, max_features='sqrt', random_state=42)\n",
    "sfs_sc = StandardScaler(with_mean=False)\n",
    "top_rfe_feats_sc = sfs_sc.fit_transform(top_rfe_feats)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=sfs_model,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring=fbeta_metric,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs = sfs.fit(top_rfe_feats_sc, np.array(\n",
    "    away_train_target).reshape(-1,), custom_feature_names=top_rfe_feats.columns)\n",
    "\n",
    "gb_sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "gb_sfs_df = gb_sfs_df.sort_values(\n",
    "    by='avg_score', ascending=False).reset_index(drop=True)\n",
    "t_fts = gb_sfs_df.iloc[0, :]['feature_names']\n",
    "print(f'\\nTop Features: {t_fts}')\n",
    "gb_sfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RFE selection followed by sequential forward feature selection with grid search... xgboost\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "away_train_target, _ = load_away_targets()\n",
    "rfe_sc = StandardScaler(with_mean=False)\n",
    "away_train_features_sc = rfe_sc.fit_transform(away_train_features)\n",
    "\n",
    "print('Performing RFE')\n",
    "rfe_model = XGBClassifier(n_estimators=200,\n",
    "                          learning_rate=0.1,\n",
    "                          max_depth=3,\n",
    "                          min_child_weight=1,\n",
    "                          gamma=0,\n",
    "                          scale_pos_weight=1,\n",
    "                          use_label_encoder=False,\n",
    "                          n_jobs=-1,\n",
    "                          verbosity=0,\n",
    "                          random_state=42)\n",
    "rfe = RFE(rfe_model, n_features_to_select=25).fit(\n",
    "    away_train_features_sc, np.array(away_train_target).reshape(-1,))\n",
    "rfe_score_df = pd.DataFrame(\n",
    "    {'Away Features': away_train_features.columns.tolist(), 'Ranking': rfe.ranking_})\n",
    "# get top rfe features\n",
    "msk = rfe_score_df['Ranking'] == 1\n",
    "msk_idx = msk[msk].index.values\n",
    "top_rfe_feats = rfe_score_df.iloc[msk_idx, 0].values\n",
    "top_rfe_feats = away_train_features[top_rfe_feats]\n",
    "\n",
    "print('Performing Sequential Forward Selection')\n",
    "sfs_model = XGBClassifier(n_estimators=200,\n",
    "                          learning_rate=0.1,\n",
    "                          max_depth=3,\n",
    "                          min_child_weight=1,\n",
    "                          gamma=0,\n",
    "                          scale_pos_weight=1,\n",
    "                          use_label_encoder=False,\n",
    "                          n_jobs=-1,\n",
    "                          verbosity=0,\n",
    "                          random_state=42)\n",
    "sfs_sc = StandardScaler(with_mean=False)\n",
    "top_rfe_feats_sc = sfs_sc.fit_transform(top_rfe_feats)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=sfs_model,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring=fbeta_metric,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs = sfs.fit(top_rfe_feats_sc, np.array(\n",
    "    away_train_target).reshape(-1,), custom_feature_names=top_rfe_feats.columns)\n",
    "\n",
    "xgb_sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "xgb_sfs_df = xgb_sfs_df.sort_values(\n",
    "    by='avg_score', ascending=False).reset_index(drop=True)\n",
    "t_fts = xgb_sfs_df.iloc[0, :]['feature_names']\n",
    "print(f'\\nTop Features: {t_fts}')\n",
    "xgb_sfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RFE selection followed by sequential forward feature selection with grid search... lightgbm\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "away_train_target, _ = load_away_targets()\n",
    "#cat_feat = [(idx, col) for idx, col in enumerate(away_train_features.columns) if 'UPoutlier' in col or 'LOWoutlier' in col or 'Local_Derby' in col or 'Dist>=100' in col or 'cluster' in col or 'upqrt' in col or 'lowqrt' in col or 'UPLOW' in col or 'bigcapacitydiff_' in col]\n",
    "# cat_feat = np.array([col[0] for col in cat_feat]) # categorical features\n",
    "rfe_sc = StandardScaler(with_mean=False)\n",
    "away_train_features_sc = rfe_sc.fit_transform(away_train_features)\n",
    "\n",
    "print('Performing RFE')\n",
    "rfe_model = LGBMClassifier(n_estimators=200,\n",
    "                           learning_rate=0.1,\n",
    "                           objective='binary',\n",
    "                           max_depth=3,\n",
    "                           n_jobs=-1,\n",
    "                           random_state=42)\n",
    "rfe = RFE(rfe_model, n_features_to_select=25).fit(\n",
    "    away_train_features_sc, np.array(away_train_target).reshape(-1,))\n",
    "rfe_score_df = pd.DataFrame(\n",
    "    {'Away Features': away_train_features.columns.tolist(), 'Ranking': rfe.ranking_})\n",
    "# get top rfe features\n",
    "msk = rfe_score_df['Ranking'] == 1\n",
    "msk_idx = msk[msk].index.values\n",
    "top_rfe_feats = rfe_score_df.iloc[msk_idx, 0].values\n",
    "top_rfe_feats = away_train_features[top_rfe_feats]\n",
    "\n",
    "print('Performing Sequential Forward Selection')\n",
    "sfs_model = LGBMClassifier(n_estimators=200,\n",
    "                           learning_rate=0.1,\n",
    "                           objective='binary',\n",
    "                           max_depth=3,\n",
    "                           n_jobs=-1,\n",
    "                           random_state=42)\n",
    "sfs_sc = StandardScaler(with_mean=False)\n",
    "top_rfe_feats_sc = sfs_sc.fit_transform(top_rfe_feats)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "fbeta_metric = make_scorer(fbeta)\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=sfs_model,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring=fbeta_metric,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs = sfs.fit(top_rfe_feats_sc, np.array(\n",
    "    away_train_target).reshape(-1,), custom_feature_names=top_rfe_feats.columns)\n",
    "\n",
    "lgbm_sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "lgbm_sfs_df = lgbm_sfs_df.sort_values(\n",
    "    by='avg_score', ascending=False).reset_index(drop=True)\n",
    "t_fts = lgbm_sfs_df.iloc[0, :]['feature_names']\n",
    "print(f'\\nTop Features: {t_fts}')\n",
    "lgbm_sfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# catboost feature importance\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "away_train_target, _ = load_away_targets()\n",
    "rfe_sc = StandardScaler(with_mean=False)\n",
    "away_train_features_sc = rfe_sc.fit_transform(away_train_features)\n",
    "\n",
    "\n",
    "cb = CatBoostClassifier(n_estimators=200,\n",
    "                        learning_rate=0.1,\n",
    "                        objective='Logloss',\n",
    "                        bootstrap_type='Bayesian',\n",
    "                        bagging_temperature=0.5,\n",
    "                        max_depth=6,\n",
    "                        verbose=3,\n",
    "                        random_state=42)\n",
    "\n",
    "pool = Pool(data=away_train_features_sc, label=away_train_target)\n",
    "\n",
    "cb.fit(pool)\n",
    "importances = cb.get_feature_importance(\n",
    "    data=pool, fstr_type=EFstrType.FeatureImportance, verbose=2, prettified=False)\n",
    "fi = pd.DataFrame({'Feature': away_train_features.columns,\n",
    "                   'Importance': importances})\n",
    "fi.sort_values(by='Importance', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model = CatBoostClassifier(n_estimators=200,\n",
    "                              learning_rate=0.1,\n",
    "                              objective='Logloss',\n",
    "                              bootstrap_type='Bayesian',\n",
    "                              bagging_temperature=0.5,\n",
    "                              max_depth=6,\n",
    "                              verbose=3,\n",
    "                              random_state=42)\n",
    "away_train_features = load_away_train_features_with_drop()\n",
    "away_train_target, _ = load_away_targets()\n",
    "cb_feats = away_train_features[['HT_PrevSeasonPos_inv', 'AT_PrevSeasonPos_inv', 'AwayCapacityDiff_bin', 'AHTSOT5PHG', 'AATSOT5PAG', 'AATGS_SOT5PAG_ratio',\n",
    "                                'HA_ATP5PG_diff', 'year', 'AHTSOT5PG', 'AATGD5PAG', 'bxcx_AATSOT5PG', 'HA_AHTGS5PG_diff', 'AHTP5PHG', 'AATGS_SOT5PG_ratio',\n",
    "                                'AAT_GS_P5PG_ratio', 'AHTGC5PHG', 'AHTGD5PG', 'AHT_GS_P5PG_ratio']]\n",
    "\n",
    "sc = StandardScaler(with_mean=True)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('sc', sc),\n",
    "        ('model', cb_model)\n",
    "    ]\n",
    ")\n",
    "scores = evaluate_model(cb_feats, np.array(\n",
    "    away_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "print(\n",
    "    f'CB model top features fbeta score: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Away features:\n",
    "\n",
    "adaboost fbeta score: 0.643711, std: 0.005774\n",
    "\n",
    "gradient boosting fbeat score: 0.643802, std: 0.004382\n",
    "\n",
    "xgboost fbeta score: 0.644352, std: 0.003056\n",
    "\n",
    "lightgbm fbeta score: 0.643192, std: 0.004525\n",
    "\n",
    "catboost fbeta score: 0.639942,    std: 0.004579\n",
    "\n",
    "model to proceed with is xgboost, lightgbm, gradient boosting and adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Summary -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the number of features, performing sequential forward feature selection would prove inefficient computationally resulting in hours spent searching the feature space for the optimal number of features. Therefore the next best solution would be to whittle the feature space down first then perform sequential forward feature selection on the remaining best features. For the first part of this method it has been opted to perform recursive feature elimination with the models that provide weighted coefficients or importance to the features and a select k best approach for those that do not. In both cases the original dataset will be reduced to the best 25 features which will then be run with sequential forward feature selection to obtain the optimal features from this scenario.\n",
    "\n",
    "Home model outcomes:\n",
    "\n",
    "    Gradient Boosting... No. features: 13,    avg fbeta: 0.584344\n",
    "    Gaussian NB... No. features: 8,    avg fbeta: 0.585609,    after pca... No. components: 7,   avg fbeta: 0.584452\n",
    "    Logistic Regression... No. features: 19,    avg fbeta: 0.592269,    after pca... No.components: 12,    avg fbeta: 0.591103\n",
    "    XGBoost... No. features: 12,    avg fbeta: 0.584726\n",
    "    Adaboost... No. features: 18,    avg fbeta: 0.581842\n",
    "    CatBoost... No. features: 18,    avg fbeta: 0.578077\n",
    "  \n",
    "After performing pca on the logistic regression model and gaussian nb model the number of features were reduced whilst still maintaining near full variance of the original dataset and with only a slight decrease in performance. The reason for keeping the models with pca reduced features when the performance has decreased even though its minimal is because the data is better setup for these models and will tribute to better generalisation. After pca Logistic regression data was reduced to only 12 feature components and gaussian nb only 7 feature components.\n",
    "\n",
    "home models to proceed with:    gradient boosting, xgboost, gaussian nb with pca, logistic regression with pca\n",
    "\n",
    "Away model outcomes:\n",
    "\n",
    "    Adaboost... No. features: 20,    avg fbeta: 0.643711\n",
    "    Gradient Boosting... No. features: 13,    avg fbeta: 0.643802\n",
    "    XGBoost... No. features: 9,    avg fbeta: 0.644352\n",
    "    Light Gradient Boosting... No. features: 12,    avg fbeta: 0.643192\n",
    "    CatBoost... No. features: 18,    avg fbeta: 0.639942\n",
    "    \n",
    "away models to proceed with:    xgboost, lightgbm, gradient boosting and adaboost\n",
    "\n",
    "As can be seen all models after feature selection have either increased performance or have approximately the same performance from initial model selection which is great, reduced dataset with negligable performance loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Sampling --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Undersampling -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gradient boosting, logistic regression/gaussian nb with pca\n",
    "# get models and features\n",
    "gb_model, gb_feats, gb_name = home_gb_setup()\n",
    "lr_model, lr_feats, lr_pca, lr_name = home_lr_setup()\n",
    "gnb_model, gnb_feats, gnb_pca, gnb_name = home_gnb_setup()\n",
    "models = [gb_model, lr_model, gnb_model]\n",
    "mod_names = [gb_name, lr_name, gnb_name]\n",
    "feats = [gb_feats, lr_feats, gnb_feats]\n",
    "home_train_target, _ = load_home_targets()\n",
    "\n",
    "# get undersampling models\n",
    "us_models, us_names = get_us_models()\n",
    "\n",
    "sc = StandardScaler(with_mean=False)\n",
    "rs = RobustScaler()\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(f'\\nStarting: {mod_names[i]}')\n",
    "    us_scores = []\n",
    "    us_model_list = []\n",
    "    mean_scores = []\n",
    "    std_list = []\n",
    "    for j in range(len(us_models)):\n",
    "        if mod_names[i] == 'GB':\n",
    "            pipe = IMBPipeline(\n",
    "                steps=[\n",
    "                    ('sc', sc),\n",
    "                    ('us', us_models[j]),\n",
    "                    ('model', models[i])\n",
    "                ]\n",
    "            )\n",
    "        elif mod_names[i] == 'LR':\n",
    "            pipe = IMBPipeline(\n",
    "                steps=[\n",
    "                    ('rs', rs),\n",
    "                    ('us', us_models[j]),\n",
    "                    ('pca', lr_pca),\n",
    "                    ('model', models[i])\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            pipe = IMBPipeline(\n",
    "                steps=[\n",
    "                    ('rs', rs),\n",
    "                    ('us', us_models[j]),\n",
    "                    ('pca', gnb_pca),\n",
    "                    ('model', models[i])\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        scores = evaluate_model(feats[i], home_train_target, pipe, k_splits=10)\n",
    "        us_scores.append(scores)\n",
    "        us_model_list.append(us_models[j])\n",
    "        mean_scores.append(np.mean(scores))\n",
    "        std_list.append(np.std(scores))\n",
    "\n",
    "    us_df = pd.DataFrame(\n",
    "        {\n",
    "            'US Model': us_model_list,\n",
    "            'Fbeta Score': mean_scores,\n",
    "            'Std': std_list\n",
    "        }\n",
    "    )\n",
    "    us_df = us_df.sort_values(\n",
    "        by='Fbeta Score', ascending=False).reset_index(drop=True)\n",
    "    print(us_df)\n",
    "    plt.boxplot(us_scores, labels=us_names, showmeans=True)\n",
    "    plt.title(f'{mod_names[i]} Undersampling')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xgboost with params\n",
    "xgb_model, xgb_feats, xgb_name = home_xgb_setup()\n",
    "home_train_target, _ = load_home_targets()\n",
    "\n",
    "# get undersampling models\n",
    "us_models, us_names = get_us_models()\n",
    "\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "us_scores = []\n",
    "us_model_list = []\n",
    "mean_scores = []\n",
    "std_list = []\n",
    "for i in range(len(us_models)):\n",
    "    pipe = IMBPipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('us', us_models[i]),\n",
    "            ('model', xgb_model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scores = evaluate_model(xgb_feats, home_train_target, pipe, k_splits=10)\n",
    "    us_scores.append(scores)\n",
    "    us_model_list.append(us_models[i])\n",
    "    mean_scores.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "\n",
    "us_df = pd.DataFrame(\n",
    "    {\n",
    "        'US Model': us_model_list,\n",
    "        'Fbeta Score': mean_scores,\n",
    "        'Std': std_list\n",
    "    }\n",
    ")\n",
    "us_df = us_df.sort_values(\n",
    "    by='Fbeta Score', ascending=False).reset_index(drop=True)\n",
    "print(us_df)\n",
    "plt.boxplot(us_scores, labels=us_names, showmeans=True)\n",
    "plt.title(f'{xgb_name} Undersampling')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Away Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xgboost undersampling\n",
    "xgb_model, xgb_feats, xgb_name = away_xgb_setup()  # get xgboost setup\n",
    "gb_model, gb_feats, gb_name = away_gb_setup()\n",
    "ab_model, ab_feats, ab_name = away_ab_setup()\n",
    "away_train_target, _ = load_away_targets()  # load target\n",
    "\n",
    "models = [xgb_model, gb_model, ab_model]\n",
    "mod_names = [xgb_name, gb_name, ab_name]\n",
    "feats = [xgb_feats, gb_feats, ab_feats]\n",
    "\n",
    "us_models, us_names = get_us_models()  # get undersampling models\n",
    "\n",
    "sc = StandardScaler(with_mean=False)  # initiate scaler\n",
    "\n",
    "# loop through undersampling models with pipeline\n",
    "for i in range(len(models)):\n",
    "    print(f'\\nStarting: {mod_names[i]}')\n",
    "    us_scores = []\n",
    "    us_model_list = []\n",
    "    mean_scores = []\n",
    "    std_list = []\n",
    "    for j in range(len(us_models)):\n",
    "        pipe = IMBPipeline(\n",
    "            steps=[\n",
    "                ('sc', sc),\n",
    "                ('us', us_models[j]),\n",
    "                ('mod', models[i])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # get undersampling model scores\n",
    "        scores = evaluate_model(feats[i], away_train_target, pipe, k_splits=10)\n",
    "        us_scores.append(scores)  # append lists\n",
    "        us_model_list.append(us_models[j])\n",
    "        mean_scores.append(np.mean(scores))\n",
    "        std_list.append(np.std(scores))\n",
    "    # df of undersampling model scores\n",
    "    us_df = pd.DataFrame(\n",
    "        {\n",
    "            'US Model': us_model_list,\n",
    "            'Fbeta Score': mean_scores,\n",
    "            'Std': std_list\n",
    "        }\n",
    "    )\n",
    "    us_df = us_df.sort_values(\n",
    "        by='Fbeta Score', ascending=False).reset_index(drop=True)\n",
    "    print(us_df)\n",
    "    plt.boxplot(us_scores, labels=us_names, showmeans=True)\n",
    "    plt.title(f'{mod_names[i]} Undersampling')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xgboost with params and lightgbm\n",
    "xgb_model, xgb_feats, xgb_name = away_xgb_setup()  # get xgboost setup\n",
    "lgbm_model, lgbm_feats, lgbm_name = away_lgbm_setup()\n",
    "\n",
    "away_train_target, _ = load_away_targets()  # load target\n",
    "\n",
    "models = [xgb_model, lgbm_model]\n",
    "mod_names = [xgb_name, lgbm_name]\n",
    "feats = [xgb_feats, lgbm_feats]\n",
    "\n",
    "us_models, us_names = get_us_models()  # get undersampling models\n",
    "\n",
    "sc = StandardScaler(with_mean=False)  # initiate scaler\n",
    "\n",
    "# loop through undersampling models with pipeline\n",
    "for i in range(len(models)):\n",
    "    print(f'\\nStarting: {mod_names[i]}')\n",
    "    us_scores = []\n",
    "    us_model_list = []\n",
    "    mean_scores = []\n",
    "    std_list = []\n",
    "    for j in range(len(us_models)):\n",
    "        pipe = IMBPipeline(\n",
    "            steps=[\n",
    "                ('sc', sc),\n",
    "                ('us', us_models[j]),\n",
    "                ('mod', models[i])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # get undersampling model scores\n",
    "        scores = evaluate_model(feats[i], away_train_target, pipe, k_splits=10)\n",
    "        us_scores.append(scores)  # append lists\n",
    "        us_model_list.append(us_models[j])\n",
    "        mean_scores.append(np.mean(scores))\n",
    "        std_list.append(np.std(scores))\n",
    "    # df of undersampling model scores\n",
    "    us_df = pd.DataFrame(\n",
    "        {\n",
    "            'US Model': us_model_list,\n",
    "            'Fbeta Score': mean_scores,\n",
    "            'Std': std_list\n",
    "        }\n",
    "    )\n",
    "    us_df = us_df.sort_values(\n",
    "        by='Fbeta Score', ascending=False).reset_index(drop=True)\n",
    "    print(us_df)\n",
    "    plt.boxplot(us_scores, labels=us_names, showmeans=True)\n",
    "    plt.title(f'{mod_names[i]} Undersampling')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Oversampling -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gradient boosting, logistic regression with pca\n",
    "# get models and features\n",
    "gb_model, gb_feats, gb_name = home_gb_setup()\n",
    "lr_model, lr_feats, lr_pca, lr_name = home_lr_setup()\n",
    "gnb_model, gnb_feats, gnb_pca, gnb_name = home_gnb_setup()\n",
    "models = [gb_model, lr_model, gnb_model]\n",
    "mod_names = [gb_name, lr_name, gnb_name]\n",
    "feats = [gb_feats, lr_feats, gnb_feats]\n",
    "home_train_target, _ = load_home_targets()\n",
    "\n",
    "# get oversampling models\n",
    "os_models, os_names = get_os_models()\n",
    "\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(f'Starting: {mod_names[i]}')\n",
    "    os_scores = []\n",
    "    os_model_list = []\n",
    "    mean_scores = []\n",
    "    std_list = []\n",
    "    for j in range(len(os_models)):\n",
    "        if mod_names[i] == 'GB':\n",
    "            pipe = IMBPipeline(\n",
    "                steps=[\n",
    "                    ('sc', sc),\n",
    "                    ('os', os_models[j]),\n",
    "                    ('model', models[i])\n",
    "                ]\n",
    "            )\n",
    "        elif mod_names[i] == 'LR':\n",
    "            pipe = IMBPipeline(\n",
    "                steps=[\n",
    "                    ('rs', rs),\n",
    "                    ('us', os_models[j]),\n",
    "                    ('pca', lr_pca),\n",
    "                    ('model', models[i])\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            pipe = IMBPipeline(\n",
    "                steps=[\n",
    "                    ('rs', rs),\n",
    "                    ('us', os_models[j]),\n",
    "                    ('pca', gnb_pca),\n",
    "                    ('model', models[i])\n",
    "                ]\n",
    "            )\n",
    "        scores = evaluate_model(feats[i], home_train_target, pipe, k_splits=10)\n",
    "        os_scores.append(scores)\n",
    "        os_model_list.append(os_models[j])\n",
    "        mean_scores.append(np.mean(scores))\n",
    "        std_list.append(np.std(scores))\n",
    "\n",
    "    os_df = pd.DataFrame(\n",
    "        {\n",
    "            'OS Model': os_model_list,\n",
    "            'Fbeta Score': mean_scores,\n",
    "            'Std': std_list\n",
    "        }\n",
    "    )\n",
    "    os_df = os_df.sort_values(\n",
    "        by='Fbeta Score', ascending=False).reset_index(drop=True)\n",
    "    print(os_df)\n",
    "    plt.boxplot(os_scores, labels=os_names, showmeans=True)\n",
    "    plt.title(f'{mod_names[i]} Oversampling')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost with params\n",
    "xgb_model, xgb_feats, xgb_name = home_xgb_setup()\n",
    "home_train_target, _ = load_home_targets()\n",
    "\n",
    "# get undersampling models\n",
    "os_models, os_names = get_os_models()\n",
    "\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "os_scores = []\n",
    "os_model_list = []\n",
    "mean_scores = []\n",
    "std_list = []\n",
    "for i in range(len(os_models)):\n",
    "    pipe = IMBPipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('os', os_models[i]),\n",
    "            ('model', xgb_model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scores = evaluate_model(xgb_feats, home_train_target, pipe, k_splits=10)\n",
    "    os_scores.append(scores)\n",
    "    os_model_list.append(os_models[i])\n",
    "    mean_scores.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "\n",
    "os_df = pd.DataFrame(\n",
    "    {\n",
    "        'OS Model': os_model_list,\n",
    "        'Fbeta Score': mean_scores,\n",
    "        'Std': std_list\n",
    "    }\n",
    ")\n",
    "os_df = os_df.sort_values(\n",
    "    by='Fbeta Score', ascending=False).reset_index(drop=True)\n",
    "print(os_df)\n",
    "plt.boxplot(os_scores, labels=os_names, showmeans=True)\n",
    "plt.title(f'{xgb_name} Oversampling')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Away Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xgboost oversampling\n",
    "xgb_model, xgb_feats, xgb_name = away_xgb_setup()  # get xgboost setup\n",
    "gb_model, gb_feats, gb_name = away_gb_setup()\n",
    "ab_model, ab_feats, ab_name = away_ab_setup()\n",
    "away_train_target, _ = load_away_targets()  # load target\n",
    "\n",
    "models = [xgb_model, gb_model, ab_model]\n",
    "mod_names = [xgb_name, gb_name, ab_name]\n",
    "feats = [xgb_feats, gb_feats, ab_feats]\n",
    "\n",
    "os_models, os_names = get_os_models()  # get oversampling models\n",
    "\n",
    "sc = StandardScaler(with_mean=False)  # initiate scaler\n",
    "\n",
    "# loop through oversampling models with pipeline\n",
    "for i in range(len(models)):\n",
    "    print(f'\\nStarting: {mod_names[i]}')\n",
    "    os_scores = []\n",
    "    os_model_list = []\n",
    "    mean_scores = []\n",
    "    std_list = []\n",
    "    for j in range(len(os_models)):\n",
    "        pipe = IMBPipeline(\n",
    "            steps=[\n",
    "                ('sc', sc),\n",
    "                ('os', os_models[j]),\n",
    "                ('xgb', models[i])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # get oversampling model scores\n",
    "        scores = evaluate_model(feats[i], away_train_target, pipe, k_splits=10)\n",
    "        os_scores.append(scores)  # append lists\n",
    "        os_model_list.append(os_models[j])\n",
    "        mean_scores.append(np.mean(scores))\n",
    "        std_list.append(np.std(scores))\n",
    "    # df of oversampling model scores\n",
    "    os_df = pd.DataFrame(\n",
    "        {\n",
    "            'OS Model': os_model_list,\n",
    "            'Fbeta Score': mean_scores,\n",
    "            'Std': std_list\n",
    "        }\n",
    "    )\n",
    "    os_df = os_df.sort_values(\n",
    "        by='Fbeta Score', ascending=False).reset_index(drop=True)\n",
    "    print(os_df)\n",
    "    plt.boxplot(os_scores, labels=os_names, showmeans=True)\n",
    "    plt.title(f'{xgb_name} Oversampling')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xgboost with params and lightgbm\n",
    "xgb_model, xgb_feats, xgb_name = away_xgb_setup()  # get xgboost setup\n",
    "lgbm_model, lgbm_feats, lgbm_name = away_lgbm_setup()\n",
    "\n",
    "away_train_target, _ = load_away_targets()  # load target\n",
    "\n",
    "models = [xgb_model, lgbm_model]\n",
    "mod_names = [xgb_name, lgbm_name]\n",
    "feats = [xgb_feats, lgbm_feats]\n",
    "\n",
    "os_models, os_names = get_os_models()  # get oversampling models\n",
    "\n",
    "sc = StandardScaler(with_mean=False)  # initiate scaler\n",
    "\n",
    "# loop through oversampling models with pipeline\n",
    "for i in range(len(models)):\n",
    "    print(f'\\nStarting: {mod_names[i]}')\n",
    "    os_scores = []\n",
    "    os_model_list = []\n",
    "    mean_scores = []\n",
    "    std_list = []\n",
    "    for j in range(len(os_models)):\n",
    "        pipe = IMBPipeline(\n",
    "            steps=[\n",
    "                ('sc', sc),\n",
    "                ('us', os_models[j]),\n",
    "                ('mod', models[i])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # get oversampling model scores\n",
    "        scores = evaluate_model(feats[i], away_train_target, pipe, k_splits=10)\n",
    "        os_scores.append(scores)  # append lists\n",
    "        os_model_list.append(os_models[j])\n",
    "        mean_scores.append(np.mean(scores))\n",
    "        std_list.append(np.std(scores))\n",
    "    # df of undersampling model scores\n",
    "    os_df = pd.DataFrame(\n",
    "        {\n",
    "            'OS Model': os_model_list,\n",
    "            'Fbeta Score': mean_scores,\n",
    "            'Std': std_list\n",
    "        }\n",
    "    )\n",
    "    os_df = os_df.sort_values(\n",
    "        by='Fbeta Score', ascending=False).reset_index(drop=True)\n",
    "    print(os_df)\n",
    "    plt.boxplot(os_scores, labels=os_names, showmeans=True)\n",
    "    plt.title(f'{mod_names[i]} Oversampling')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Summary -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "under and oversampling is implemented to balance the dataset for classification tasks, to provide better insights of the characteristics of the minority class from which the models will learn. Without balancing the dataset the models will be good at predicting the majority class and next to useless at predicting the minority class depending on how severely imbalanced the dataset is. To help mitigate this issue undersampling or oversampling or both can be applied to the dataset; at a high level undersampling involves removing examples of the majority class, oversampling involves creating more examples of the minority class or a combination of both can be used. For each method some criteria is used to determine which examples should be sampled, for example with some oversampling methods examples near the borderline between the two classes get resampled as these minority examples can be misclassified and sampling these could help the model accurately predict the correct class.\n",
    "\n",
    "undersampling home models... \n",
    "\n",
    "    Gradient Boosting with tomeklinks fbeta score: 0.589236,   std: 0.009513\n",
    "\n",
    "    Logistic Regression with near miss ver3 fbeta score: 0.592371,    std: 0.008272\n",
    "    \n",
    "    Gaussian NB with near miss ver3 fbeat score: 0.576640,    std: 0.010239\n",
    "    \n",
    "    XGBoost with instance hardness threshold fbeta score: 0.589392,   std: 0.008605\n",
    "\n",
    "undersampling away models....\n",
    "\n",
    "    XGBoost with one sided selection fbeta score: 0.655338,    std: 0.004663\n",
    "    \n",
    "    Gradient Boosting with tomeklinks fbeat score: 0.653820,    std: 0.006291\n",
    "    \n",
    "    AdaBoost with tomeklinks fbeat score: 0.653018,    std: 0.006094\n",
    "    \n",
    "    Light GBM with one sided selection fbeta score: 0.651019,    std: 0.006110\n",
    "\n",
    "\n",
    "oversampling home models... \n",
    "\n",
    "    Gradient Boosting with svm smote fbeta score: 0.590869,   std: 0.009334\n",
    "\n",
    "    Logistic Regression with kmeans smote fbeta score: 0.591988,    std: 0.010471\n",
    "    \n",
    "    Gaussian NB with kmean smote fbeat score: 0.581018,    std: 0.006867\n",
    "    \n",
    "    XGBoost with borderline smote fbeta score: 0.592335,   std: 0.008925\n",
    "\n",
    "oversampling away models....\n",
    "\n",
    "    XGBoost with svm smote fbeta score:  0.661319    std: 0.005484\n",
    "    \n",
    "    Gradient Boosting with adasyn fbeta score: 0.662989    std: 0.006634\n",
    "    \n",
    "    AdaBoost with svm smote fbeta score: 0.657282   std: 0.007692\n",
    "    \n",
    "    Light GBM with svm smote fbeta score: 0.659310,    std: 0.006528\n",
    "\n",
    "\n",
    "models with the greatest increase in performance to proceed with... \n",
    "\n",
    "    Home models: Logitic Regression with near miss ver3 undersampling, XGBoost with borderline smote oversampling\n",
    "    \n",
    "    Away models: XGBoost with svm smote oversampling, Gradient Boosting with adasyn oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Hyperparameter Tuning --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home.. xgboost model hyperopt\n",
    "xgb_model, xgb_feats, xgb_bsmote, xgb_name = home_xgb_setup()\n",
    "home_train_target, _ = load_home_targets()\n",
    "sc = StandardScaler(with_mean=False, with_std=True)\n",
    "pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('scaler', sc),\n",
    "        ('us', xgb_bsmote),\n",
    "        ('model', xgb_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def xgb_objective(params):\n",
    "    pipe.set_params(**params)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "    metric = make_scorer(fbeta)\n",
    "    scores = cross_val_score(pipe, xgb_feats, np.array(\n",
    "        home_train_target).reshape(-1, ), scoring=metric, cv=cv, n_jobs=-1)\n",
    "    #scores = evaluate_model(lr_feats, np.array(home_train_target).reshape(-1, ), pipe, k_splits = 10)\n",
    "    avg_loss = 1 - np.mean(scores)\n",
    "    return {'loss': avg_loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# define parameters\n",
    "param_space = {\n",
    "    'model__n_estimators': scope.int(hp.quniform('model__n_estimators', 100, 1500, 10)),\n",
    "    'model__learning_rate': hp.uniform('model__learning_rate', 0.01, 1.0)\n",
    "    # 'model__max_depth': scope.int(hp.quniform('model__max_depth', 3, 10, 1)),\n",
    "    # 'model__min_child_weight': scope.int(hp.quniform('model__min_child_weight', 1, 12, 2)),\n",
    "    # 'model__gamma': hp.uniform('model__gamma', 0.0, 0.7)\n",
    "    # 'model__subsample': hp.uniform('model__subsample', 0.5, 0.9),\n",
    "    # 'model__colsample_bytree': hp.uniform('model__colsample_bytree', 0.5, 0.9)\n",
    "    # 'model__reg_alpha': hp.uniform('model__reg_alpha', 0.0001, 0.2),\n",
    "    # 'model__reg_lambda': hp.uniform('model__reg_lambda', 0.0001, 0.2)\n",
    "}\n",
    "\n",
    "# optimize model params\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=xgb_objective, space=param_space,\n",
    "                   algo=tpe.suggest, max_evals=200, trials=trials)\n",
    "\n",
    "best_param_space = space_eval(param_space, best_params)\n",
    "print(f'Best Parameters:\\n{best_param_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" best loss: 0.40742098389303627... after undersampling tuning\n",
    "Best Parameters: {'model__max_depth': 3, 'model__min_child_weight': 8}  best loss: 0.40911686712965145\n",
    "Best Parameters: {'model__gamma': 0.6936419289666603}  best loss: 0.40906388544775685\n",
    "Best Parameters: {'model__colsample_bytree': 0.5920903811620744, 'model__subsample': 0.8374088758397853} best loss: 0.40730940803486004\n",
    "Best Parameters: {'model__reg_alpha': 0.07425990654719038, 'model__reg_lambda': 0.16768800738594583} best loss: 0.40719825524837827\n",
    "Best Parameters: {'model__learning_rate': 0.0488938809129075, 'model__n_estimators': 320} best loss: 0.4074975818679476\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate XGB tuned model\n",
    "xgb_model, xgb_feats, xgb_bsmote, xgb_name = home_xgb_setup()\n",
    "home_train_target, _ = load_home_targets()\n",
    "sc = StandardScaler(with_mean=False, with_std=True)\n",
    "pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('scaler', sc),\n",
    "        ('us', xgb_bsmote),\n",
    "        ('model', xgb_model)\n",
    "    ]\n",
    ")\n",
    "scores = evaluate_model(xgb_feats, np.array(\n",
    "    home_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "print(f'Tuned XGB Avg Fbeta: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model hyperopt\n",
    "lr_model, lr_feats, lr_pca, lr_nm3, lr_name = home_lr_setup()\n",
    "home_train_target, _ = load_home_targets()\n",
    "rs = RobustScaler(with_centering=False)\n",
    "pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('scaler', rs),\n",
    "        ('us', lr_nm3),\n",
    "        ('pca', lr_pca),\n",
    "        ('model', lr_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def lr_objective(params):\n",
    "    pipe.set_params(**params)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "    metric = make_scorer(fbeta)\n",
    "    scores = cross_val_score(pipe, lr_feats, np.array(\n",
    "        home_train_target).reshape(-1, ), scoring=metric, cv=cv, n_jobs=1)\n",
    "    #scores = evaluate_model(lr_feats, np.array(home_train_target).reshape(-1, ), pipe, k_splits = 10)\n",
    "    avg_loss = 1 - np.mean(scores)\n",
    "    return {'loss': avg_loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# define parameters\n",
    "param_space = {\n",
    "    # 'model__penalty': hp.choice('model__penalty',\n",
    "    #                           [{'model__penalty': hp.choice('l1_penalty', ['l1']),\n",
    "    #                                 'model__solver': hp.choice('l1_solver', ['saga', 'liblinear'])},\n",
    "    #                            {'model__penalty': hp.choice('l2_penalty', ['l2']),\n",
    "    #                                 'model__solver': hp.choice('l2_solver', ['newton-cg', 'lbfgs', 'sag', 'saga', 'liblinear'])},\n",
    "    #                            {'model__penalty': hp.choice('none_penalty', ['none']),\n",
    "    #                                 'model__solver': hp.choice('none_solver', ['newton-cg','lbfgs', 'sag', 'saga'])},\n",
    "    #                            {'model__penalty': hp.choice('enet_penalty', ['elasticnet']),\n",
    "    #                                 'model__solver': hp.choice('sags_solver', ['saga'])}\n",
    "    #                         ]),\n",
    "    'model__penalty': 'l2',\n",
    "    'model__solver':  hp.choice('model__solver', ['newton-cg', 'lbfgs', 'sag', 'saga', 'liblinear']),\n",
    "    'model__C': hp.uniform('model__C', 0.1, 3.0),\n",
    "    'model__max_iter': scope.int(hp.quniform('model__max_iter', 100, 300, 10)),\n",
    "    'model__tol': hp.loguniform('model__tol', np.log(1.0001), np.log(1.105)),\n",
    "    'model__class_weight': hp.choice('model__class_weight', ['balanced', None])\n",
    "}\n",
    "\n",
    "# optimize model params\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=lr_objective, space=param_space,\n",
    "                   algo=tpe.suggest, max_evals=150, trials=trials)\n",
    "\n",
    "best_param_space = space_eval(param_space, best_params)\n",
    "print(f'Best Parameters:\\n{best_param_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Parameters: {'scaler__with_centering': False, 'us__n_neighbors': 3, 'us__n_neighbors_ver3': 3}\n",
    "        best loss: 0.40762876656556046\n",
    "        \n",
    "Best Parameters: ---- l2 penalty ----\n",
    "{'model__C': 1.0516419703666957, 'model__class_weight': 'balanced', 'model__max_iter': 300, 'model__penalty': 'l2', \n",
    "'model__solver': 'liblinear', 'model__tol': 1.0316431882026003}\n",
    "        best loss: 0.40744398053239705\n",
    "        \n",
    "Best Parameters: --- l1 penalty ----\n",
    "{'model__C': 0.13916392773859043, 'model__class_weight': None, 'model__max_iter': 130, 'model__penalty': 'l1', \n",
    "'model__solver': 'liblinear', 'model__tol': 1.0683985965344678}\n",
    "        best loss: 0.4071924589486443\n",
    "\n",
    "Best Parameters: ---- none penalty ----\n",
    "{'model__class_weight': None, 'model__max_iter': 110, 'model__penalty': 'none', 'model__solver': 'lbfgs', \n",
    "'model__tol': 1.0006085827691054}\n",
    "        best loss: 0.40762871501378917\n",
    "        \n",
    "Best Parameters: ---- elasticnet penalty ----\n",
    "{'model__C': 0.10648895061859351, 'model__class_weight': 'balanced', 'model__l1_ratio': 0.0017244126069944493, \n",
    "'model__max_iter': 200, 'model__penalty': 'elasticnet', 'model__solver': 'saga', 'model__tol': 1.019302605931096}\n",
    "        best loss: 0.4113738956377505\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home logistic regression model tuning evaluation\n",
    "lr_model, lr_feats, lr_pca, lr_nm3, lr_name = home_lr_setup()\n",
    "home_train_target, _ = load_home_targets()\n",
    "rs = RobustScaler(with_centering=False)\n",
    "pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('scaler', rs),\n",
    "        ('us', lr_nm3),\n",
    "        ('pca', lr_pca),\n",
    "        ('model', lr_model)\n",
    "    ]\n",
    ")\n",
    "scores = evaluate_model(lr_feats, np.array(\n",
    "    home_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "print(\n",
    "    f'Home logistic regression after model tuning, Avg Fbeta: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking classifier with both home models\n",
    "train_features = load_train_features()\n",
    "lr_model, lr_feats, lr_pca, lr_nm3, lr_name = home_lr_setup()\n",
    "xgb_model, xgb_feats, xgb_bsmote, xgb_name = home_xgb_setup()\n",
    "home_train_target, _ = load_home_targets()\n",
    "rs = RobustScaler(with_centering=False)\n",
    "sc = StandardScaler(with_mean=False, with_std=True)\n",
    "#cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 2, random_state = 1)\n",
    "estims = [\n",
    "    ('lr', IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(lr_feats.columns)),\n",
    "            ('scaler', rs),\n",
    "            ('us', lr_nm3),\n",
    "            ('pca', lr_pca),\n",
    "            ('model', lr_model)\n",
    "        ])\n",
    "     ),\n",
    "    ('xgb', IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(xgb_feats.columns)),\n",
    "            ('scaler', sc),\n",
    "            ('os', xgb_bsmote),\n",
    "            ('model', xgb_model)\n",
    "        ])\n",
    "     )\n",
    "]\n",
    "\n",
    "sc = StackingClassifier(\n",
    "    estimators=estims,\n",
    "    final_estimator=GradientBoostingClassifier(\n",
    "        n_estimators=150, random_state=42),\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "scores = evaluate_model(train_features, np.array(\n",
    "    home_train_target).reshape(-1,), sc, k_splits=10)\n",
    "print(\n",
    "    f'Home LR/XGB models Stacking Classifier, Avg Fbeta: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home model voting classifier\n",
    "train_features = load_train_features()\n",
    "lr_model, lr_feats, lr_pca, lr_nm3, lr_name = home_lr_setup()\n",
    "xgb_model, xgb_feats, xgb_bsmote, xgb_name = home_xgb_setup()\n",
    "home_train_target, _ = load_home_targets()\n",
    "rs = RobustScaler(with_centering=False)\n",
    "sc = StandardScaler(with_mean=False, with_std=True)\n",
    "\n",
    "estims = [\n",
    "    ('lr', IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(lr_feats.columns)),\n",
    "            ('scaler', rs),\n",
    "            ('us', lr_nm3),\n",
    "            ('pca', lr_pca),\n",
    "            ('model', lr_model)\n",
    "        ])\n",
    "     ),\n",
    "    ('xgb', IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(xgb_feats.columns)),\n",
    "            ('scaler', sc),\n",
    "            ('os', xgb_bsmote),\n",
    "            ('model', xgb_model)\n",
    "        ])\n",
    "     )\n",
    "]\n",
    "vc = VotingClassifier(\n",
    "    estimators=estims,\n",
    "    voting='hard',\n",
    "    n_jobs=-1\n",
    ")\n",
    "scores = evaluate_model(train_features, np.array(\n",
    "    home_train_target).reshape(-1,), vc, k_splits=10)\n",
    "print(f'Home {lr_name}/{xgb_name} models Voting Classifier, Avg Fbeta: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Away Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting model hyperopt\n",
    "train_features = load_train_features()\n",
    "gb_pipe, _, gb_name = away_gb_setup()\n",
    "away_train_target, _ = load_away_targets()\n",
    "\n",
    "\n",
    "def gb_objective(params):\n",
    "    gb_pipe.set_params(**params)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "    metric = make_scorer(fbeta)\n",
    "    scores = cross_val_score(gb_pipe, train_features, np.array(\n",
    "        away_train_target).reshape(-1, ), scoring=metric, cv=cv, n_jobs=-1)\n",
    "    #scores = evaluate_model(lr_feats, np.array(home_train_target).reshape(-1, ), pipe, k_splits = 10)\n",
    "    avg_loss = 1 - np.mean(scores)\n",
    "    return {'loss': avg_loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# define parameters\n",
    "param_space = {\n",
    "    # hp.uniform('model__learning_rate', 0.001, 0.1),\n",
    "    'model__learning_rate': 0.021886438886199792,\n",
    "    # scope.int(hp.quniform('model__n_estimators', 100, 750, 10)),\n",
    "    'model__n_estimators': 730,\n",
    "    # hp.uniform('model__subsample', 0.1, 1.0),\n",
    "    'model__subsample': 0.5976371247166854,\n",
    "    # scope.int(hp.quniform('model__min_samples_split', 500, 2000, 25)),\n",
    "    'model__min_samples_split': 1450,\n",
    "    # scope.int(hp.quniform('model__min_samples_leaf', 50, 500, 10)),\n",
    "    'model__min_samples_leaf': 480,\n",
    "    # scope.int(hp.quniform('model__max_depth', 3, 11, 1)),\n",
    "    'model__max_depth': 3,\n",
    "    # scope.int(hp.quniform('model__max_features', 1, 8, 1)),\n",
    "    'model__max_features': 7,\n",
    "    'model__ccp_alpha': hp.uniform('model__ccp_alpha', 0.001, 0.1)\n",
    "}\n",
    "\n",
    "# optimize model params\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=gb_objective, space=param_space,\n",
    "                   algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "\n",
    "best_param_space = space_eval(param_space, best_params)\n",
    "print(f'Best Parameters:\\n{best_param_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Parameters: {'os__n_neighbors': 6, 'scaler__with_mean': False, 'scaler__with_std': True} best loss: 0.33664451412221863\n",
    "Best Parameters: {'model__ccp_alpha': 1.1243946224171244, 'model__max_depth': 4.0, 'model__max_features': 8, \n",
    "                  'model__min_samples_leaf': 100, 'model__min_samples_split': 1000, 'model__subsample': 0.1967614244568458}\n",
    "                  best loss: 0.38974766400850225\n",
    "Best Parameters: {'model__max_depth': 3.0, 'model__max_features': 8, 'model__min_samples_leaf': 420, \n",
    "                  'model__min_samples_split': 675, 'model__subsample': 0.43918481213848615}\n",
    "                   best loss: 0.33716110968295065\n",
    "Best Parameters: {'model__learning_rate': 0.027115584500934167, 'model__n_estimators': 650} best loss: 0.334564047993395\n",
    "\n",
    "##### after overfitting #####\n",
    "\n",
    "Best Parameters:\n",
    "{'model__ccp_alpha': 1.071038490980779, 'model__learning_rate': 0.045865681876250834, 'model__max_features': 4, \n",
    " 'model__n_estimators': 660, 'model__subsample': 0.7428739111521593}  best loss: 0.38974766400850225\n",
    " \n",
    "Best Parameters:\n",
    "{'model__learning_rate': 0.021886438886199792, 'model__max_depth': 3, 'model__max_features': 7, \n",
    " 'model__min_samples_leaf': 480, 'model__min_samples_split': 1450, 'model__n_estimators': 730, \n",
    " 'model__subsample': 0.5976371247166854}  best loss: 0.33505772349746543\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate gradient boosting tuning\n",
    "gb_model, gb_feats, gb_adasyn, gb_name = away_gb_setup()\n",
    "away_train_target, _ = load_away_targets()\n",
    "sc = StandardScaler(with_mean=False, with_std=True)\n",
    "pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('scaler', sc),\n",
    "        ('os', gb_adasyn),\n",
    "        ('model', gb_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "scores = evaluate_model(gb_feats, np.array(\n",
    "    away_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "print(f'Tuned GB model Avg Fbeta: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting with bagging\n",
    "gb_model, gb_feats, gb_adasyn, gb_name = away_gb_setup()\n",
    "away_train_target, _ = load_away_targets()\n",
    "sc = StandardScaler(with_mean=False, with_std=True)\n",
    "bc = BaggingClassifier(\n",
    "    base_estimator=gb_model,\n",
    "    n_estimators=50,\n",
    "    max_samples=0.8,\n",
    "    max_features=0.7,\n",
    "    bootstrap_features=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('scaler', sc),\n",
    "        ('os', gb_adasyn),\n",
    "        ('model', bc)\n",
    "    ]\n",
    ")\n",
    "\n",
    "scores = evaluate_model(gb_feats, np.array(\n",
    "    away_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "print(\n",
    "    f'Tuned {gb_name} model Avg Fbeta: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting with bagging\n",
    "gb_pipe, _, gb_name = away_gb_setup()\n",
    "train_features = load_train_features()\n",
    "test_features = load_test_features()\n",
    "away_train_target, away_test_target = load_away_targets()\n",
    "\n",
    "# get predictions for cluster 1 & 3 features\n",
    "test_cluster_feats = load_cluster_test_feats()\n",
    "rf_cl1_model = joblib.load('cl1_rf_model.sav')\n",
    "rf_pred = rf_cl1_model.predict(test_cluster_feats)\n",
    "gb_cl3_model = joblib.load('cl3_gb_model.sav')\n",
    "gb_pred = gb_cl3_model.predict(test_cluster_feats)\n",
    "# load test features, add cluster 1 & 3 predictions, keep model features\n",
    "test_features['cluster_1'] = rf_pred\n",
    "test_features['cluster_3'] = gb_pred\n",
    "\n",
    "gb_feats = train_features[['AHTGC5PHG', 'AATSOT5PG', 'AHTSOT5PHG', 'HA_AHTGS5PG_diff', 'AHT_GS_P5PG_ratio',\n",
    "                           'AwayCapacityDiff_bin', 'cluster_1', 'cluster_3', 'HT_PrevSeasonPos_inv',\n",
    "                           'AT_PrevSeasonPos_inv', 'bxcx_AHTGC5PG', 'bxcx_AATSOT5PG', 'bxcx_AHT_GS_P5PG_ratio']]\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=650,\n",
    "                                      learning_rate=0.027115584500934167,\n",
    "                                      max_depth=3,\n",
    "                                      max_features=8,\n",
    "                                      min_samples_leaf=420,\n",
    "                                      min_samples_split=675,\n",
    "                                      subsample=0.43918481213848615,\n",
    "                                      #ccp_alpha =  1.1243946224171244,\n",
    "                                      random_state=42)\n",
    "gb_adasyn = ADASYN(n_neighbors=6, random_state=1, n_jobs=-1)\n",
    "\n",
    "bc = BaggingClassifier(\n",
    "    base_estimator=gb_model,\n",
    "    n_estimators=50,\n",
    "    max_samples=0.8,\n",
    "    max_features=0.7,\n",
    "    bootstrap_features=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('trans', KeepColumnsTransformer(gb_feats.columns)),\n",
    "        ('scaler', StandardScaler(with_mean=False, with_std=True)),\n",
    "        ('os', gb_adasyn),\n",
    "        ('model', bc)\n",
    "    ]\n",
    ")\n",
    "\n",
    "scores = evaluate_model(train_features, np.array(\n",
    "    away_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "print(f'{gb_name} Train Avg Fbeta: {np.mean(scores)},    Std: {np.std(scores)}')\n",
    "\n",
    "pipe.fit(train_features, np.array(away_train_target).reshape(-1,))\n",
    "pred = pipe.predict(test_features)\n",
    "print(f'Test Fbeta: {fbeta(away_test_target, pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWAY.. xgboost model hyperopt\n",
    "xgb_model, xgb_feats, xgb_svms, xgb_name = away_xgb_setup()\n",
    "away_train_target, _ = load_away_targets()\n",
    "sc = StandardScaler(with_mean=False, with_std=True)\n",
    "pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('scaler', sc),\n",
    "        ('os', xgb_svms),\n",
    "        ('model', xgb_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def xgb_objective(params):\n",
    "    pipe.set_params(**params)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "    metric = make_scorer(fbeta)\n",
    "    scores = cross_val_score(pipe, xgb_feats, np.array(\n",
    "        away_train_target).reshape(-1, ), scoring=metric, cv=cv, n_jobs=-1)\n",
    "    #scores = evaluate_model(lr_feats, np.array(home_train_target).reshape(-1, ), pipe, k_splits = 10)\n",
    "    avg_loss = 1 - np.mean(scores)\n",
    "    return {'loss': avg_loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# define parameters\n",
    "param_space = {\n",
    "    'model__n_estimators': scope.int(hp.quniform('model__n_estimators', 200, 2000, 10)),\n",
    "    'model__learning_rate': hp.uniform('model__learning_rate', 0.01, 0.1)\n",
    "    # 'model__max_depth': scope.int(hp.quniform('model__max_depth', 3, 12, 1)),\n",
    "    # 'model__min_child_weight': scope.int(hp.quniform('model__min_child_weight', 1, 12, 1)),\n",
    "    # 'model__gamma': hp.uniform('model__gamma', 0.0, 0.8),\n",
    "    # 'model__subsample': hp.uniform('model__subsample', 0.5, 1.0),\n",
    "    # 'model__colsample_bytree': hp.uniform('model__colsample_bytree', 0.5, 0.9),\n",
    "    # 'model__reg_alpha': hp.uniform('model__reg_alpha', 0.001, 0.2),\n",
    "    # 'model__reg_lambda': hp.uniform('model__reg_lambda', 0.001, 0.2)\n",
    "}\n",
    "\n",
    "# optimize model params\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=xgb_objective, space=param_space,\n",
    "                   algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "\n",
    "best_param_space = space_eval(param_space, best_params)\n",
    "print(f'Best Parameters:\\n{best_param_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Parameters:\n",
    "{'os__k_neighbors': 8, 'os__m_neighbors': 14, 'os__svm_estimator': SVC(), 'scaler__with_mean': False, 'scaler__with_std': True}\n",
    "        best loss: 0.3404996349238907\n",
    "Best Parameters:\n",
    "{'model__gamma': 0.6757959901913699, 'model__max_depth': 3, 'model__min_child_weight': 10, 'model__subsample': 0.7962485851393263} \n",
    "        best loss: 0.3398373294482273\n",
    "Best Parameters:\n",
    "{'model__colsample_bytree': 0.5735095367483903, 'model__reg_alpha': 0.13029677939259385, 'model__reg_lambda': 0.10315636718690373}\n",
    "        best loss: 0.3395668383422825\n",
    "Best Parameters: {'model__learning_rate': 0.018277402480679054, 'model__n_estimators': 570}\n",
    "        best loss: 0.3375532945064921\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away XGB model tuning evaluation\n",
    "xgb_model, xgb_feats, xgb_svms, xgb_name = away_xgb_setup()\n",
    "away_train_target, _ = load_away_targets()\n",
    "sc = StandardScaler(with_mean=False, with_std=True)\n",
    "pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('scaler', sc),\n",
    "        ('os', xgb_svms),\n",
    "        ('model', xgb_model)\n",
    "    ]\n",
    ")\n",
    "scores = evaluate_model(xgb_feats, np.array(\n",
    "    away_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "print(\n",
    "    f'Away XGB model after tuning, Avg Fbeta: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away models stacking classifier\n",
    "train_features = load_train_features()\n",
    "xgb_model, xgb_feats, xgb_svms, xgb_name = away_xgb_setup()\n",
    "gb_model, gb_feats, gb_adasyn, gb_name = away_gb_setup()\n",
    "away_train_target, _ = load_away_targets()\n",
    "sc = StandardScaler(with_mean=False, with_std=True)\n",
    "estims = [\n",
    "    ('gb', IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(gb_feats.columns)),\n",
    "            ('scaler', sc),\n",
    "            ('os', gb_adasyn),\n",
    "            ('model', gb_model)\n",
    "        ])\n",
    "     ),\n",
    "    ('xgb', IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(xgb_feats.columns)),\n",
    "            ('scaler', sc),\n",
    "            ('os', xgb_svms),\n",
    "            ('model', xgb_model)\n",
    "        ])\n",
    "     )\n",
    "]\n",
    "\n",
    "sc = StackingClassifier(\n",
    "    estimators=estims,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "scores = evaluate_model(train_features, np.array(\n",
    "    away_train_target).reshape(-1,), sc, k_splits=10)\n",
    "print(f'Away {gb_name}/{xgb_name} models Stacking Classifier, Avg Fbeta: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away models voting classifier\n",
    "train_features = load_train_features()\n",
    "xgb_model, xgb_feats, xgb_svms, xgb_name = away_xgb_setup()\n",
    "gb_model, gb_feats, gb_adasyn, gb_name = away_gb_setup()\n",
    "away_train_target, _ = load_away_targets()\n",
    "sc = StandardScaler(with_mean=False, with_std=True)\n",
    "estims = [\n",
    "    ('gb', IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(gb_feats.columns)),\n",
    "            ('scaler', sc),\n",
    "            ('os', gb_adasyn),\n",
    "            ('model', gb_model)\n",
    "        ])\n",
    "     ),\n",
    "    ('xgb', IMBPipeline(\n",
    "        steps=[\n",
    "            ('trans', KeepColumnsTransformer(xgb_feats.columns)),\n",
    "            ('scaler', sc),\n",
    "            ('os', xgb_svms),\n",
    "            ('model', xgb_model)\n",
    "        ])\n",
    "     )\n",
    "]\n",
    "vc = VotingClassifier(\n",
    "    estimators=estims,\n",
    "    voting='soft',\n",
    "    n_jobs=1\n",
    ")\n",
    "scores = evaluate_model(train_features, np.array(\n",
    "    away_train_target).reshape(-1,), vc, k_splits=10)\n",
    "print(f'Away {gb_name}/{xgb_name} models Voting Classifier, Avg Fbeta: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting model hyperopt\n",
    "train_features = load_train_features()\n",
    "lgbm_pipe, lgbm_name = away_lgbm_setup()\n",
    "away_train_target, _ = load_away_targets()\n",
    "\n",
    "\n",
    "def lgbm_objective(params):\n",
    "    lgbm_pipe.set_params(**params)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "    metric = make_scorer(fbeta)\n",
    "    scores = cross_val_score(lgbm_pipe, train_features, np.array(\n",
    "        away_train_target).reshape(-1, ), scoring=metric, cv=cv, n_jobs=-1)\n",
    "    #scores = evaluate_model(lr_feats, np.array(home_train_target).reshape(-1, ), pipe, k_splits = 10)\n",
    "    avg_loss = 1 - np.mean(scores)\n",
    "    return {'loss': avg_loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# define parameters\n",
    "param_space = {\n",
    "    'model__learning_rate': hp.uniform('model__learning_rate', 0.001, 0.05),\n",
    "    'model__n_estimators': scope.int(hp.quniform('model__n_estimators', 100, 750, 10)),\n",
    "    # scope.int(hp.quniform('model__num_leaves', 30, 90, 5)),\n",
    "    'model__num_leaves': 35,\n",
    "    # scope.int(hp.quniform('model__min_child_samples', 100, 1500, 10)),\n",
    "    'model__min_child_samples': 1320,\n",
    "    # hp.uniform('model__colsample_bytree', 0.5, 1.0),\n",
    "    'model__colsample_bytree': 0.7787949835735254,\n",
    "    # hp.uniform('model__subsample', 0.5, 1.0),\n",
    "    'model__subsample': 0.8073575692094029,\n",
    "    # hp.choice('model__is_unbalance', [True, False]),\n",
    "    'model__is_unbalance': True,\n",
    "    # scope.int(hp.quniform('model__max_depth', 3, 11, 1)),\n",
    "    'model__max_depth': 4,\n",
    "    # 'model__max_bin': scope.int(hp.quniform('model__max_bin', 255, 300, 5)),\n",
    "    # hp.uniform('model__reg_alpha', 0.0, 0.1),\n",
    "    'model__reg_alpha': 0.06951672237498768,\n",
    "    # hp.uniform('model__reg_lambda', 0.0, 0.1)\n",
    "    'model__reg_lambda': 0.03784851967467663,\n",
    "}\n",
    "\n",
    "# optimize model params\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=lgbm_objective, space=param_space,\n",
    "                   algo=tpe.suggest, max_evals=75, trials=trials)\n",
    "\n",
    "best_param_space = space_eval(param_space, best_params)\n",
    "print(f'Best Parameters:\\n{best_param_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = load_train_features()\n",
    "lgbm_pipe, lgbm_name = away_lgbm_setup()\n",
    "away_train_target, _ = load_away_targets()\n",
    "\n",
    "scores = evaluate_model(train_features, np.array(\n",
    "    away_train_target).reshape(-1,), lgbm_pipe, k_splits=10)\n",
    "print(f'{lgbm_name} Avg Fbeta: {np.mean(scores)},   Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Parameters:  best loss: 0.3414808670872569\n",
    "{'os__k_neighbors': 3, 'os__m_neighbors': 7, 'scaler__with_mean': True, 'scaler__with_std': True}\n",
    "Best Parameters:\n",
    "{'model__colsample_bytree': 0.7787949835735254, 'model__is_unbalance': True, 'model__max_depth': 4, \n",
    " 'model__min_child_samples': 1320, 'model__num_leaves': 35, 'model__reg_alpha': 0.06951672237498768, \n",
    " 'model__reg_lambda': 0.03784851967467663, 'model__subsample': 0.8073575692094029}\n",
    " best loss: 0.33581922981611856\n",
    "Best Parameters:\n",
    "{'model__colsample_bytree': 0.7787949835735254, 'model__is_unbalance': True, 'model__learning_rate': 0.04250057994580665, \n",
    " 'model__max_depth': 4, 'model__min_child_samples': 1320, 'model__n_estimators': 470, 'model__num_leaves': 35, \n",
    " 'model__reg_alpha': 0.06951672237498768, 'model__reg_lambda': 0.03784851967467663, 'model__subsample': 0.8073575692094029}\n",
    " best loss: 0.3362585825540674\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Summary -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All model hyperparameter tuning was implemented using bayesian optimisation.\n",
    "\n",
    "Gradient boosting tuning involved tuning tree specific parameters and boosting parameters; \n",
    "\n",
    "    min_samples_split: the minimum number of samples (or observations) which are required in a node to be considered for                                splitting. Can provide control for overfitting.\n",
    "    min_samples_leaf: the minimum samples (or observations) required in a terminal node or leaf. Can control overfitting.\n",
    "    max_depth: the maximum depth of a tree.\n",
    "    max_features: The number of features to consider while searching for a best split. \n",
    "    \n",
    "    learning_rate: the impact of each tree on the final outcome. Used in conjunction with n_estimators, the lower the value\n",
    "                   usually provides better generalisation.\n",
    "    n_estimators: The number of sequential trees to be modeled. Used in conjunction with learning_rate\n",
    "    subsample: The fraction of observations to be selected for each tree. \n",
    "    \n",
    "XGBoost tuning involved tuning boosting parameters;\n",
    "\n",
    "    learning_rate: the impact of each tree on the final outcome. Used in conjunction with n_estimators, makes the model more                        robust\n",
    "    n_estimators: the number of boosting trees, used in conjunction eith learning_rate - higher n_estimators to lower                             learning_rate\n",
    "    min_child_weight: the minimum sum of weights of all observations required in a child. Similar to min_samples_leaf for                             gradient boosting, can control overfitting.\n",
    "    max_depth: maximum depth of the tree.\n",
    "    gamma: specifies the minimum loss reduction required to make a split.\n",
    "    subsample: same as gradient boosting.\n",
    "    colsample_bytree: the fraction of columns to be randomly sampled for each tree. similar to max features with gradient                             boosting.\n",
    "    reg_lambda: L2 regularisation on weights, helps reduce overfitting\n",
    "    reg_lambda: L1 regularisation on weights.\n",
    "    \n",
    "Logistic Regression doesnt really have any critical hyperparameters to tune, though there are hyperparameters to aid performance for the data it is modelling;\n",
    "\n",
    "    penalty: Used to specify the norm used in the penalization.\n",
    "    solver: optimisation algorithm, although there are specific algorithms for different types of data all solvers were included             in the search space.\n",
    "    max_iter: number of iterations for the solver to converge\n",
    "    C: controls the penalty strength\n",
    "    tol: tolerance for stopping\n",
    "    \n",
    "Light Gradient Boosting tuning involved tuning many of the same parameters listed with xgboost tuning and gradient boosting tuning, the only difference is num_leaves: Maximum tree leaves for base learners.\n",
    "\n",
    "The individual models were also combined into ensemble methods voting and stacking to see if performance could be gained.\n",
    "\n",
    "Home model results:\n",
    "\n",
    "    Logistic Regression model, Avg Fbeta: 0.5928075410513557,    Std: 0.008289114614265857\n",
    "    \n",
    "    XGBClassifier model, Avg Fbeta: 0.5925024181320524,    Std: 0.00791501842121371\n",
    "   \n",
    "    Stacked Classifier (LR/XGB) model, Avg Fbeta: 0.5836628041152927,    Std: 0.010158813335395256\n",
    "    \n",
    "    Voting Classifier (LR/XGB) model, Avg Fbeta: 0.5924814014193714,    Std: 0.008173213617041583\n",
    "    \n",
    "Away model results:\n",
    "\n",
    "    Gradient Boosting model, Avg Fbeta: 0.665435952006605,    Std: 0.00779246295616173\n",
    "    \n",
    "    XGBClassifier model, Avg Fbeta: 0.6624467054935079,    Std: 0.007283174908768594\n",
    "    \n",
    "    LGBMClassifier model, Avg Fbeta: 0.6637414174459326,   Std: 0.008821754261260821\n",
    "    \n",
    "    Stacked Classifier (GB/XGB) model, Avg Fbeta: 0.6389081116604908,    Std: 0.004767996936439064\n",
    "    \n",
    "    Voting Classifier (GB/XGB) model, Avg Fbeta: 0.665915932158899,    Std: 0.00686345949936166\n",
    "    \n",
    "Home Models:   logistic regression & XGBClassifier models on their own performed the best\n",
    "\n",
    "Away Models:   Gradient Boosting, XGBClassifier & the combination with the voting classifier performed the best\n",
    "\n",
    "As can be seen all models have improved fbeta scores.\n",
    "Proceed with testing models for generalisation also including a weighted average of stand alone models.\n",
    "\n",
    "##Update##:\n",
    "Found that gradient boosting model overfit, retuned gradient boosting model and included ccp_alpha parameter to help overfitting by pruning the tree. Corrected the overfit for good generalisation but the model is not performing aswell as the others, light gradient boosting model is now taking its place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Model Calibration --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression calibration\n",
    "train_features = load_train_features()\n",
    "test_features = load_test_features()\n",
    "home_train_target, home_test_target = load_home_targets()\n",
    "# get predictions for cluster 1 & 3 features\n",
    "test_cluster_feats = load_cluster_test_feats()\n",
    "rf_cl1_model = joblib.load('cl1_rf_model.sav')\n",
    "rf_pred = rf_cl1_model.predict(test_cluster_feats)\n",
    "gb_cl3_model = joblib.load('cl3_gb_model.sav')\n",
    "gb_pred = gb_cl3_model.predict(test_cluster_feats)\n",
    "# add cluster 1 & 3 predictions\n",
    "test_features['cluster_1'] = rf_pred\n",
    "test_features['cluster_3'] = gb_pred\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    C=0.13916392773859043,\n",
    "    max_iter=130,\n",
    "    tol=1.0683985965344678,\n",
    "    class_weight=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lr_feats = ['AHTGS5PG_UPoutlier', 'AHTGS5PHG_UPoutlier', 'AATGS5PAG_UPoutlier', 'AHTSOT5PG_UPoutlier',\n",
    "            'AATSOT5PG_UPoutlier', 'AHTSOT5PHG_UPoutlier', 'AHTGD5PHG_UPoutlier', 'HT_PrevSeasonPos_inv',\n",
    "            'AT_PrevSeasonPos_inv', 'HA_AHTGS5PG_diff_lowqrt', 'AHTGS5PG_upqrt_AATGC5PG_lowqrt',\n",
    "            'AHTSOT5PG_bxcx_pwrTRANSFORM', 'AATSOT5PG_bxcx_pwrTRANSFORM', 'AHTGD5PG_quantileTRANSFORM',\n",
    "            'AATGD5PG_quantileTRANSFORM', 'AwayCapacityDiff_bin_quantileTRANSFORM',\n",
    "            'bxcx_AHTSOT5PG_quantileTRANSFORM', 'bxcx_AATSOT5PG_quantileTRANSFORM',\n",
    "            'bxcx_AAT_GS_P5PG_ratio_quantileTRANSFORM']\n",
    "\n",
    "lr_pipe, _, _, lr_name = home_lr_setup()\n",
    "\n",
    "lr_iso_cal = IMBPipeline(\n",
    "    steps=[\n",
    "        ('transformer', KeepColumnsTransformer(lr_feats)),\n",
    "        ('scaler', RobustScaler(with_centering=False)),\n",
    "        ('sampling', NearMiss(version=3, n_neighbors=3, n_neighbors_ver3=3, n_jobs=-1)),\n",
    "        ('pca', PCA(n_components=12, whiten=True)),\n",
    "        ('model', CalibratedClassifierCV(lr_model, cv=cv, method='isotonic'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "lr_sig_cal = IMBPipeline(\n",
    "    steps=[\n",
    "        ('transformer', KeepColumnsTransformer(lr_feats)),\n",
    "        ('scaler', RobustScaler(with_centering=False)),\n",
    "        ('sampling', NearMiss(version=3, n_neighbors=3, n_neighbors_ver3=3, n_jobs=-1)),\n",
    "        ('pca', PCA(n_components=12, whiten=True)),\n",
    "        ('model', CalibratedClassifierCV(lr_model, cv=cv, method='sigmoid'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pipes = [(lr_pipe, lr_name), (lr_iso_cal, lr_name + ' isotonic'),\n",
    "         (lr_sig_cal, lr_name + ' sigmoid')]\n",
    "\n",
    "# plot calibration curve and histogram of predicted postive probabilities\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax1.plot([0, 1], [0, 1], linestyle='--',\n",
    "         label='Perfect Calibration', color='gray')\n",
    "for clf, name in pipes:\n",
    "    print(f'Processing: {name}')\n",
    "    clf.fit(train_features, np.array(home_train_target).reshape(-1,))\n",
    "    y_pred = clf.predict(test_features)\n",
    "    fb_score = fbeta(np.array(home_test_target).reshape(-1,), y_pred)\n",
    "    probs = clf.predict_proba(test_features)[:, 1]\n",
    "    fov, mpv = calibration_curve(\n",
    "        np.array(home_test_target).reshape(-1,), probs, n_bins=10)\n",
    "    ax1.plot(mpv, fov, marker='.', label=f'{name} fb:{fb_score}')\n",
    "    ax2.hist(probs, range=(0, 1), bins=10, label=name, histtype='step', lw=2)\n",
    "ax1.set_title('Calibration (Reliability) Curve of Logistic Regression Model')\n",
    "ax1.set_ylabel('Fraction of Positives')\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.set_xlabel('Mean Predicted Value')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.legend(loc='upper right', ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb classifier calibration\n",
    "train_features = load_train_features()\n",
    "test_features = load_test_features()\n",
    "home_train_target, home_test_target = load_home_targets()\n",
    "# get predictions for cluster 1 & 3 features\n",
    "test_cluster_feats = load_cluster_test_feats()\n",
    "rf_cl1_model = joblib.load('cl1_rf_model.sav')\n",
    "rf_pred = rf_cl1_model.predict(test_cluster_feats)\n",
    "gb_cl3_model = joblib.load('cl3_gb_model.sav')\n",
    "gb_pred = gb_cl3_model.predict(test_cluster_feats)\n",
    "# add cluster 1 & 3 predictions\n",
    "test_features['cluster_1'] = rf_pred\n",
    "test_features['cluster_3'] = gb_pred\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=320,\n",
    "                          learning_rate=0.0488938809129075,\n",
    "                          max_depth=3,\n",
    "                          min_child_weight=8,\n",
    "                          gamma=0.6936419289666603,\n",
    "                          scale_pos_weight=1,\n",
    "                          colsample_bytree=0.5920903811620744,\n",
    "                          subsample=0.8374088758397853,\n",
    "                          reg_alpha=0.07425990654719038,\n",
    "                          reg_lambda=0.16768800738594583,\n",
    "                          use_label_encoder=False,\n",
    "                          n_jobs=-1,\n",
    "                          verbosity=0,\n",
    "                          random_state=42)\n",
    "\n",
    "xgb_feats = ['AHTSOT5PG', 'AATSOT5PG', 'AATGD5PAG', 'season_month_sin', 'season_month_cos',\n",
    "             'HA_ATP5PG_diff', 'AwayCapacityDiff_bin', 'cluster_3', 'HT_PrevSeasonPos_inv',\n",
    "             'AT_PrevSeasonPos_inv', 'HT_GSGC_UPLOW_QRT', 'AHTGC5PG_upqrt_AATGC5PG_lowqrt']\n",
    "\n",
    "xgb_pipe, _, _, xgb_name = home_xgb_setup()\n",
    "\n",
    "xgb_iso_cal = IMBPipeline(\n",
    "    steps=[\n",
    "        ('transformer', KeepColumnsTransformer(xgb_feats)),\n",
    "        ('scaler', StandardScaler(with_mean=False, with_std=True)),\n",
    "        ('sampling', BorderlineSMOTE(k_neighbors=12, m_neighbors=20,\n",
    "                                     kind='borderline-1', random_state=1, n_jobs=-1)),\n",
    "        ('model', CalibratedClassifierCV(xgb_model, cv=cv, method='isotonic'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "xgb_sig_cal = IMBPipeline(\n",
    "    steps=[\n",
    "        ('transformer', KeepColumnsTransformer(xgb_feats)),\n",
    "        ('scaler', StandardScaler(with_mean=False, with_std=True)),\n",
    "        ('sampling', BorderlineSMOTE(k_neighbors=12, m_neighbors=20,\n",
    "                                     kind='borderline-1', random_state=1, n_jobs=-1)),\n",
    "        ('model', CalibratedClassifierCV(xgb_model, cv=cv, method='sigmoid'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pipes = [(xgb_pipe, xgb_name), (xgb_iso_cal, xgb_name + ' isotonic'),\n",
    "         (xgb_sig_cal, xgb_name + ' sigmoid')]\n",
    "\n",
    "# plot calibration curve and histogram of predicted postive probabilities\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax1.plot([0, 1], [0, 1], linestyle='--',\n",
    "         label='Perfect Calibration', color='gray')\n",
    "for clf, name in pipes:\n",
    "    print(f'Processing: {name}')\n",
    "    clf.fit(train_features, np.array(home_train_target).reshape(-1,))\n",
    "    y_pred = clf.predict(test_features)\n",
    "    fb_score = fbeta(np.array(home_test_target).reshape(-1,), y_pred)\n",
    "    probs = clf.predict_proba(test_features)[:, 1]\n",
    "    fov, mpv = calibration_curve(\n",
    "        np.array(home_test_target).reshape(-1,), probs, n_bins=10)\n",
    "    ax1.plot(mpv, fov, marker='.', label=f'{name} fb:{fb_score}')\n",
    "    ax2.hist(probs, range=(0, 1), bins=10, label=name, histtype='step', lw=2)\n",
    "ax1.set_title('Calibration (Reliability) Curve of XGB Classifier Model')\n",
    "ax1.set_ylabel('Fraction of Positives')\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.set_xlabel('Mean Predicted Value')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.legend(loc='upper right', ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home model, voting classifier with calibrated models\n",
    "train_features = load_train_features()\n",
    "xgb_pipe, _, xgb_name = home_xgb_setup()\n",
    "lr_pipe, _, lr_name = home_lr_setup()\n",
    "home_train_target, _ = load_home_targets()\n",
    "\n",
    "vc = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_pipe), ('lr', lr_pipe)],\n",
    "    voting='soft',\n",
    "    n_jobs=1\n",
    ")\n",
    "scores = evaluate_model(train_features, np.array(\n",
    "    home_train_target).reshape(-1,), vc, k_splits=10)\n",
    "print(f'Home {xgb_name}/{lr_name} models Voting Classifier, Avg Fbeta: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Away Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm calibration\n",
    "train_features = load_train_features()\n",
    "test_features = load_test_features()\n",
    "away_train_target, away_test_target = load_away_targets()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "lgbm_model = LGBMClassifier(n_estimators=470,\n",
    "                            learning_rate=0.04250057994580665,\n",
    "                            objective='binary',\n",
    "                            max_depth=4,\n",
    "                            num_leaves=35,\n",
    "                            min_child_samples=1320,\n",
    "                            colsample_bytree=0.7787949835735254,\n",
    "                            subsample=0.8073575692094029,\n",
    "                            reg_alpha=0.06951672237498768,\n",
    "                            reg_lambda=0.03784851967467663,\n",
    "                            is_unbalance=True,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=42)\n",
    "\n",
    "lgbm_feats = ['AHTGS5PG', 'AHTGC5PG', 'AHTSOT5PHG', 'AATSOT5PAG', 'AHTP5PHG', 'AHTGD5PG',\n",
    "              'HA_AHTGS5PG_diff', 'HA_ATP5PG_diff', 'AHT_GS_P5PG_ratio', 'AwayCapacityDiff_bin',\n",
    "              'HT_PrevSeasonPos_inv', 'AT_PrevSeasonPos_inv']\n",
    "\n",
    "lgbm_pipe, _, _, lgbm_name = away_lgbm_setup()\n",
    "\n",
    "lgbm_iso_cal = IMBPipeline(\n",
    "    steps=[\n",
    "        ('transformer', KeepColumnsTransformer(lgbm_feats)),\n",
    "        ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
    "        ('sampling', SVMSMOTE(k_neighbors=3, m_neighbors=7, random_state=1, n_jobs=-1)),\n",
    "        ('model', CalibratedClassifierCV(lgbm_model, cv=cv, method='isotonic'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "lgbm_sig_cal = IMBPipeline(\n",
    "    steps=[\n",
    "        ('transformer', KeepColumnsTransformer(lgbm_feats)),\n",
    "        ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
    "        ('sampling', SVMSMOTE(k_neighbors=3, m_neighbors=7, random_state=1, n_jobs=-1)),\n",
    "        ('model', CalibratedClassifierCV(lgbm_model, cv=cv, method='sigmoid'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipes = [(lgbm_pipe, lgbm_name), (lgbm_iso_cal, lgbm_name +\n",
    "                                  ' isotonic'), (lgbm_sig_cal, lgbm_name + ' sigmoid')]\n",
    "# plot calibration curve and histogram of predicted postive probabilities\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax1.plot([0, 1], [0, 1], linestyle='--',\n",
    "         label='Perfect Calibration', color='gray')\n",
    "for clf, name in pipes:\n",
    "    print(f'Processing {name}')\n",
    "    clf.fit(train_features, np.array(away_train_target).reshape(-1,))\n",
    "    y_pred = clf.predict(test_features)\n",
    "    fb_score = fbeta(away_test_target, y_pred)\n",
    "    probs = clf.predict_proba(test_features)[:, 1]\n",
    "    fov, mpv = calibration_curve(\n",
    "        np.array(away_test_target).reshape(-1,), probs, n_bins=10)\n",
    "    ax1.plot(mpv, fov, marker='.', label=f'{name} fb:{fb_score}')\n",
    "    ax2.hist(probs, range=(0, 1), bins=10, label=name, histtype='step', lw=2)\n",
    "ax1.set_title('Calibration (Reliability) Curve of Away LGBM Model')\n",
    "ax1.set_ylabel('Fraction of Positives')\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.set_xlabel('Mean Predicted Value')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.legend(loc='upper right', ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = load_train_features()\n",
    "test_features = load_test_features()\n",
    "away_train_target, away_test_target = load_away_targets()\n",
    "\n",
    "# get predictions for cluster 1 & 3 features\n",
    "test_cluster_feats = load_cluster_test_feats()\n",
    "rf_cl1_model = joblib.load('cl1_rf_model.sav')\n",
    "rf_pred = rf_cl1_model.predict(test_cluster_feats)\n",
    "# add cluster 1 predictions\n",
    "test_features['cluster_1'] = rf_pred\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=570,\n",
    "                          learning_rate=0.018277402480679054,\n",
    "                          max_depth=3,\n",
    "                          min_child_weight=10,\n",
    "                          gamma=0.6757959901913699,\n",
    "                          subsample=0.7962485851393263,\n",
    "                          colsample_bytree=0.5735095367483903,\n",
    "                          scale_pos_weight=1,\n",
    "                          reg_alpha=0.13029677939259385,\n",
    "                          reg_lambda=0.10315636718690373,\n",
    "                          use_label_encoder=False,\n",
    "                          n_jobs=-1,\n",
    "                          verbosity=0,\n",
    "                          random_state=42)\n",
    "\n",
    "xgb_feats = ['AHTGC5PG', 'AATP5PAG', 'DayofWeek', 'HA_ATP5PG_diff', 'cluster_1', 'HT_PrevSeasonPos_inv',\n",
    "             'AT_PrevSeasonPos_inv', 'HA_AHTGS5PG_diff_upqrt', 'AHTGC5PG_upqrt_AATGC5PG_lowqrt']\n",
    "\n",
    "xgb_pipe, _, _, xgb_name = away_xgb_setup()\n",
    "\n",
    "xgb_iso_cal = IMBPipeline(\n",
    "    steps=[\n",
    "        ('transformer', KeepColumnsTransformer(xgb_feats)),\n",
    "        ('scaler', StandardScaler(with_mean=False, with_std=True)),\n",
    "        ('sampling', SVMSMOTE(k_neighbors=8, m_neighbors=14,\n",
    "                              svm_estimator=SVC(), random_state=1, n_jobs=-1)),\n",
    "        ('model', CalibratedClassifierCV(xgb_model, cv=cv, method='isotonic'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "xgb_sig_cal = IMBPipeline(\n",
    "    steps=[\n",
    "        ('transformer', KeepColumnsTransformer(xgb_feats)),\n",
    "        ('scaler', StandardScaler(with_mean=False, with_std=True)),\n",
    "        ('sampling', SVMSMOTE(k_neighbors=8, m_neighbors=14,\n",
    "                              svm_estimator=SVC(), random_state=1, n_jobs=-1)),\n",
    "        ('model', CalibratedClassifierCV(xgb_model, cv=cv, method='sigmoid'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipes = [(xgb_pipe, xgb_name), (xgb_iso_cal, xgb_name + ' isotonic'),\n",
    "         (xgb_sig_cal, xgb_name + ' sigmoid')]\n",
    "# plot calibration curve and histogram of predicted postive probabilities\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax1.plot([0, 1], [0, 1], linestyle='--',\n",
    "         label='Perfect Calibration', color='gray')\n",
    "for clf, name in pipes:\n",
    "    print(f'Processing {name}')\n",
    "    clf.fit(train_features, np.array(away_train_target).reshape(-1,))\n",
    "    y_pred = clf.predict(test_features)\n",
    "    fb_score = fbeta(away_test_target, y_pred)\n",
    "    probs = clf.predict_proba(test_features)[:, 1]\n",
    "    fov, mpv = calibration_curve(\n",
    "        np.array(away_test_target).reshape(-1,), probs, n_bins=10)\n",
    "    ax1.plot(mpv, fov, marker='.', label=f'{name} fb:{fb_score}')\n",
    "    ax2.hist(probs, range=(0, 1), bins=10, label=name, histtype='step', lw=2)\n",
    "ax1.set_title('Calibration (Reliability) Curve of Away XGB Model')\n",
    "ax1.set_ylabel('Fraction of Positives')\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.set_xlabel('Mean Predicted Value')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.legend(loc='upper right', ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = load_train_features()\n",
    "test_features = load_test_features()\n",
    "away_train_target, away_test_target = load_away_targets()\n",
    "\n",
    "# get predictions for cluster 1 & 3 features\n",
    "test_cluster_feats = load_cluster_test_feats()\n",
    "rf_cl1_model = joblib.load('cl1_rf_model.sav')\n",
    "rf_pred = rf_cl1_model.predict(test_cluster_feats)\n",
    "gb_cl3_model = joblib.load('cl3_gb_model.sav')\n",
    "gb_pred = gb_cl3_model.predict(test_cluster_feats)\n",
    "# add cluster 1 & 3 predictions\n",
    "test_features['cluster_1'] = rf_pred\n",
    "test_features['cluster_3'] = gb_pred\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=650,\n",
    "                                      learning_rate=0.027115584500934167,\n",
    "                                      max_depth=3,\n",
    "                                      max_features=8,\n",
    "                                      min_samples_leaf=420,\n",
    "                                      min_samples_split=675,\n",
    "                                      subsample=0.43918481213848615,\n",
    "                                      #ccp_alpha =  1.1243946224171244,\n",
    "                                      random_state=42)\n",
    "\n",
    "gb_feats = ['AHTGC5PHG', 'AATSOT5PG', 'AHTSOT5PHG', 'HA_AHTGS5PG_diff', 'AHT_GS_P5PG_ratio',\n",
    "            'AwayCapacityDiff_bin', 'cluster_1', 'cluster_3', 'HT_PrevSeasonPos_inv',\n",
    "            'AT_PrevSeasonPos_inv', 'bxcx_AHTGC5PG', 'bxcx_AATSOT5PG', 'bxcx_AHT_GS_P5PG_ratio']\n",
    "\n",
    "gb_pipe, _, gb_name = away_gb_setup()\n",
    "\n",
    "gb_iso_cal = IMBPipeline(\n",
    "    steps=[\n",
    "        ('transformer', KeepColumnsTransformer(gb_feats)),\n",
    "        ('scaler', StandardScaler(with_mean=False, with_std=True)),\n",
    "        ('sampling', ADASYN(n_neighbors=6, random_state=1, n_jobs=-1)),\n",
    "        ('model', CalibratedClassifierCV(gb_model, cv=cv, method='isotonic'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "gb_sig_cal = IMBPipeline(\n",
    "    steps=[\n",
    "        ('transformer', KeepColumnsTransformer(gb_feats)),\n",
    "        ('scaler', StandardScaler(with_mean=False, with_std=True)),\n",
    "        ('sampling', ADASYN(n_neighbors=6, random_state=1, n_jobs=-1)),\n",
    "        ('model', CalibratedClassifierCV(gb_model, cv=cv, method='sigmoid'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipes = [(gb_pipe, gb_name), (gb_iso_cal, gb_name + ' isotonic'),\n",
    "         (gb_sig_cal, gb_name + ' sigmoid')]\n",
    "# plot calibration curve and histogram of predicted postive probabilities\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax1.plot([0, 1], [0, 1], linestyle='--',\n",
    "         label='Perfect Calibration', color='gray')\n",
    "for clf, name in pipes:\n",
    "    print(f'Processing {name}')\n",
    "    clf.fit(train_features, np.array(away_train_target).reshape(-1,))\n",
    "    y_pred = clf.predict(test_features)\n",
    "    fb_score = fbeta(away_test_target, y_pred)\n",
    "    probs = clf.predict_proba(test_features)[:, 1]\n",
    "    fov, mpv = calibration_curve(\n",
    "        np.array(away_test_target).reshape(-1,), probs, n_bins=10)\n",
    "    ax1.plot(mpv, fov, marker='.', label=f'{name} fb:{fb_score}')\n",
    "    ax2.hist(probs, range=(0, 1), bins=10, label=name, histtype='step', lw=2)\n",
    "ax1.set_title('Calibration (Reliability) Curve of Away GB Model')\n",
    "ax1.set_ylabel('Fraction of Positives')\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.set_xlabel('Mean Predicted Value')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.legend(loc='upper right', ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away model, voting classifier with calibrated models\n",
    "train_features = load_train_features()\n",
    "xgb_pipe, _, xgb_name = away_xgb_setup()\n",
    "lgbm_pipe, lgbm_name = away_lgbm_setup()\n",
    "away_train_target, _ = load_away_targets()\n",
    "\n",
    "vc = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_pipe), ('lgbm', lgbm_pipe)],\n",
    "    voting='soft',\n",
    "    n_jobs=1\n",
    ")\n",
    "scores = evaluate_model(train_features, np.array(\n",
    "    away_train_target).reshape(-1,), vc, k_splits=10)\n",
    "print(f'Away {xgb_name}/{lgbm_name} models Voting Classifier, Avg Fbeta: {np.mean(scores)},    Std: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Summary -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using the probabilities predicted by the models we want to calibrate each model to be as close to perfect as possible to improve over confident or under confident probability predicting.\n",
    "\n",
    "Home model calibration results:\n",
    "    \n",
    "    Logistic Regression, no calibration.. Fbeta: 0.5956956435585508\n",
    "    \n",
    "    XGB classifier, method = sigmoid.. Fbeta: 0.5851352642401303\n",
    "    \n",
    "Away Model calibration results:\n",
    "\n",
    "    LGBM model, no calibration... fbeta: 0.6753807784651213 \n",
    "    \n",
    "    XGB model, no calibration... fbeta: 0.6770685167578759\n",
    "    \n",
    "    GB model, overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Final Models (Generalisation/Visualisation) --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features/targets\n",
    "train_features = load_train_features()\n",
    "test_features = load_test_features()\n",
    "home_train_target, home_test_target = load_home_targets()\n",
    "\n",
    "# get predictions for cluster 1 & 3 features\n",
    "test_cluster_feats = load_cluster_test_feats()\n",
    "rf_cl1_model = joblib.load('cl1_rf_model.sav')\n",
    "rf_pred = rf_cl1_model.predict(test_cluster_feats)\n",
    "gb_cl3_model = joblib.load('cl3_gb_model.sav')\n",
    "gb_pred = gb_cl3_model.predict(test_cluster_feats)\n",
    "# add cluster 1 & 3 predictions to test features\n",
    "test_features['cluster_1'] = rf_pred\n",
    "test_features['cluster_3'] = gb_pred\n",
    "\n",
    "# load pipelines\n",
    "lr_pipe, cal_lr_pipe, lr_test_feats, lr_name = home_lr_setup()\n",
    "xgb_pipe, cal_xgb_pipe, xgb_test_feats, xgb_name = home_xgb_setup()\n",
    "\n",
    "# instantiate a simple model\n",
    "lr_sm = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "lrsm_test_feats = test_features['AwayCapacityDiff']\n",
    "lr_sm_pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('trans', KeepColumnsTransformer(['AwayCapacityDiff'])),\n",
    "        ('model', lr_sm)\n",
    "    ]\n",
    ")\n",
    "lr_sm_name = 'LR SM'\n",
    "\n",
    "# instantiate voting classifier\n",
    "vc_pipe = VotingClassifier(\n",
    "    estimators=[('lr', lr_pipe), ('xgb', cal_xgb_pipe)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "vc_name = 'VC'\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "pipes = [lr_pipe, cal_xgb_pipe, lr_sm_pipe, vc_pipe]\n",
    "p_names = [lr_name, xgb_name, lr_sm_name, vc_name]\n",
    "fit_pipes = [pipe.fit(train_features, np.array(\n",
    "    home_train_target).reshape(-1,)) for pipe in pipes]\n",
    "# pipelines for ensemble\n",
    "ensemble_pipes = [lr_pipe, cal_xgb_pipe]\n",
    "ensemble_fit_pipes = [pipe.fit(train_features, np.array(\n",
    "    home_train_target).reshape(-1,)) for pipe in ensemble_pipes]\n",
    "# save models\n",
    "for i in range(len(fit_pipes)):\n",
    "    joblib.dump(fit_pipes[i], f'{p_names[i]}_home_win_model_pipeline.sav')\n",
    "pipe_test_features = [lr_test_feats, xgb_test_feats, lrsm_test_feats]\n",
    "# instantiate lists for plotting\n",
    "lc_mean_train_scores = []\n",
    "lc_std_train_scores = []\n",
    "lc_mean_test_scores = []\n",
    "lc_std_test_scores = []\n",
    "train_sizes = []\n",
    "rc_rates = []\n",
    "rc_threshs = []\n",
    "auc_scores = []\n",
    "\n",
    "for i in range(len(pipes)):\n",
    "    pipe_pred = fit_pipes[i].predict(test_features)  # pipe_test_features[i]\n",
    "    # pipe_test_features[i] # probabilities for class 1\n",
    "    pipe_prob_pred = fit_pipes[i].predict_proba(test_features)[:, 1]\n",
    "    fb_score = fbeta(home_test_target, pipe_pred)\n",
    "    print(f'{p_names[i]} pipe Fbeta score: {fb_score}')\n",
    "    print(\n",
    "        f'{p_names[i]} pipe Cohen Kappa Score: {cohen_kappa_score(home_test_target, pipe_pred)}')\n",
    "    print(\n",
    "        f'{p_names[i]} pipe classification report:\\n{classification_report(home_test_target, pipe_pred)}')\n",
    "    print(\n",
    "        f'{p_names[i]} pipe confusion matrix:\\n{confusion_matrix(home_test_target, pipe_pred)}\\n')\n",
    "    # learning curve\n",
    "    train_size, train_scores, test_scores = learning_curve(pipes[i], train_features, np.array(\n",
    "        home_train_target).reshape(-1,), cv=cv, n_jobs=-1, random_state=1)\n",
    "    mean_train_scores = np.mean(train_scores, axis=1)\n",
    "    std_train_scores = np.std(train_scores, axis=1)\n",
    "    mean_test_scores = np.mean(test_scores, axis=1)\n",
    "    std_test_scores = np.std(test_scores, axis=1)\n",
    "    lc_mean_train_scores.append(mean_train_scores)\n",
    "    lc_std_train_scores.append(std_train_scores)\n",
    "    lc_mean_test_scores.append(mean_test_scores)\n",
    "    lc_std_test_scores.append(std_test_scores)\n",
    "    train_sizes.append(train_size)\n",
    "    # roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(home_test_target, pipe_prob_pred)\n",
    "    rc_rates.append((fpr, tpr))\n",
    "    rc_threshs.append(thresholds)\n",
    "    auc_scores.append(auc(fpr, tpr))\n",
    "    # save test features win probabilities for home teams as df\n",
    "    home_team_win_probs = pd.DataFrame(\n",
    "        {'HomeTeam': test_features.HomeTeam.values, f'{p_names[i]}_home_win_probs': pipe_prob_pred})\n",
    "    home_team_win_probs.to_csv(\n",
    "        f'{p_names[i]}_model_home_team_win_probs.csv', encoding='utf-8', index=False)\n",
    "    # feature importances\n",
    "    if p_names[i] == 'XGB':\n",
    "        xgb_pipe.fit(train_features, np.array(home_train_target).reshape(-1,))\n",
    "        importances = xgb_pipe.steps[3][1].feature_importances_\n",
    "        feats = pipe_test_features[i].columns\n",
    "        plt.figure(figsize=(20, 16))\n",
    "        plt.bar(feats, importances)\n",
    "        plt.title(f'{p_names[i]} Feature Importances')\n",
    "        plt.xlabel(f'{p_names[i]} Features')\n",
    "        plt.ylabel('Importance')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "# evaluate an equal weight ensemble\n",
    "equal_weights = [1.0/len(ensemble_pipes) for _ in range(len(ensemble_pipes))]\n",
    "np.savetxt('weights_for_equal_weighted_ensemble.csv',\n",
    "           np.array(equal_weights), delimiter=',')  # save weights\n",
    "ew_pred, ew_probs, ew_score = evaluate_ensemble(\n",
    "    ensemble_fit_pipes, equal_weights, test_features, home_test_target)\n",
    "# roc curve\n",
    "fpr, tpr, thresholds = roc_curve(home_test_target, ew_probs)\n",
    "rc_rates.append((fpr, tpr))\n",
    "rc_threshs.append(thresholds)\n",
    "auc_scores.append(auc(fpr, tpr))\n",
    "p_names.append('EW Ens')\n",
    "print(f'Equal weighted ensemble Fbeta score: {ew_score}')\n",
    "print(\n",
    "    f'Equal weighted ensemble Cohen Kappa Score: {cohen_kappa_score(home_test_target, ew_pred)}')\n",
    "print(\n",
    "    f'Equal weighted ensemble classification report:\\n{classification_report(home_test_target, ew_pred)}')\n",
    "print(\n",
    "    f'Equal weighted ensemble confusion matrix:\\n{confusion_matrix(home_test_target, ew_pred)}\\n')\n",
    "# save test features win probabilities for home teams as df\n",
    "home_team_win_probs = pd.DataFrame(\n",
    "    {'HomeTeam': test_features.HomeTeam.values, 'EW_Ensemble_home_win_probs': ew_probs})\n",
    "home_team_win_probs.to_csv(\n",
    "    f'EW_Ensemble_home_team_win_probs.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# weighted average ensemble\n",
    "# bounds for weights\n",
    "weight_bounds = [(0.0, 0.1) for _ in range(len(ensemble_pipes))]\n",
    "# arguments for the loss function\n",
    "search_arg = (ensemble_fit_pipes, test_features, home_test_target)\n",
    "# global optimization of ensemble weights\n",
    "result = differential_evolution(\n",
    "    loss_function, weight_bounds, search_arg, maxiter=1000, tol=1e-7)\n",
    "weights = normalise(result['x'])\n",
    "np.savetxt('weights_for_optimised_weighted_ensemble.csv',\n",
    "           np.array(weights), delimiter=',')  # save weights\n",
    "print(f'Optimised Ensemble Weights:\\n{weights}')\n",
    "# evaluate ensemble with optimised weights\n",
    "ow_pred, ow_probs, ow_score = evaluate_ensemble(\n",
    "    ensemble_fit_pipes, weights, test_features, home_test_target)\n",
    "fpr, tpr, thresholds = roc_curve(home_test_target, ow_probs)\n",
    "rc_rates.append((fpr, tpr))\n",
    "rc_threshs.append(thresholds)\n",
    "auc_scores.append(auc(fpr, tpr))\n",
    "p_names.append('OW Ens')\n",
    "print(f'Optimised Weighted Average Ensemble Fbeta Score: {ow_score}')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble Cohen Kappa Score: {cohen_kappa_score(home_test_target, ow_pred)}')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble classification report:\\n{classification_report(home_test_target, ow_pred)}')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble confusion matrix:\\n{confusion_matrix(home_test_target, ow_pred)}\\n')\n",
    "# save test features win probabilities for home teams as df\n",
    "home_team_win_probs = pd.DataFrame(\n",
    "    {'HomeTeam': test_features.HomeTeam.values, 'OW_Ensemble_home_win_probs': ow_probs})\n",
    "home_team_win_probs.to_csv(\n",
    "    f'OW_Ensemble_home_team_win_probs.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# plots for learning curves\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Home Win Model Learning Curves')\n",
    "fig.tight_layout()\n",
    "for i in range(len(pipes)):\n",
    "    if i == 0:\n",
    "        ax = ax1\n",
    "    elif i == 1:\n",
    "        ax = ax2\n",
    "    elif i == 2:\n",
    "        ax = ax3\n",
    "    else:\n",
    "        ax = ax4\n",
    "    ax.plot(train_sizes[i], lc_mean_train_scores[i],\n",
    "            'o-', color='blue', label='train score')\n",
    "    ax.fill_between(train_sizes[i],\n",
    "                    lc_mean_train_scores[i] - lc_std_train_scores[i],\n",
    "                    lc_mean_train_scores[i] + lc_std_train_scores[i],\n",
    "                    alpha=0.1,\n",
    "                    color='b')\n",
    "    ax.plot(train_sizes[i], lc_mean_test_scores[i],\n",
    "            'o-', color='r', label='cv score')\n",
    "    ax.fill_between(train_sizes[i],\n",
    "                    lc_mean_test_scores[i] - lc_std_test_scores[i],\n",
    "                    lc_mean_test_scores[i] + lc_std_test_scores[i],\n",
    "                    alpha=0.1,\n",
    "                    color='r')\n",
    "    ax.set_title(f'{p_names[i]} Learning Curve')\n",
    "    ax.set_xlabel('Training Samples')\n",
    "    ax.set_ylabel('Fbeta Score')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# plots for roc curves\n",
    "plt.figure(figsize=(20, 16))\n",
    "plt.plot(rc_rates[0][0], rc_rates[0][1],\n",
    "         label=f'{p_names[0]} (AUC: {auc_scores[0]})')\n",
    "plt.plot(rc_rates[1][0], rc_rates[1][1],\n",
    "         label=f'{p_names[1]} (AUC: {auc_scores[1]})')\n",
    "plt.plot(rc_rates[2][0], rc_rates[2][1],\n",
    "         label=f'{p_names[2]} (AUC: {auc_scores[2]})')\n",
    "plt.plot(rc_rates[3][0], rc_rates[3][1],\n",
    "         label=f'{p_names[3]} (AUC: {auc_scores[3]})')\n",
    "plt.plot(rc_rates[4][0], rc_rates[4][1],\n",
    "         label=f'{p_names[4]} (AUC: {auc_scores[4]})')\n",
    "plt.plot(rc_rates[5][0], rc_rates[5][1],\n",
    "         label=f'{p_names[5]} (AUC: {auc_scores[5]})')\n",
    "plt.plot([0, 1], [0, 1], color='blue', linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.title('Home Win Model ROC Curves')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# plots for cumulative response curve\n",
    "plt.figure(figsize=(20, 16))\n",
    "plt.plot([((idx + 1)/len(rc_threshs[0])) for idx,\n",
    "          x in enumerate(rc_threshs[0])], rc_rates[0][1], label=f'{p_names[0]}')\n",
    "plt.plot([((idx + 1)/len(rc_threshs[1])) for idx,\n",
    "          x in enumerate(rc_threshs[1])], rc_rates[1][1], label=f'{p_names[1]}')\n",
    "plt.plot([((idx + 1)/len(rc_threshs[2])) for idx,\n",
    "          x in enumerate(rc_threshs[2])], rc_rates[2][1], label=f'{p_names[2]}')\n",
    "plt.plot([((idx + 1)/len(rc_threshs[3])) for idx,\n",
    "          x in enumerate(rc_threshs[3])], rc_rates[3][1], label=f'{p_names[3]}')\n",
    "plt.plot([((idx + 1)/len(rc_threshs[4])) for idx,\n",
    "          x in enumerate(rc_threshs[4])], rc_rates[4][1], label=f'{p_names[4]}')\n",
    "plt.plot([((idx + 1)/len(rc_threshs[5])) for idx,\n",
    "          x in enumerate(rc_threshs[5])], rc_rates[5][1], label=f'{p_names[5]}')\n",
    "plt.plot([0, 1], [0, 1], color='blue', linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.title('Home Win Model Cumulative Response Curves')\n",
    "plt.xlabel('Percentage of Data')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# possibly lift curves/ profit curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimised weight ensemble including simple logistic regression model\n",
    "# load features/targets\n",
    "train_features = load_train_features()\n",
    "test_features = load_test_features()\n",
    "home_train_target, home_test_target = load_home_targets()\n",
    "\n",
    "# get predictions for cluster 1 & 3 features\n",
    "test_cluster_feats = load_cluster_test_feats()\n",
    "rf_cl1_model = joblib.load('cl1_rf_model.sav')\n",
    "rf_pred = rf_cl1_model.predict(test_cluster_feats)\n",
    "gb_cl3_model = joblib.load('cl3_gb_model.sav')\n",
    "gb_pred = gb_cl3_model.predict(test_cluster_feats)\n",
    "# add cluster 1 & 3 predictions to test features\n",
    "test_features['cluster_1'] = rf_pred\n",
    "test_features['cluster_3'] = gb_pred\n",
    "\n",
    "# load pipelines\n",
    "lr_pipe, cal_lr_pipe, lr_test_feats, lr_name = home_lr_setup()\n",
    "xgb_pipe, cal_xgb_pipe, xgb_test_feats, xgb_name = home_xgb_setup()\n",
    "\n",
    "# instantiate a simple model\n",
    "lr_sm = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "lrsm_test_feats = test_features['AwayCapacityDiff']\n",
    "lr_sm_pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('trans', KeepColumnsTransformer(['AwayCapacityDiff'])),\n",
    "        ('model', lr_sm)\n",
    "    ]\n",
    ")\n",
    "\n",
    "ensemble_pipes = [lr_pipe, cal_xgb_pipe, lr_sm_pipe]\n",
    "ensemble_fit_pipes = [pipe.fit(train_features, np.array(\n",
    "    home_train_target).reshape(-1,)) for pipe in ensemble_pipes]\n",
    "\n",
    "# bounds for weights\n",
    "weight_bounds = [(0.0, 0.1) for _ in range(len(ensemble_pipes))]\n",
    "# arguments for the loss function\n",
    "search_arg = (ensemble_fit_pipes, test_features, home_test_target)\n",
    "# global optimization of ensemble weights\n",
    "result = differential_evolution(\n",
    "    loss_function, weight_bounds, search_arg, maxiter=1000, tol=1e-7)\n",
    "weights = normalise(result['x'])\n",
    "np.savetxt('home_ensemble_optimised_weights_inc_simpmod.csv',\n",
    "           np.array(weights), delimiter=',')  # save weights\n",
    "print(f'Optimised Ensemble inc. Simple Model Weights:\\n{weights}')\n",
    "# evaluate ensemble with optimised weights\n",
    "ow_pred, ow_probs, ow_score = evaluate_ensemble(\n",
    "    ensemble_fit_pipes, weights, test_features, home_test_target)\n",
    "fpr, tpr, thresholds = roc_curve(home_test_target, ow_probs)\n",
    "rc_rates.append((fpr, tpr))\n",
    "rc_threshs.append(thresholds)\n",
    "auc_scores.append(auc(fpr, tpr))\n",
    "p_names.append('OW Ens')\n",
    "print(f'Optimised Weighted Average Ensemble Fbeta Score: {ow_score}')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble Cohen Kappa Score: {cohen_kappa_score(home_test_target, ow_pred)}')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble classification report:\\n{classification_report(home_test_target, ow_pred)}')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble confusion matrix:\\n{confusion_matrix(home_test_target, ow_pred)}\\n')\n",
    "# save test features win probabilities for home teams as df\n",
    "home_team_win_probs = pd.DataFrame(\n",
    "    {'HomeTeam': test_features.HomeTeam.values, 'OW_Ensemble_home_win_probs': ow_probs})\n",
    "home_team_win_probs.to_csv(\n",
    "    f'OW_Ensemble_inc_simpmod_home_team_win_probs.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Away Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features/targets\n",
    "train_features = load_train_features()\n",
    "test_features = load_test_features()\n",
    "away_train_target, away_test_target = load_away_targets()\n",
    "\n",
    "# get predictions for cluster 1 & 3 features\n",
    "test_cluster_feats = load_cluster_test_feats()\n",
    "rf_cl1_model = joblib.load('cl1_rf_model.sav')\n",
    "rf_pred = rf_cl1_model.predict(test_cluster_feats)\n",
    "gb_cl3_model = joblib.load('cl3_gb_model.sav')\n",
    "gb_pred = gb_cl3_model.predict(test_cluster_feats)\n",
    "# add cluster 1 & 3 predictions to test features\n",
    "test_features['cluster_1'] = rf_pred\n",
    "test_features['cluster_3'] = gb_pred\n",
    "\n",
    "# load pipelines\n",
    "lgbm_pipe, lgbm_cal_pipe, lgbm_test_feats, lgbm_name = away_lgbm_setup()\n",
    "xgb_pipe, xgb_cal_pipe, xgb_test_feats, xgb_name = away_xgb_setup()\n",
    "# instantiate a simple model\n",
    "lr_sm = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "lrsm_test_feats = test_features['AwayCapacityDiff']\n",
    "lr_sm_pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('trans', KeepColumnsTransformer(['AwayCapacityDiff'])),\n",
    "        ('model', lr_sm)\n",
    "    ]\n",
    ")\n",
    "lr_sm_name = 'LR SM'\n",
    "# instantiate voting classifier\n",
    "vc_pipe = VotingClassifier(\n",
    "    estimators=[('lgbm', lgbm_pipe), ('xgb', xgb_pipe)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "vc_name = 'VC'\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "pipes = [lgbm_pipe, xgb_pipe, vc_pipe, lr_sm_pipe]\n",
    "p_names = [lgbm_name, xgb_name, vc_name, lr_sm_name]\n",
    "fit_pipes = [pipe.fit(train_features, np.array(\n",
    "    away_train_target).reshape(-1,)) for pipe in pipes]\n",
    "# pipelines for ensemble\n",
    "ensemble_pipes = [lgbm_pipe, xgb_pipe]\n",
    "ensemble_fit_pipes = [pipe.fit(train_features, np.array(\n",
    "    away_train_target).reshape(-1,)) for pipe in ensemble_pipes]\n",
    "# save models\n",
    "for i in range(len(fit_pipes)):\n",
    "    joblib.dump(fit_pipes[i], f'{p_names[i]}_away_win_model_pipeline.sav')\n",
    "pipe_test_features = [lgbm_test_feats, xgb_test_feats, lrsm_test_feats]\n",
    "# instantiate lists for plotting\n",
    "lc_mean_train_scores = []\n",
    "lc_std_train_scores = []\n",
    "lc_mean_test_scores = []\n",
    "lc_std_test_scores = []\n",
    "train_sizes = []\n",
    "rc_rates = []\n",
    "rc_threshs = []\n",
    "auc_scores = []\n",
    "\n",
    "for i in range(len(pipes)):\n",
    "    pipe_pred = fit_pipes[i].predict(test_features)  # pipe_test_features[i]\n",
    "    # pipe_test_features[i] # probabilities for class 1\n",
    "    pipe_prob_pred = fit_pipes[i].predict_proba(test_features)[:, 1]\n",
    "    fb_score = fbeta(away_test_target, pipe_pred)\n",
    "    print(f'{p_names[i]} pipe Fbeta score: {fb_score}')\n",
    "    print(\n",
    "        f'{p_names[i]} pipe Cohen Kappa Score: {cohen_kappa_score(away_test_target, pipe_pred)}')\n",
    "    print(\n",
    "        f'{p_names[i]} pipe classification report:\\n{classification_report(away_test_target, pipe_pred)}')\n",
    "    print(\n",
    "        f'{p_names[i]} pipe confusion matrix:\\n{confusion_matrix(away_test_target, pipe_pred)}\\n')\n",
    "    # learning curve\n",
    "    train_size, train_scores, test_scores = learning_curve(pipes[i], train_features, np.array(\n",
    "        away_train_target).reshape(-1,), cv=cv, n_jobs=-1, random_state=1)\n",
    "    mean_train_scores = np.mean(train_scores, axis=1)\n",
    "    std_train_scores = np.std(train_scores, axis=1)\n",
    "    mean_test_scores = np.mean(test_scores, axis=1)\n",
    "    std_test_scores = np.std(test_scores, axis=1)\n",
    "    lc_mean_train_scores.append(mean_train_scores)\n",
    "    lc_std_train_scores.append(std_train_scores)\n",
    "    lc_mean_test_scores.append(mean_test_scores)\n",
    "    lc_std_test_scores.append(std_test_scores)\n",
    "    train_sizes.append(train_size)\n",
    "    # roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(away_test_target, pipe_prob_pred)\n",
    "    rc_rates.append((fpr, tpr))\n",
    "    rc_threshs.append(thresholds)\n",
    "    auc_scores.append(auc(fpr, tpr))\n",
    "    # save test features win probabilities for away teams as df\n",
    "    away_team_win_probs = pd.DataFrame(\n",
    "        {'AwayTeam': test_features.AwayTeam.values, f'{p_names[i]}_away_win_probs': pipe_prob_pred})\n",
    "    away_team_win_probs.to_csv(\n",
    "        f'{p_names[i]}_model_away_team_win_probs.csv', encoding='utf-8', index=False)\n",
    "    # feature importances\n",
    "    if p_names[i] == 'XGB' or p_names[i] == 'LGBM':\n",
    "        importances = fit_pipes[i].steps[3][1].feature_importances_\n",
    "        feats = pipe_test_features[i].columns\n",
    "        plt.figure(figsize=(20, 16))\n",
    "        plt.bar(feats, importances)\n",
    "        plt.title(f'{p_names[i]} Away Model Feature Importances')\n",
    "        plt.xlabel(f'{p_names[i]} Features')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('Importance')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "# evaluate an equal weight ensemble\n",
    "equal_weights = [1.0/len(ensemble_pipes) for _ in range(len(ensemble_pipes))]\n",
    "np.savetxt('equal_weights_for_away_models_ensemble.csv',\n",
    "           np.array(equal_weights), delimiter=',')  # save weights\n",
    "ew_pred, ew_probs, ew_score = evaluate_ensemble(\n",
    "    ensemble_fit_pipes, equal_weights, test_features, away_test_target)\n",
    "# roc curve\n",
    "fpr, tpr, thresholds = roc_curve(away_test_target, ew_probs)\n",
    "rc_rates.append((fpr, tpr))\n",
    "rc_threshs.append(thresholds)\n",
    "auc_scores.append(auc(fpr, tpr))\n",
    "p_names.append('EW Ens')\n",
    "print(f'Equal weighted ensemble Fbeta score: {ew_score}')\n",
    "print(\n",
    "    f'Equal weighted ensemble Cohen Kappa Score: {cohen_kappa_score(away_test_target, ew_pred)}')\n",
    "print(\n",
    "    f'Equal weighted ensemble classification report:\\n{classification_report(away_test_target, ew_pred)}')\n",
    "print(\n",
    "    f'Equal weighted ensemble confusion matrix:\\n{confusion_matrix(away_test_target, ew_pred)}\\n')\n",
    "# save test features win probabilities for away teams as df\n",
    "away_team_win_probs = pd.DataFrame(\n",
    "    {'AwayTeam': test_features.AwayTeam.values, 'EW_Ensemble_away_win_probs': ew_probs})\n",
    "away_team_win_probs.to_csv(\n",
    "    f'EW_Ensemble_away_team_win_probs.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# weighted average ensemble\n",
    "# bounds for weights\n",
    "weight_bounds = [(0.0, 0.1) for _ in range(len(ensemble_pipes))]\n",
    "# arguments for the loss function\n",
    "search_arg = (ensemble_fit_pipes, test_features, away_test_target)\n",
    "# global optimization of ensemble weights\n",
    "result = differential_evolution(\n",
    "    loss_function, weight_bounds, search_arg, maxiter=1000, tol=1e-7)\n",
    "weights = normalise(result['x'])\n",
    "np.savetxt('optimised_weights_for_away_models_ensemble.csv',\n",
    "           np.array(weights), delimiter=',')  # save weights\n",
    "print(f'Optimised Ensemble Weights:\\n{weights}')\n",
    "# evaluate ensemble with optimised weights\n",
    "ow_pred, ow_probs, ow_score = evaluate_ensemble(\n",
    "    ensemble_fit_pipes, weights, test_features, away_test_target)\n",
    "fpr, tpr, thresholds = roc_curve(away_test_target, ow_probs)\n",
    "rc_rates.append((fpr, tpr))\n",
    "rc_threshs.append(thresholds)\n",
    "auc_scores.append(auc(fpr, tpr))\n",
    "p_names.append('OW Ens')\n",
    "print(f'Optimised Weighted Average Ensemble Fbeta Score: {ow_score}')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble Cohen Kappa Score: {cohen_kappa_score(away_test_target, ow_pred)}')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble classification report:\\n{classification_report(away_test_target, ow_pred)}')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble confusion matrix:\\n{confusion_matrix(away_test_target, ow_pred)}\\n')\n",
    "# save test features win probabilities for away teams as df\n",
    "away_team_win_probs = pd.DataFrame(\n",
    "    {'AwayTeam': test_features.AwayTeam.values, 'OW_Ensemble_away_win_probs': ow_probs})\n",
    "away_team_win_probs.to_csv(\n",
    "    f'OW_Ensemble_away_team_win_probs.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# plots for learning curves\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Away Win Model Learning Curves')\n",
    "fig.tight_layout(pad=3)\n",
    "for i in range(len(pipes)):\n",
    "    if i == 0:\n",
    "        ax = ax1\n",
    "    elif i == 1:\n",
    "        ax = ax2\n",
    "    elif i == 2:\n",
    "        ax = ax3\n",
    "    else:\n",
    "        ax = ax4\n",
    "    ax.plot(train_sizes[i], lc_mean_train_scores[i],\n",
    "            'o-', color='blue', label='train score')\n",
    "    ax.fill_between(train_sizes[i],\n",
    "                    lc_mean_train_scores[i] - lc_std_train_scores[i],\n",
    "                    lc_mean_train_scores[i] + lc_std_train_scores[i],\n",
    "                    alpha=0.1,\n",
    "                    color='b')\n",
    "    ax.plot(train_sizes[i], lc_mean_test_scores[i],\n",
    "            'o-', color='r', label='cv score')\n",
    "    ax.fill_between(train_sizes[i],\n",
    "                    lc_mean_test_scores[i] - lc_std_test_scores[i],\n",
    "                    lc_mean_test_scores[i] + lc_std_test_scores[i],\n",
    "                    alpha=0.1,\n",
    "                    color='r')\n",
    "    ax.set_title(f'{p_names[i]} Learning Curve')\n",
    "    ax.set_xlabel('Training Samples')\n",
    "    ax.set_ylabel('Fbeta Score')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# plots for roc curves\n",
    "plt.figure(figsize=(20, 16))\n",
    "plt.plot(rc_rates[0][0], rc_rates[0][1],\n",
    "         label=f'{p_names[0]} (AUC: {auc_scores[0]})')\n",
    "plt.plot(rc_rates[1][0], rc_rates[1][1],\n",
    "         label=f'{p_names[1]} (AUC: {auc_scores[1]})')\n",
    "plt.plot(rc_rates[2][0], rc_rates[2][1],\n",
    "         label=f'{p_names[2]} (AUC: {auc_scores[2]})')\n",
    "plt.plot(rc_rates[3][0], rc_rates[3][1],\n",
    "         label=f'{p_names[3]} (AUC: {auc_scores[3]})')\n",
    "plt.plot(rc_rates[4][0], rc_rates[4][1],\n",
    "         label=f'{p_names[4]} (AUC: {auc_scores[4]})')\n",
    "plt.plot(rc_rates[5][0], rc_rates[5][1],\n",
    "         label=f'{p_names[5]} (AUC: {auc_scores[5]})')\n",
    "plt.plot([0, 1], [0, 1], color='blue', linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.title('Away Win Model ROC Curves')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# plots for cumulative response curve\n",
    "plt.figure(figsize=(20, 16))\n",
    "plt.plot([((idx + 1)/len(rc_threshs[0])) for idx,\n",
    "          x in enumerate(rc_threshs[0])], rc_rates[0][1], label=f'{p_names[0]}')\n",
    "plt.plot([((idx + 1)/len(rc_threshs[1])) for idx,\n",
    "          x in enumerate(rc_threshs[1])], rc_rates[1][1], label=f'{p_names[1]}')\n",
    "plt.plot([((idx + 1)/len(rc_threshs[2])) for idx,\n",
    "          x in enumerate(rc_threshs[2])], rc_rates[2][1], label=f'{p_names[2]}')\n",
    "plt.plot([((idx + 1)/len(rc_threshs[3])) for idx,\n",
    "          x in enumerate(rc_threshs[3])], rc_rates[3][1], label=f'{p_names[3]}')\n",
    "plt.plot([((idx + 1)/len(rc_threshs[4])) for idx,\n",
    "          x in enumerate(rc_threshs[4])], rc_rates[4][1], label=f'{p_names[4]}')\n",
    "plt.plot([((idx + 1)/len(rc_threshs[5])) for idx,\n",
    "          x in enumerate(rc_threshs[5])], rc_rates[5][1], label=f'{p_names[5]}')\n",
    "plt.plot([0, 1], [0, 1], color='blue', linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.title('Away Win Model Cumulative Response Curves')\n",
    "plt.xlabel('Percentage of Data')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# optimised weight ensemble including the simple logistic regression model\n",
    "# load features/targets\n",
    "train_features = load_train_features()\n",
    "test_features = load_test_features()\n",
    "away_train_target, away_test_target = load_away_targets()\n",
    "\n",
    "# get predictions for cluster 1 & 3 features\n",
    "test_cluster_feats = load_cluster_test_feats()\n",
    "rf_cl1_model = joblib.load('cl1_rf_model.sav')\n",
    "rf_pred = rf_cl1_model.predict(test_cluster_feats)\n",
    "gb_cl3_model = joblib.load('cl3_gb_model.sav')\n",
    "gb_pred = gb_cl3_model.predict(test_cluster_feats)\n",
    "# add cluster 1 & 3 predictions to test features\n",
    "test_features['cluster_1'] = rf_pred\n",
    "test_features['cluster_3'] = gb_pred\n",
    "\n",
    "# load pipelines\n",
    "lgbm_pipe, lgbm_cal_pipe, lgbm_test_feats, lgbm_name = away_lgbm_setup()\n",
    "xgb_pipe, xgb_cal_pipe, xgb_test_feats, xgb_name = away_xgb_setup()\n",
    "# instantiate a simple model\n",
    "lr_sm = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "lrsm_test_feats = test_features['AwayCapacityDiff']\n",
    "lr_sm_pipe = IMBPipeline(\n",
    "    steps=[\n",
    "        ('trans', KeepColumnsTransformer(['AwayCapacityDiff'])),\n",
    "        ('model', lr_sm)\n",
    "    ]\n",
    ")\n",
    "\n",
    "ensemble_pipes = [lgbm_pipe, xgb_pipe, lr_sm_pipe]\n",
    "ensemble_fit_pipes = [pipe.fit(train_features, np.array(\n",
    "    away_train_target).reshape(-1,)) for pipe in ensemble_pipes]\n",
    "\n",
    "weight_bounds = [(0.0, 0.1) for _ in range(len(ensemble_pipes))]\n",
    "# arguments for the loss function\n",
    "search_arg = (ensemble_fit_pipes, test_features, away_test_target)\n",
    "# global optimization of ensemble weights\n",
    "result = differential_evolution(\n",
    "    loss_function, weight_bounds, search_arg, maxiter=1000, tol=1e-7)\n",
    "weights = normalise(result['x'])\n",
    "np.savetxt('optimised_weights_for_away_models_inc_simpmod_ensemble.csv',\n",
    "           np.array(weights), delimiter=',')  # save weights\n",
    "print(f'Optimised Ensemble inc Simple Model Weights:\\n{weights}')\n",
    "# evaluate ensemble with optimised weights\n",
    "ow_pred, ow_probs, ow_score = evaluate_ensemble(\n",
    "    ensemble_fit_pipes, weights, test_features, away_test_target)\n",
    "fpr, tpr, thresholds = roc_curve(away_test_target, ow_probs)\n",
    "rc_rates.append((fpr, tpr))\n",
    "rc_threshs.append(thresholds)\n",
    "auc_scores.append(auc(fpr, tpr))\n",
    "p_names.append('OW Ens')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble inc. Simple Model Fbeta Score: {ow_score}')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble inc. Simple Model Cohen Kappa Score: {cohen_kappa_score(away_test_target, ow_pred)}')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble inc. Simple Model classification report:\\n{classification_report(away_test_target, ow_pred)}')\n",
    "print(\n",
    "    f'Optimised Weighted Average Ensemble inc. Simple Model confusion matrix:\\n{confusion_matrix(away_test_target, ow_pred)}\\n')\n",
    "# save test features win probabilities for away teams as df\n",
    "away_team_win_probs = pd.DataFrame(\n",
    "    {'AwayTeam': test_features.AwayTeam.values, 'OW_Ensemble_away_win_probs': ow_probs})\n",
    "away_team_win_probs.to_csv(\n",
    "    f'OW_Ensemble_inc_simpmod_away_team_win_probs.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model expected profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T14:47:50.158361Z",
     "start_time": "2021-04-07T14:47:48.857840Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "test_features = load_test_features()\n",
    "_, home_test_target = load_home_targets()\n",
    "_, away_test_target = load_away_targets()\n",
    "\n",
    "# get predictions for cluster 1 & 3 features\n",
    "test_cluster_feats = load_cluster_test_feats()\n",
    "rf_cl1_model = joblib.load('cl1_rf_model.sav')\n",
    "rf_pred = rf_cl1_model.predict(test_cluster_feats)\n",
    "gb_cl3_model = joblib.load('cl3_gb_model.sav')\n",
    "gb_pred = gb_cl3_model.predict(test_cluster_feats)\n",
    "# add cluster 1 & 3 predictions to test features\n",
    "test_features['cluster_1'] = rf_pred\n",
    "test_features['cluster_3'] = gb_pred\n",
    "\n",
    "# load home models\n",
    "home_lr_model = joblib.load('LR_home_win_model_pipeline.sav')\n",
    "home_xgb_model = joblib.load('XGB_home_win_model_pipeline.sav')\n",
    "home_lrsm_model = joblib.load('LR SM_home_win_model_pipeline.sav')\n",
    "home_opt_weights = np.loadtxt(\n",
    "    'home_ensemble_optimised_weights_inc_simpmod.csv', delimiter=',')\n",
    "\n",
    "# load away models\n",
    "away_lgbm_model = joblib.load('LGBM_away_win_model_pipeline.sav')\n",
    "away_xgb_model = joblib.load('XGB_away_win_model_pipeline.sav')\n",
    "away_lrsm_model = joblib.load('LR SM_away_win_model_pipeline.sav')\n",
    "away_opt_weights = np.loadtxt(\n",
    "    'optimised_weights_for_away_models_inc_simpmod_ensemble.csv', delimiter=',')\n",
    "\n",
    "home_models = [(home_lr_model, 'home_LR'), (home_xgb_model,\n",
    "                                            'home_XGB'), (home_lrsm_model, 'home_LRSM'), (_, 'home_ENS')]\n",
    "away_models = [(away_lgbm_model, 'away_LGBM'), (away_xgb_model,\n",
    "                                                'away_XGB'), (away_lrsm_model, 'away_LRSM'), (_, 'away_ENS')]\n",
    "\n",
    "cb_matrix = np.array([[0, -5],\n",
    "                      [0, 16]])  # 16 is an averaged return\n",
    "home_pos_prior = 0.44\n",
    "away_pos_prior = 0.29\n",
    "models_dict = {'Models': [], 'Combined Exp. Profit': []}\n",
    "for h_model, h_name in home_models:\n",
    "    if h_name == 'home_ENS':\n",
    "        home_ensemble = [home_lr_model, home_xgb_model, home_lrsm_model]\n",
    "        h_ens_yhat_probs = [home_ensemble[i].predict_proba(\n",
    "            test_features)[:, 1] for i in range(len(home_ensemble))]\n",
    "        h_ens_yhat_probs = np.array(h_ens_yhat_probs)\n",
    "        h_weighted_probs = np.tensordot(\n",
    "            h_ens_yhat_probs, home_opt_weights, axes=((0), (0)))\n",
    "        # round probabilities to classes.. 0 or 1\n",
    "        h_yhat_classes = np.round(h_weighted_probs)\n",
    "        h_yhat_classes = np.array([int(x) for x in h_yhat_classes])\n",
    "        home_cm = confusion_matrix(home_test_target, h_yhat_classes)\n",
    "        home_exp_profit = expected_profit(home_cm, cb_matrix, home_pos_prior)\n",
    "    else:\n",
    "        home_yhat_class = h_model.predict(test_features)\n",
    "        home_cm = confusion_matrix(home_test_target, home_yhat_class)\n",
    "        home_exp_profit = expected_profit(home_cm, cb_matrix, home_pos_prior)\n",
    "    for a_model, a_name in away_models:\n",
    "        print(f'processing {h_name} & {a_name}')\n",
    "        if a_name == 'away_ENS':\n",
    "            away_ensemble = [away_lgbm_model, away_xgb_model, away_lrsm_model]\n",
    "            a_ens_yhat_probs = [away_ensemble[i].predict_proba(\n",
    "                test_features)[:, 1] for i in range(len(away_ensemble))]\n",
    "            a_ens_yhat_probs = np.array(a_ens_yhat_probs)\n",
    "            a_weighted_probs = np.tensordot(\n",
    "                a_ens_yhat_probs, away_opt_weights, axes=((0), (0)))\n",
    "            # round probabilities to classes.. 0 or 1\n",
    "            a_yhat_classes = np.round(a_weighted_probs)\n",
    "            a_yhat_classes = np.array([int(x) for x in a_yhat_classes])\n",
    "            away_cm = confusion_matrix(away_test_target, a_yhat_classes)\n",
    "            away_exp_profit = expected_profit(\n",
    "                away_cm, cb_matrix, away_pos_prior)\n",
    "        else:\n",
    "            # prob predictions for class 1\n",
    "            away_yhat_class = a_model.predict(test_features)\n",
    "            away_cm = confusion_matrix(away_test_target, away_yhat_class)\n",
    "            away_exp_profit = expected_profit(\n",
    "                away_cm, cb_matrix, away_pos_prior)\n",
    "\n",
    "        comb_exp_profit = home_exp_profit + away_exp_profit\n",
    "        models_dict['Models'].append(f'{h_name} & {a_name}')\n",
    "        models_dict['Combined Exp. Profit'].append(comb_exp_profit)\n",
    "        print(\n",
    "            f'{h_name} exp. profit: {home_exp_profit},      {a_name} exp. profit: {away_exp_profit}')\n",
    "\n",
    "model_profit_df = pd.DataFrame(models_dict)\n",
    "model_profit_df = model_profit_df.sort_values(\n",
    "    by='Combined Exp. Profit', ascending=False).reset_index(drop=True)\n",
    "model_profit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Summary -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Home Models:\n",
    "\n",
    "Both home models have generalised well with the Logistic Regression model coming out on top with an fbeta score of 0.595695 and a cohen kappa score of 0.181366, compared to XGBoosts fbeta score of 0.585135 and cohen kappa score of 0.156890 with cluster_3 being the feature that provided the most information. Both models out performed the simple logistic regression model.\n",
    "\n",
    "The voting classifier didnt out perform the logistic regression model.\n",
    "\n",
    "An equal weighted ensemble and also an optimised weighted ensemble was produced to see if there could be anymore performance gained. The equal weighted ensemble performed exactly the same as the voting classifier which would be exected but the optimised weighted ensemble gave a slight performance boost on the logistic regression model with an fbeta score of 0.596013 although a slightly lower cohen kappa score of 0.180733.\n",
    "\n",
    "The learning curves for the logistic regression and xgboost models show that there is room for improvement by obtaining more data. The logistic regresion model shows more variablity with its cross validated scores.\n",
    "\n",
    "All models tested show ROC curves better than random and better compared to the simple model, with AUC scores of approx 0.62. The top AUC scores are shown by the equal weighted ensemble and the optimised weighted ensemble. The ROC curves are all approximately the same with the Logistic regression and optimal weighted ensemble having a slight peak at approx. 55% true positve rate to 35% false positive rate.\n",
    "\n",
    "The cumulative response curve shows that the logistic regression, equal weighted ensemble and optimised weighted ensemble produce roughly the same true positve rate for the percentage of data seen. The equal weighted ensemble does have a slight increase at around 60 percent of the data albeit very minimal.\n",
    "\n",
    "After analysis the optimised weighted ensemble would be the best choice for the final home win model as it outperforms the other models even though it is only marginal. Also the optimised weighted ensemble was tested with the simple model included and it had a slight boost in performance with an fbeta score of 0.597327 and a cohen kappa score of 0.185075. Also compared to other models it has the best true positive predictions along with the best false negatives but with a slight increase in false positive predictions but this lends itself to being more risk accepting. So as a final model the optimised weighted ensemble with simple model included appears to be the best choice.\n",
    "\n",
    "Away Models:\n",
    "\n",
    "Both models again have generalised well even producing a slightly better fbeta score than expected, the XGBoost model performed the best with an fbeat score of 0.677068 and cohen kappa score of 0.171716 compared to the light gradient boostings fbeta score of 0.675380 and cohne kappa score of 0.164242. Light gradient boosting model found that 'AHTP5PG','AHTGC5PG' and 'AHTGS5PG' provided the most information and the XGBoost model found that 'cluster_1' and 'HA_ATP5PG_diff' provided the most information on the target. Both models outperformed the simple model.\n",
    "\n",
    "The voting classifier increased performance with an fbeta score of 0.679937 and cohen kappa score of 0.174959\n",
    "\n",
    "The equal weighted ensemble model performed the same as the voting classifier, the optimised weighted ensemble model increased performance with an fbeta score of 0.681059 and cohen kappa score of 0.178157.\n",
    "\n",
    "The learning curve for the XGBoost model shows a plateau leading to a slight decline with the test score meaning that more data might not possibly improve the fbeta score. The learning curve for the light gradient boosting model shows the test score starting to plateau which also could mean more data might not improve the fbeta score. The reason behind the plateau and decline could be that the proportion of away wins is fairly low at approx. 29% and theres not many good predictors of an away win, which leads to the increase of data not having an effect on away win prediction performance. Also because an away win is harder to predict we will run into more false positive and false negative predictions, this could be because the home team/away team either over perform or under perform, dip in player confidence and other underlying factors. To boost away win prediction performance and improve the learning curves more attention to feature engineering for this area will help.\n",
    "\n",
    "All models tested show ROC curves better than random and better than the simple model with curves all approx. the same. The optimised weighted ensemble has the best AUC score at 0.6439 just above the equal weighted ensemble.\n",
    "\n",
    "All cumulative response curves are roughly the same up until approx. 40% of data seen then the simple models true positve rate exceeds the other models.\n",
    "\n",
    "After analysis the final away win model is the optimised weighted ensemble but with the simple models increased true positive rate in the cumulative response curve, the optimised ensemble had the simple model included which led to an increased performance with an fbeta score of 0.682849 and cohen kappa score of 0.183988.\n",
    "\n",
    "--------------\n",
    "\n",
    "after calculating combined home and away model expected profits, surprisingly we found that the combination of the home optimised model and away simple logistic regression model produced the highest expected profit of 3.93... in the longterm on average we can expect 3.93 return from each bet the model predicts we should bet on. This is compared to the two top performing models, the home and away optimised models, producing and expected profit of 3.74. Looking at the confusion matrices it can be seen why the away simple logistic regression model helps produce the best expected profit, the away simple model shows in this domain that it is extremely risk accepting showing nearly double the amount of false positives compared to true positives and the smallest number of false negatives amongst the away models. This does show that allowing more risk can reap more rewards, although the expected profit was calculated using and averaged return value from a £5 bet and is not using the odds for the teams, so this could change if the original odds were used as the profit margins will change but it does provide a comparison. As using the away simple model produces a huge amount of false positives compared to the other away models, using it by itself might prove to be too untrustworthy as the cohen kappa score is half that of the away best ensemble model.\n",
    "\n",
    "For future analysis of the away models more focus should be applied to maximising recall as this will allow the models to make more correct predictions (minimise false negatives), it can be seen from away model confusion matrices that the away false negatives are more than double false positives compared to the home models where they are approximately equal. Future analysis of the home models should include more attention to weighting fbeta towards recall to maximise more rewards\n",
    "\n",
    "Both home and away top ensemble models produce cohen kappa scores of approx. 0.18, which are not trustworthy scores for predictive modelling and this reflects the fact that there is a lot of variability within the results of football matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Models for  cluster predictions --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for cluster 1 & 3 predictions\n",
    "train_features = load_train_features()\n",
    "train_features.head()\n",
    "cluster_train_feats = []\n",
    "# get columns that were used for kmeans clustering\n",
    "for f in train_features.columns:\n",
    "    if f != 'cluster_0':\n",
    "        cluster_train_feats.append(f)\n",
    "    else:\n",
    "        break\n",
    "cluster_train_feats = train_features[cluster_train_feats].copy()\n",
    "drop_cols = ['Div', 'FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC',\n",
    "             'AC', 'HY', 'AY', 'HR', 'AR']\n",
    "cluster_train_feats.drop(columns=drop_cols, inplace=True)  # drop cols cant use\n",
    "# cluster_train_feats = football_data_team_ohe(cluster_train_feats) # ohe\n",
    "# targets for cluster predictions\n",
    "cluster1_targ = train_features['cluster_1'].copy()\n",
    "cluster3_targ = train_features['cluster_3'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test features for clusters\n",
    "test_features = load_test_features()\n",
    "cluster_train_features = load_cluster_features()\n",
    "cluster_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "tf = cluster_train_features.columns\n",
    "cluster_test_features = test_features[tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train/test\n",
    "# load data\n",
    "cluster_features = load_cluster_features()\n",
    "cluster1_target = load_cluster1_target()\n",
    "cluster3_target = load_cluster3_target()\n",
    "# split data\n",
    "cl1_train_features, cl1_test_features, cl1_train_target, cl1_test_target = train_test_split(\n",
    "    cluster_features, cluster1_target, test_size=0.2, random_state=42, stratify=cluster1_target)\n",
    "cl3_train_features, cl3_test_features, cl3_train_target, cl3_test_target = train_test_split(\n",
    "    cluster_features, cluster3_target, test_size=0.2, random_state=42, stratify=cluster3_target)\n",
    "# save data\n",
    "# cluster 1\n",
    "cl1_train_features.to_csv('cluster1_train_features.csv',\n",
    "                          encoding='utf-8', index=False)\n",
    "cl1_test_features.to_csv('cluster1_test_features.csv',\n",
    "                         encoding='utf-8', index=False)\n",
    "cl1_train_target.to_csv('cluster1_train_target.csv',\n",
    "                        encoding='utf-8', index=False)\n",
    "cl1_test_target.to_csv('cluster1_test_target.csv',\n",
    "                       encoding='utf-8', index=False)\n",
    "# cluster 3\n",
    "cl3_train_features.to_csv('cluster3_train_features.csv',\n",
    "                          encoding='utf-8', index=False)\n",
    "cl3_test_features.to_csv('cluster3_test_features.csv',\n",
    "                         encoding='utf-8', index=False)\n",
    "cl3_train_target.to_csv('cluster3_train_target.csv',\n",
    "                        encoding='utf-8', index=False)\n",
    "cl3_test_target.to_csv('cluster3_test_target.csv',\n",
    "                       encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 1 Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster model test without home/away teams\n",
    "cl1_train_feats, _ = load_cluster1_features()\n",
    "cl1_train_target, _ = load_cluster1_targets()\n",
    "cl1_train_feats.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "cl_models, cl_names = load_cluster_models()\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(cl_models)):\n",
    "    print(f'Running {cl_names[i]} Model')\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('model', cl_models[i])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scores = evaluate_cluster_model(cl1_train_feats, np.array(\n",
    "        cl1_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "    model_list.append(cl_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg F1 Score': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg F1 Score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster model test with home/away teams\n",
    "cl1_train_feats, _ = load_cluster1_features()\n",
    "cl1_train_target, _ = load_cluster1_targets()\n",
    "ohtt = OHETeamTransformer()\n",
    "ohe_cl1_train_feats = ohtt.transform(cl1_train_feats)\n",
    "\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "cl_models, cl_names = load_cluster_models()\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(cl_models)):\n",
    "    print(f'Running {cl_names[i]} Model')\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('model', cl_models[i])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scores = evaluate_cluster_model(ohe_cl1_train_feats, np.array(\n",
    "        cl1_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "    model_list.append(cl_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg F1 Score': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg F1 Score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalisation\n",
    "# load data\n",
    "cl1_train_features, cl1_test_features = load_cluster1_features()\n",
    "cl1_train_target, cl1_test_target = load_cluster1_targets()\n",
    "# remove home/away teams\n",
    "cl1_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "cl1_test_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "# fit & predict\n",
    "rf = RandomForestClassifier(n_estimators=200, class_weight='balanced',\n",
    "                            max_features='sqrt', n_jobs=-1, random_state=42)\n",
    "rf.fit(cl1_train_features, np.array(cl1_train_target).reshape(-1,))\n",
    "rf_pred = rf.predict(cl1_test_features)\n",
    "print(confusion_matrix(cl1_test_target, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cluster 1 random forest model\n",
    "joblib.dump(rf, 'cl1_rf_model.sav')\n",
    "# load model\n",
    "# model = joblib.load('cl1_rf_model.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 3 Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster model test without home/away teams\n",
    "cl3_train_feats, _ = load_cluster3_features()\n",
    "cl3_train_target, _ = load_cluster3_targets()\n",
    "cl3_train_feats.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "cl_models, cl_names = load_cluster_models()\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(cl_models)):\n",
    "    print(f'Running {cl_names[i]} Model')\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('model', cl_models[i])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scores = evaluate_cluster_model(cl3_train_feats, np.array(\n",
    "        cl3_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "    model_list.append(cl_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg F1 Score': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg F1 Score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster model test with home/away teams\n",
    "cl3_train_feats, _ = load_cluster3_features()\n",
    "cl3_train_target, _ = load_cluster3_targets()\n",
    "ohtt = OHETeamTransformer()\n",
    "ohe_cl3_train_feats = ohtt.transform(cl3_train_feats)\n",
    "\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "cl_models, cl_names = load_cluster_models()\n",
    "\n",
    "model_list = []\n",
    "score_list = []\n",
    "std_list = []\n",
    "\n",
    "for i in range(len(cl_models)):\n",
    "    print(f'Running {cl_names[i]} Model')\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('sc', sc),\n",
    "            ('model', cl_models[i])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scores = evaluate_cluster_model(ohe_cl3_train_feats, np.array(\n",
    "        cl3_train_target).reshape(-1,), pipe, k_splits=10)\n",
    "    model_list.append(cl_names[i])\n",
    "    score_list.append(np.mean(scores))\n",
    "    std_list.append(np.std(scores))\n",
    "model_performance = pd.DataFrame(\n",
    "    {'Model': model_list, 'Avg F1 Score': score_list, 'Std': std_list})\n",
    "model_performance.sort_values(\n",
    "    by='Avg F1 Score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalisation\n",
    "# load data\n",
    "cl3_train_features, cl3_test_features = load_cluster3_features()\n",
    "cl3_train_target, cl3_test_target = load_cluster3_targets()\n",
    "# remove home/away teams\n",
    "cl3_train_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "cl3_test_features.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "# fit & predict\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=200, learning_rate=0.1, max_features='sqrt', random_state=42)\n",
    "gb.fit(cl3_train_features, np.array(cl3_train_target).reshape(-1,))\n",
    "gb_pred = gb.predict(cl3_test_features)\n",
    "print(confusion_matrix(cl3_test_target, gb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cluster 3 gradient boosting model\n",
    "joblib.dump(gb, 'cl3_gb_model.sav')\n",
    "# load model\n",
    "# model = joblib.load('cl3_gb_model.sav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "26px",
    "width": "324px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "260.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
